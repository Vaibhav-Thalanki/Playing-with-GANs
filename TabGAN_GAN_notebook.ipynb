{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66ea9ebe0c2d4c0c979b22e6f8dfa9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd073c0deab74b1c84c757dd04f4b4d0",
              "IPY_MODEL_5e590e7c9eba46709b683dfa4d23f855",
              "IPY_MODEL_928f0f7e628a41f1bbfc933240b970f7"
            ],
            "layout": "IPY_MODEL_9781fd2ea4de4239857507f5287c511d"
          }
        },
        "dd073c0deab74b1c84c757dd04f4b4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dab2c77192024d829cb439087eb07b6c",
            "placeholder": "​",
            "style": "IPY_MODEL_a84f54dfea304a3381bd7df92a038675",
            "value": "Fitting CTGAN transformers for each column: 100%"
          }
        },
        "5e590e7c9eba46709b683dfa4d23f855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a881253636c74692bce1a59636be9755",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35c8417d55cf4921911438863fc15afa",
            "value": 5
          }
        },
        "928f0f7e628a41f1bbfc933240b970f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d1b5af1bd474b80a0f6dd4573405af6",
            "placeholder": "​",
            "style": "IPY_MODEL_1ff99bd12a5345358ed1d912b8fd73c1",
            "value": " 5/5 [00:02&lt;00:00,  2.68it/s]"
          }
        },
        "9781fd2ea4de4239857507f5287c511d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab2c77192024d829cb439087eb07b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84f54dfea304a3381bd7df92a038675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a881253636c74692bce1a59636be9755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c8417d55cf4921911438863fc15afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d1b5af1bd474b80a0f6dd4573405af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff99bd12a5345358ed1d912b8fd73c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8dfc1e3d398469fb00f1ed34c2d6ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0e4d0f5e5604c7e9e651128186b22a3",
              "IPY_MODEL_25d13fdd77f64989a6f6e8939d88a91e",
              "IPY_MODEL_e044d893282e4ef49db3c9a9d9220ee2"
            ],
            "layout": "IPY_MODEL_89ab8d472d7245e8be1b2265c311af80"
          }
        },
        "f0e4d0f5e5604c7e9e651128186b22a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77739df8df61493dabab6438f41b96d6",
            "placeholder": "​",
            "style": "IPY_MODEL_f4bdb70a850346d9b176ef1593dd53eb",
            "value": "Training CTGAN, epochs:: 100%"
          }
        },
        "25d13fdd77f64989a6f6e8939d88a91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7aaf27384b8488fb9707c5dfb99a904",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88870b8507494eadb9e375460be74917",
            "value": 500
          }
        },
        "e044d893282e4ef49db3c9a9d9220ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d13bd1ce79746019c0fda7f040afb4f",
            "placeholder": "​",
            "style": "IPY_MODEL_8955f5164b774bfcacfd142b42168564",
            "value": " 500/500 [01:41&lt;00:00,  5.28it/s]"
          }
        },
        "89ab8d472d7245e8be1b2265c311af80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77739df8df61493dabab6438f41b96d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bdb70a850346d9b176ef1593dd53eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7aaf27384b8488fb9707c5dfb99a904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88870b8507494eadb9e375460be74917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d13bd1ce79746019c0fda7f040afb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8955f5164b774bfcacfd142b42168564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA64fOomZWBU",
        "outputId": "3fc50cbf-1c1b-4387-9684-e8d748ee0353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "Dkl07tWRZV9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "f5F6DUO1ZV6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QqYYPCaaZV3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nsharan/h-1b-visa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3M3Mfq8lSbZ",
        "outputId": "d2e89df4-0fa7-49a7-d0f7-22d4159180e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading h-1b-visa.zip to /content\n",
            "100% 94.8M/94.8M [00:00<00:00, 151MB/s]\n",
            "100% 94.8M/94.8M [00:00<00:00, 130MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip h-1b-visa.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDJfRDzxlNYx",
        "outputId": "c271f625-4e45-4f80-fe5b-ac984b9167b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  h-1b-visa.zip\n",
            "  inflating: h1b_kaggle.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu21b7Nmmhd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b06039-e462-42db-b20d-b92e1672e3a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 06:49:17--  https://raw.githubusercontent.com/Diyago/GAN-for-tabular-data/master/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 183 [text/plain]\n",
            "Saving to: ‘requirements.txt.1’\n",
            "\n",
            "\rrequirements.txt.1    0%[                    ]       0  --.-KB/s               \rrequirements.txt.1  100%[===================>]     183  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-04 06:49:17 (10.9 MB/s) - ‘requirements.txt.1’ saved [183/183]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: category_encoders==2.1.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (2.0.0+cu118)\n",
            "Requirement already satisfied: pandas>=1.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: lightgbm>=2.2.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (3.3.5)\n",
            "Requirement already satisfied: scikit_learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: torchvision>=0.4.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (0.15.1+cu118)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (2.8.1)\n",
            "Requirement already satisfied: tqdm>=4.61.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (4.65.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders==2.1.0->-r requirements.txt (line 2)) (0.13.5)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders==2.1.0->-r requirements.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil==2.8.1->-r requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->-r requirements.txt (line 4)) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->-r requirements.txt (line 4)) (3.25.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.2->-r requirements.txt (line 5)) (2022.7.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm>=2.2.3->-r requirements.txt (line 6)) (0.40.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>=1.0.2->-r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>=1.0.2->-r requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.4.2->-r requirements.txt (line 8)) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.4.2->-r requirements.txt (line 8)) (2.27.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.6.1->category_encoders==2.1.0->-r requirements.txt (line 2)) (23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->-r requirements.txt (line 4)) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.4.2->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.4.2->-r requirements.txt (line 8)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.4.2->-r requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.4.2->-r requirements.txt (line 8)) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabgan in /usr/local/lib/python3.9/dist-packages (1.3.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from tabgan) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from tabgan) (1.4.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from tabgan) (0.15.1+cu118)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.9/dist-packages (from tabgan) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tabgan) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from tabgan) (2.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tabgan) (1.22.0)\n",
            "Requirement already satisfied: category-encoders in /usr/local/lib/python3.9/dist-packages (from tabgan) (2.1.0)\n",
            "Requirement already satisfied: lightgbm>=2.2.3 in /usr/local/lib/python3.9/dist-packages (from tabgan) (3.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lightgbm>=2.2.3->tabgan) (1.10.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm>=2.2.3->tabgan) (0.40.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->tabgan) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->tabgan) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->tabgan) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->tabgan) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->tabgan) (3.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->tabgan) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->tabgan) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->tabgan) (3.10.7)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0->tabgan) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0->tabgan) (16.0.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from category-encoders->tabgan) (0.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from category-encoders->tabgan) (0.13.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->tabgan) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil->tabgan) (1.16.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->tabgan) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->tabgan) (2.27.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.6.1->category-encoders->tabgan) (23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.0->tabgan) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->tabgan) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->tabgan) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->tabgan) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->tabgan) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.0->tabgan) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# HIDE OUTPUT\n",
        "CMD = \"wget https://raw.githubusercontent.com/Diyago/\"\\\n",
        "  \"GAN-for-tabular-data/master/requirements.txt\"\n",
        "\n",
        "!{CMD}\n",
        "!pip install -r requirements.txt\n",
        "!pip install tabgan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "sUKAFr0f1Zwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"h1b_kaggle.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "WQsPVkQ4BaxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "outputId": "86e13683-e4ef-478d-8fa4-886c3b99eed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0          CASE_STATUS  \\\n",
              "0                 1  CERTIFIED-WITHDRAWN   \n",
              "1                 2  CERTIFIED-WITHDRAWN   \n",
              "2                 3  CERTIFIED-WITHDRAWN   \n",
              "3                 4  CERTIFIED-WITHDRAWN   \n",
              "4                 5            WITHDRAWN   \n",
              "...             ...                  ...   \n",
              "3002453     3002454                  NaN   \n",
              "3002454     3002455                  NaN   \n",
              "3002455     3002456                  NaN   \n",
              "3002456     3002457                  NaN   \n",
              "3002457     3002458                  NaN   \n",
              "\n",
              "                                             EMPLOYER_NAME  \\\n",
              "0                                   UNIVERSITY OF MICHIGAN   \n",
              "1                                   GOODMAN NETWORKS, INC.   \n",
              "2                                PORTS AMERICA GROUP, INC.   \n",
              "3        GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY O...   \n",
              "4                                PEABODY INVESTMENTS CORP.   \n",
              "...                                                    ...   \n",
              "3002453                                                NaN   \n",
              "3002454                                                NaN   \n",
              "3002455                                                NaN   \n",
              "3002456                                                NaN   \n",
              "3002457                                                NaN   \n",
              "\n",
              "                              SOC_NAME                     JOB_TITLE  \\\n",
              "0        BIOCHEMISTS AND BIOPHYSICISTS  POSTDOCTORAL RESEARCH FELLOW   \n",
              "1                     CHIEF EXECUTIVES       CHIEF OPERATING OFFICER   \n",
              "2                     CHIEF EXECUTIVES         CHIEF PROCESS OFFICER   \n",
              "3                     CHIEF EXECUTIVES   REGIONAL PRESIDEN, AMERICAS   \n",
              "4                     CHIEF EXECUTIVES  PRESIDENT MONGOLIA AND INDIA   \n",
              "...                                ...                           ...   \n",
              "3002453                            NaN                           NaN   \n",
              "3002454                            NaN                           NaN   \n",
              "3002455                            NaN                           NaN   \n",
              "3002456                            NaN                           NaN   \n",
              "3002457                            NaN                           NaN   \n",
              "\n",
              "        FULL_TIME_POSITION  PREVAILING_WAGE    YEAR                 WORKSITE  \\\n",
              "0                        N          36067.0  2016.0      ANN ARBOR, MICHIGAN   \n",
              "1                        Y         242674.0  2016.0             PLANO, TEXAS   \n",
              "2                        Y         193066.0  2016.0  JERSEY CITY, NEW JERSEY   \n",
              "3                        Y         220314.0  2016.0         DENVER, COLORADO   \n",
              "4                        Y         157518.4  2016.0      ST. LOUIS, MISSOURI   \n",
              "...                    ...              ...     ...                      ...   \n",
              "3002453                NaN              NaN     NaN            NYC, NEW YORK   \n",
              "3002454                NaN              NaN     NaN        SOUTH LAKE, TEXAS   \n",
              "3002455                NaN              NaN     NaN      CLINTON, NEW JERSEY   \n",
              "3002456                NaN              NaN     NaN    OWINGS MILL, MARYLAND   \n",
              "3002457                NaN              NaN     NaN         ALTANTA, GEORGIA   \n",
              "\n",
              "                lon        lat  \n",
              "0        -83.743038  42.280826  \n",
              "1        -96.698886  33.019843  \n",
              "2        -74.077642  40.728158  \n",
              "3       -104.990251  39.739236  \n",
              "4        -90.199404  38.627003  \n",
              "...             ...        ...  \n",
              "3002453  -74.005941  40.712784  \n",
              "3002454  -97.134178  32.941236  \n",
              "3002455  -74.909890  40.636768  \n",
              "3002456  -76.780253  39.419550  \n",
              "3002457  -84.387982  33.748995  \n",
              "\n",
              "[3002458 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9431a316-f751-47b0-bea8-6404a0bd830a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CASE_STATUS</th>\n",
              "      <th>EMPLOYER_NAME</th>\n",
              "      <th>SOC_NAME</th>\n",
              "      <th>JOB_TITLE</th>\n",
              "      <th>FULL_TIME_POSITION</th>\n",
              "      <th>PREVAILING_WAGE</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>WORKSITE</th>\n",
              "      <th>lon</th>\n",
              "      <th>lat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>UNIVERSITY OF MICHIGAN</td>\n",
              "      <td>BIOCHEMISTS AND BIOPHYSICISTS</td>\n",
              "      <td>POSTDOCTORAL RESEARCH FELLOW</td>\n",
              "      <td>N</td>\n",
              "      <td>36067.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>ANN ARBOR, MICHIGAN</td>\n",
              "      <td>-83.743038</td>\n",
              "      <td>42.280826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>GOODMAN NETWORKS, INC.</td>\n",
              "      <td>CHIEF EXECUTIVES</td>\n",
              "      <td>CHIEF OPERATING OFFICER</td>\n",
              "      <td>Y</td>\n",
              "      <td>242674.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>PLANO, TEXAS</td>\n",
              "      <td>-96.698886</td>\n",
              "      <td>33.019843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>PORTS AMERICA GROUP, INC.</td>\n",
              "      <td>CHIEF EXECUTIVES</td>\n",
              "      <td>CHIEF PROCESS OFFICER</td>\n",
              "      <td>Y</td>\n",
              "      <td>193066.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>JERSEY CITY, NEW JERSEY</td>\n",
              "      <td>-74.077642</td>\n",
              "      <td>40.728158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>GATES CORPORATION, A WHOLLY-OWNED SUBSIDIARY O...</td>\n",
              "      <td>CHIEF EXECUTIVES</td>\n",
              "      <td>REGIONAL PRESIDEN, AMERICAS</td>\n",
              "      <td>Y</td>\n",
              "      <td>220314.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>DENVER, COLORADO</td>\n",
              "      <td>-104.990251</td>\n",
              "      <td>39.739236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>WITHDRAWN</td>\n",
              "      <td>PEABODY INVESTMENTS CORP.</td>\n",
              "      <td>CHIEF EXECUTIVES</td>\n",
              "      <td>PRESIDENT MONGOLIA AND INDIA</td>\n",
              "      <td>Y</td>\n",
              "      <td>157518.4</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>ST. LOUIS, MISSOURI</td>\n",
              "      <td>-90.199404</td>\n",
              "      <td>38.627003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002453</th>\n",
              "      <td>3002454</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NYC, NEW YORK</td>\n",
              "      <td>-74.005941</td>\n",
              "      <td>40.712784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002454</th>\n",
              "      <td>3002455</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SOUTH LAKE, TEXAS</td>\n",
              "      <td>-97.134178</td>\n",
              "      <td>32.941236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002455</th>\n",
              "      <td>3002456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CLINTON, NEW JERSEY</td>\n",
              "      <td>-74.909890</td>\n",
              "      <td>40.636768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002456</th>\n",
              "      <td>3002457</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OWINGS MILL, MARYLAND</td>\n",
              "      <td>-76.780253</td>\n",
              "      <td>39.419550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002457</th>\n",
              "      <td>3002458</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ALTANTA, GEORGIA</td>\n",
              "      <td>-84.387982</td>\n",
              "      <td>33.748995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3002458 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9431a316-f751-47b0-bea8-6404a0bd830a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9431a316-f751-47b0-bea8-6404a0bd830a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9431a316-f751-47b0-bea8-6404a0bd830a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.sample(frac = 1)"
      ],
      "metadata": {
        "id": "WHbo-CZdaH_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(10000)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "XmLMrl_saRfH",
        "outputId": "5b050cac-6fb3-4441-e7f7-8c0dcc592954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0          CASE_STATUS  \\\n",
              "1850053     1850054            CERTIFIED   \n",
              "1202051     1202052  CERTIFIED-WITHDRAWN   \n",
              "256307       256308            CERTIFIED   \n",
              "2703666     2703667            CERTIFIED   \n",
              "2381440     2381441            CERTIFIED   \n",
              "...             ...                  ...   \n",
              "685279       685280            CERTIFIED   \n",
              "2222065     2222066  CERTIFIED-WITHDRAWN   \n",
              "676130       676131            CERTIFIED   \n",
              "1412936     1412937               DENIED   \n",
              "870012       870013            CERTIFIED   \n",
              "\n",
              "                                            EMPLOYER_NAME  \\\n",
              "1850053   COGNIZANT TECHNOLOGY SOLUTIONS U.S. CORPORATION   \n",
              "1202051                               NEW YORK UNIVERSITY   \n",
              "256307                                    ADALISOFT, INC.   \n",
              "2703666                            MAKRO TECHNOLOGIES INC   \n",
              "2381440                      FOUGERA PHARMACEUTICALS INC.   \n",
              "...                                                   ...   \n",
              "685279                 COGENT HEALTHCARE OF ILLINOIS, LLC   \n",
              "2222065  UT-BATTELLE, LLC (OAK RIDGE NATIONAL LABORATORY)   \n",
              "676130                                      ACCENTURE LLP   \n",
              "1412936                             MOTOROLA MOBILITY LLC   \n",
              "870012                                     LIBERTYCOM LLC   \n",
              "\n",
              "                                             SOC_NAME  \\\n",
              "1850053                     Computer Systems Analysts   \n",
              "1202051     POLITICAL SCIENCE TEACHERS, POSTSECONDARY   \n",
              "256307                           COMPUTER PROGRAMMERS   \n",
              "2703666                          Computer Programmers   \n",
              "2381440    Medical Scientists, Except Epidemiologists   \n",
              "...                                               ...   \n",
              "685279             PHYSICIANS AND SURGEONS, ALL OTHER   \n",
              "2222065  Computer and Information Research Scientists   \n",
              "676130                           COMPUTER PROGRAMMERS   \n",
              "1412936        Architectural and Engineering Managers   \n",
              "870012              SOFTWARE DEVELOPERS, APPLICATIONS   \n",
              "\n",
              "                                                 JOB_TITLE FULL_TIME_POSITION  \\\n",
              "1850053                                       MANAGER JC50                  Y   \n",
              "1202051                 ASSISTANT PROFESSOR/FACULTY FELLOW                  Y   \n",
              "256307                                  PROGRAMMER ANALYST                  N   \n",
              "2703666                                COMPUTER PROGRAMMER                  Y   \n",
              "2381440     SCIENTIST, PHARMACEUTICAL TECHNICAL OPERATIONS                  Y   \n",
              "...                                                    ...                ...   \n",
              "685279                               HOSPITALIST PHYSICIAN                  Y   \n",
              "2222065  POSTDOCTORAL RESEARCH ASSOCIATE IN FUTURE TECH...                  Y   \n",
              "676130                    COMPUTER PROGRAMMER/CONFIGURER 2                  Y   \n",
              "1412936                                    PROJECT MANAGER                  Y   \n",
              "870012                                   SOFTWARE ENGINEER                  Y   \n",
              "\n",
              "         PREVAILING_WAGE    YEAR               WORKSITE         lon        lat  \n",
              "1850053          92206.0  2013.0    TEANECK, NEW JERSEY  -74.011654  40.893247  \n",
              "1202051          38730.0  2015.0     NEW YORK, NEW YORK  -74.005941  40.712784  \n",
              "256307           45011.0  2016.0          IRVING, TEXAS  -96.948894  32.814018  \n",
              "2703666          76793.6  2011.0    GROTON, CONNECTICUT  -72.079072  41.349746  \n",
              "2381440          64979.0  2012.0     MELVILLE, NEW YORK  -73.415121  40.793432  \n",
              "...                  ...     ...                    ...         ...        ...  \n",
              "685279          123281.6  2015.0       NORMAL, ILLINOIS  -88.990631  40.514203  \n",
              "2222065          47819.0  2013.0   OAK RIDGE, TENNESSEE  -84.269645  36.010356  \n",
              "676130           97115.0  2015.0   ISSAQUAH, WASHINGTON -122.032619  47.530101  \n",
              "1412936         134856.0  2014.0  SUNNYVALE, CALIFORNIA -122.036350  37.368830  \n",
              "870012           53768.0  2015.0  LITTLE ROCK, ARKANSAS  -92.289595  34.746481  \n",
              "\n",
              "[10000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b79c07d-4c32-48e6-ab78-d645cee80f74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CASE_STATUS</th>\n",
              "      <th>EMPLOYER_NAME</th>\n",
              "      <th>SOC_NAME</th>\n",
              "      <th>JOB_TITLE</th>\n",
              "      <th>FULL_TIME_POSITION</th>\n",
              "      <th>PREVAILING_WAGE</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>WORKSITE</th>\n",
              "      <th>lon</th>\n",
              "      <th>lat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1850053</th>\n",
              "      <td>1850054</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>COGNIZANT TECHNOLOGY SOLUTIONS U.S. CORPORATION</td>\n",
              "      <td>Computer Systems Analysts</td>\n",
              "      <td>MANAGER JC50</td>\n",
              "      <td>Y</td>\n",
              "      <td>92206.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>TEANECK, NEW JERSEY</td>\n",
              "      <td>-74.011654</td>\n",
              "      <td>40.893247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202051</th>\n",
              "      <td>1202052</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>NEW YORK UNIVERSITY</td>\n",
              "      <td>POLITICAL SCIENCE TEACHERS, POSTSECONDARY</td>\n",
              "      <td>ASSISTANT PROFESSOR/FACULTY FELLOW</td>\n",
              "      <td>Y</td>\n",
              "      <td>38730.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>NEW YORK, NEW YORK</td>\n",
              "      <td>-74.005941</td>\n",
              "      <td>40.712784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256307</th>\n",
              "      <td>256308</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>ADALISOFT, INC.</td>\n",
              "      <td>COMPUTER PROGRAMMERS</td>\n",
              "      <td>PROGRAMMER ANALYST</td>\n",
              "      <td>N</td>\n",
              "      <td>45011.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>IRVING, TEXAS</td>\n",
              "      <td>-96.948894</td>\n",
              "      <td>32.814018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2703666</th>\n",
              "      <td>2703667</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>MAKRO TECHNOLOGIES INC</td>\n",
              "      <td>Computer Programmers</td>\n",
              "      <td>COMPUTER PROGRAMMER</td>\n",
              "      <td>Y</td>\n",
              "      <td>76793.6</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>GROTON, CONNECTICUT</td>\n",
              "      <td>-72.079072</td>\n",
              "      <td>41.349746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2381440</th>\n",
              "      <td>2381441</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>FOUGERA PHARMACEUTICALS INC.</td>\n",
              "      <td>Medical Scientists, Except Epidemiologists</td>\n",
              "      <td>SCIENTIST, PHARMACEUTICAL TECHNICAL OPERATIONS</td>\n",
              "      <td>Y</td>\n",
              "      <td>64979.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>MELVILLE, NEW YORK</td>\n",
              "      <td>-73.415121</td>\n",
              "      <td>40.793432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685279</th>\n",
              "      <td>685280</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>COGENT HEALTHCARE OF ILLINOIS, LLC</td>\n",
              "      <td>PHYSICIANS AND SURGEONS, ALL OTHER</td>\n",
              "      <td>HOSPITALIST PHYSICIAN</td>\n",
              "      <td>Y</td>\n",
              "      <td>123281.6</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>NORMAL, ILLINOIS</td>\n",
              "      <td>-88.990631</td>\n",
              "      <td>40.514203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222065</th>\n",
              "      <td>2222066</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>UT-BATTELLE, LLC (OAK RIDGE NATIONAL LABORATORY)</td>\n",
              "      <td>Computer and Information Research Scientists</td>\n",
              "      <td>POSTDOCTORAL RESEARCH ASSOCIATE IN FUTURE TECH...</td>\n",
              "      <td>Y</td>\n",
              "      <td>47819.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>OAK RIDGE, TENNESSEE</td>\n",
              "      <td>-84.269645</td>\n",
              "      <td>36.010356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676130</th>\n",
              "      <td>676131</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>ACCENTURE LLP</td>\n",
              "      <td>COMPUTER PROGRAMMERS</td>\n",
              "      <td>COMPUTER PROGRAMMER/CONFIGURER 2</td>\n",
              "      <td>Y</td>\n",
              "      <td>97115.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>ISSAQUAH, WASHINGTON</td>\n",
              "      <td>-122.032619</td>\n",
              "      <td>47.530101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1412936</th>\n",
              "      <td>1412937</td>\n",
              "      <td>DENIED</td>\n",
              "      <td>MOTOROLA MOBILITY LLC</td>\n",
              "      <td>Architectural and Engineering Managers</td>\n",
              "      <td>PROJECT MANAGER</td>\n",
              "      <td>Y</td>\n",
              "      <td>134856.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>SUNNYVALE, CALIFORNIA</td>\n",
              "      <td>-122.036350</td>\n",
              "      <td>37.368830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870012</th>\n",
              "      <td>870013</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>LIBERTYCOM LLC</td>\n",
              "      <td>SOFTWARE DEVELOPERS, APPLICATIONS</td>\n",
              "      <td>SOFTWARE ENGINEER</td>\n",
              "      <td>Y</td>\n",
              "      <td>53768.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>LITTLE ROCK, ARKANSAS</td>\n",
              "      <td>-92.289595</td>\n",
              "      <td>34.746481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b79c07d-4c32-48e6-ab78-d645cee80f74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b79c07d-4c32-48e6-ab78-d645cee80f74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b79c07d-4c32-48e6-ab78-d645cee80f74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRE-PROCESSING"
      ],
      "metadata": {
        "id": "5XwZlF3qNlA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_emp = list(df['EMPLOYER_NAME'][df['YEAR'] >= 2015].groupby(df['EMPLOYER_NAME']).count().sort_values(ascending=False).head(10).index)\n",
        "top_emp"
      ],
      "metadata": {
        "id": "1Hu9WQX_LJmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab39a6d-3fdc-4fd8-9c6c-46fb5eb809c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['INFOSYS LIMITED',\n",
              " 'TATA CONSULTANCY SERVICES LIMITED',\n",
              " 'IBM INDIA PRIVATE LIMITED',\n",
              " 'ACCENTURE LLP',\n",
              " 'WIPRO LIMITED',\n",
              " 'CAPGEMINI AMERICA INC',\n",
              " 'DELOITTE CONSULTING LLP',\n",
              " 'ERNST & YOUNG U.S. LLP',\n",
              " 'MICROSOFT CORPORATION',\n",
              " 'GOOGLE INC.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['PREVAILING_WAGE'] <= 500000]\n",
        "by_emp_year = df[['EMPLOYER_NAME', 'YEAR', 'PREVAILING_WAGE']][df['EMPLOYER_NAME'].isin(top_emp)]\n",
        "by_emp_year = by_emp_year.groupby([df['EMPLOYER_NAME'],df['YEAR']])"
      ],
      "metadata": {
        "id": "DVImHsqrNoLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SOC_NAME'] = df['SOC_NAME'].fillna(df['SOC_NAME'].mode()[0])"
      ],
      "metadata": {
        "id": "i0cba2rqNoIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4922cdc0-3f06-4be2-cfdd-73878d49d933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-443ca6b8ad20>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME'] = df['SOC_NAME'].fillna(df['SOC_NAME'].mode()[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "FS3QIZHqaqnU",
        "outputId": "56189a94-52a8-4217-d147-93c2c0d2e6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0          CASE_STATUS  \\\n",
              "1850053     1850054            CERTIFIED   \n",
              "1202051     1202052  CERTIFIED-WITHDRAWN   \n",
              "256307       256308            CERTIFIED   \n",
              "2703666     2703667            CERTIFIED   \n",
              "2381440     2381441            CERTIFIED   \n",
              "...             ...                  ...   \n",
              "685279       685280            CERTIFIED   \n",
              "2222065     2222066  CERTIFIED-WITHDRAWN   \n",
              "676130       676131            CERTIFIED   \n",
              "1412936     1412937               DENIED   \n",
              "870012       870013            CERTIFIED   \n",
              "\n",
              "                                            EMPLOYER_NAME  \\\n",
              "1850053   COGNIZANT TECHNOLOGY SOLUTIONS U.S. CORPORATION   \n",
              "1202051                               NEW YORK UNIVERSITY   \n",
              "256307                                    ADALISOFT, INC.   \n",
              "2703666                            MAKRO TECHNOLOGIES INC   \n",
              "2381440                      FOUGERA PHARMACEUTICALS INC.   \n",
              "...                                                   ...   \n",
              "685279                 COGENT HEALTHCARE OF ILLINOIS, LLC   \n",
              "2222065  UT-BATTELLE, LLC (OAK RIDGE NATIONAL LABORATORY)   \n",
              "676130                                      ACCENTURE LLP   \n",
              "1412936                             MOTOROLA MOBILITY LLC   \n",
              "870012                                     LIBERTYCOM LLC   \n",
              "\n",
              "                                             SOC_NAME  \\\n",
              "1850053                     Computer Systems Analysts   \n",
              "1202051     POLITICAL SCIENCE TEACHERS, POSTSECONDARY   \n",
              "256307                           COMPUTER PROGRAMMERS   \n",
              "2703666                          Computer Programmers   \n",
              "2381440    Medical Scientists, Except Epidemiologists   \n",
              "...                                               ...   \n",
              "685279             PHYSICIANS AND SURGEONS, ALL OTHER   \n",
              "2222065  Computer and Information Research Scientists   \n",
              "676130                           COMPUTER PROGRAMMERS   \n",
              "1412936        Architectural and Engineering Managers   \n",
              "870012              SOFTWARE DEVELOPERS, APPLICATIONS   \n",
              "\n",
              "                                                 JOB_TITLE FULL_TIME_POSITION  \\\n",
              "1850053                                       MANAGER JC50                  Y   \n",
              "1202051                 ASSISTANT PROFESSOR/FACULTY FELLOW                  Y   \n",
              "256307                                  PROGRAMMER ANALYST                  N   \n",
              "2703666                                COMPUTER PROGRAMMER                  Y   \n",
              "2381440     SCIENTIST, PHARMACEUTICAL TECHNICAL OPERATIONS                  Y   \n",
              "...                                                    ...                ...   \n",
              "685279                               HOSPITALIST PHYSICIAN                  Y   \n",
              "2222065  POSTDOCTORAL RESEARCH ASSOCIATE IN FUTURE TECH...                  Y   \n",
              "676130                    COMPUTER PROGRAMMER/CONFIGURER 2                  Y   \n",
              "1412936                                    PROJECT MANAGER                  Y   \n",
              "870012                                   SOFTWARE ENGINEER                  Y   \n",
              "\n",
              "         PREVAILING_WAGE    YEAR               WORKSITE         lon        lat  \n",
              "1850053          92206.0  2013.0    TEANECK, NEW JERSEY  -74.011654  40.893247  \n",
              "1202051          38730.0  2015.0     NEW YORK, NEW YORK  -74.005941  40.712784  \n",
              "256307           45011.0  2016.0          IRVING, TEXAS  -96.948894  32.814018  \n",
              "2703666          76793.6  2011.0    GROTON, CONNECTICUT  -72.079072  41.349746  \n",
              "2381440          64979.0  2012.0     MELVILLE, NEW YORK  -73.415121  40.793432  \n",
              "...                  ...     ...                    ...         ...        ...  \n",
              "685279          123281.6  2015.0       NORMAL, ILLINOIS  -88.990631  40.514203  \n",
              "2222065          47819.0  2013.0   OAK RIDGE, TENNESSEE  -84.269645  36.010356  \n",
              "676130           97115.0  2015.0   ISSAQUAH, WASHINGTON -122.032619  47.530101  \n",
              "1412936         134856.0  2014.0  SUNNYVALE, CALIFORNIA -122.036350  37.368830  \n",
              "870012           53768.0  2015.0  LITTLE ROCK, ARKANSAS  -92.289595  34.746481  \n",
              "\n",
              "[9994 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44941e66-6dcd-433a-802c-a8288d280a93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CASE_STATUS</th>\n",
              "      <th>EMPLOYER_NAME</th>\n",
              "      <th>SOC_NAME</th>\n",
              "      <th>JOB_TITLE</th>\n",
              "      <th>FULL_TIME_POSITION</th>\n",
              "      <th>PREVAILING_WAGE</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>WORKSITE</th>\n",
              "      <th>lon</th>\n",
              "      <th>lat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1850053</th>\n",
              "      <td>1850054</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>COGNIZANT TECHNOLOGY SOLUTIONS U.S. CORPORATION</td>\n",
              "      <td>Computer Systems Analysts</td>\n",
              "      <td>MANAGER JC50</td>\n",
              "      <td>Y</td>\n",
              "      <td>92206.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>TEANECK, NEW JERSEY</td>\n",
              "      <td>-74.011654</td>\n",
              "      <td>40.893247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202051</th>\n",
              "      <td>1202052</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>NEW YORK UNIVERSITY</td>\n",
              "      <td>POLITICAL SCIENCE TEACHERS, POSTSECONDARY</td>\n",
              "      <td>ASSISTANT PROFESSOR/FACULTY FELLOW</td>\n",
              "      <td>Y</td>\n",
              "      <td>38730.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>NEW YORK, NEW YORK</td>\n",
              "      <td>-74.005941</td>\n",
              "      <td>40.712784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256307</th>\n",
              "      <td>256308</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>ADALISOFT, INC.</td>\n",
              "      <td>COMPUTER PROGRAMMERS</td>\n",
              "      <td>PROGRAMMER ANALYST</td>\n",
              "      <td>N</td>\n",
              "      <td>45011.0</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>IRVING, TEXAS</td>\n",
              "      <td>-96.948894</td>\n",
              "      <td>32.814018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2703666</th>\n",
              "      <td>2703667</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>MAKRO TECHNOLOGIES INC</td>\n",
              "      <td>Computer Programmers</td>\n",
              "      <td>COMPUTER PROGRAMMER</td>\n",
              "      <td>Y</td>\n",
              "      <td>76793.6</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>GROTON, CONNECTICUT</td>\n",
              "      <td>-72.079072</td>\n",
              "      <td>41.349746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2381440</th>\n",
              "      <td>2381441</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>FOUGERA PHARMACEUTICALS INC.</td>\n",
              "      <td>Medical Scientists, Except Epidemiologists</td>\n",
              "      <td>SCIENTIST, PHARMACEUTICAL TECHNICAL OPERATIONS</td>\n",
              "      <td>Y</td>\n",
              "      <td>64979.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>MELVILLE, NEW YORK</td>\n",
              "      <td>-73.415121</td>\n",
              "      <td>40.793432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685279</th>\n",
              "      <td>685280</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>COGENT HEALTHCARE OF ILLINOIS, LLC</td>\n",
              "      <td>PHYSICIANS AND SURGEONS, ALL OTHER</td>\n",
              "      <td>HOSPITALIST PHYSICIAN</td>\n",
              "      <td>Y</td>\n",
              "      <td>123281.6</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>NORMAL, ILLINOIS</td>\n",
              "      <td>-88.990631</td>\n",
              "      <td>40.514203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222065</th>\n",
              "      <td>2222066</td>\n",
              "      <td>CERTIFIED-WITHDRAWN</td>\n",
              "      <td>UT-BATTELLE, LLC (OAK RIDGE NATIONAL LABORATORY)</td>\n",
              "      <td>Computer and Information Research Scientists</td>\n",
              "      <td>POSTDOCTORAL RESEARCH ASSOCIATE IN FUTURE TECH...</td>\n",
              "      <td>Y</td>\n",
              "      <td>47819.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>OAK RIDGE, TENNESSEE</td>\n",
              "      <td>-84.269645</td>\n",
              "      <td>36.010356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676130</th>\n",
              "      <td>676131</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>ACCENTURE LLP</td>\n",
              "      <td>COMPUTER PROGRAMMERS</td>\n",
              "      <td>COMPUTER PROGRAMMER/CONFIGURER 2</td>\n",
              "      <td>Y</td>\n",
              "      <td>97115.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>ISSAQUAH, WASHINGTON</td>\n",
              "      <td>-122.032619</td>\n",
              "      <td>47.530101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1412936</th>\n",
              "      <td>1412937</td>\n",
              "      <td>DENIED</td>\n",
              "      <td>MOTOROLA MOBILITY LLC</td>\n",
              "      <td>Architectural and Engineering Managers</td>\n",
              "      <td>PROJECT MANAGER</td>\n",
              "      <td>Y</td>\n",
              "      <td>134856.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>SUNNYVALE, CALIFORNIA</td>\n",
              "      <td>-122.036350</td>\n",
              "      <td>37.368830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870012</th>\n",
              "      <td>870013</td>\n",
              "      <td>CERTIFIED</td>\n",
              "      <td>LIBERTYCOM LLC</td>\n",
              "      <td>SOFTWARE DEVELOPERS, APPLICATIONS</td>\n",
              "      <td>SOFTWARE ENGINEER</td>\n",
              "      <td>Y</td>\n",
              "      <td>53768.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>LITTLE ROCK, ARKANSAS</td>\n",
              "      <td>-92.289595</td>\n",
              "      <td>34.746481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9994 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44941e66-6dcd-433a-802c-a8288d280a93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44941e66-6dcd-433a-802c-a8288d280a93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44941e66-6dcd-433a-802c-a8288d280a93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['CASE_STATUS'] = df['CASE_STATUS'].map({'CERTIFIED' : 0, 'CERTIFIED-WITHDRAWN' : 1, 'DENIED' : 2, 'WITHDRAWN' : 3, \n",
        "                                           'PENDING QUALITY AND COMPLIANCE REVIEW - UNASSIGNED' : 4, 'REJECTED' : 5, 'INVALIDATED' : 6})"
      ],
      "metadata": {
        "id": "kTqLn7TLNoFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490c0c25-ddf7-4ea9-a203-bed8e1b044ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-8b22dfd5a89d>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['CASE_STATUS'] = df['CASE_STATUS'].map({'CERTIFIED' : 0, 'CERTIFIED-WITHDRAWN' : 1, 'DENIED' : 2, 'WITHDRAWN' : 3,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['FULL_TIME_POSITION'] = df['FULL_TIME_POSITION'].map({'N' : 0, 'Y' : 1})"
      ],
      "metadata": {
        "id": "KGe0vYC1NoDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069b4142-1979-4e42-d21c-105c61f14c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4449b2ba6280>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['FULL_TIME_POSITION'] = df['FULL_TIME_POSITION'].map({'N' : 0, 'Y' : 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "df['SOC_NAME1'] = 'others'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('computer|software',case=False)] = 'it'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('chief|management',case=False)] = 'manager'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('mechanical',case=False)] = 'mechanical'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('database|Analyst',case=False)] = 'database'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('sales|market',case=False)] = 'scm'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('financial',case=False)] = 'finance'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('public|fundraising',case=False)] = 'pr'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('education|law',case=False)] = 'administrative'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('auditors|compliance',case=False)] = 'audit'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('distribution|logistics',case=False)] = 'scm'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('recruiters|human',case=False)] = 'hr'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('agricultural|farm',case=False)] = 'agri'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('construction|architectural',case=False)] = 'estate'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('forencsic|health',case=False)] = 'medical'\n",
        "df['SOC_NAME1'][df['SOC_NAME'].str.contains('teachers',case=False)] = 'education'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qQCZ9e4bnCd",
        "outputId": "161a7d7a-18c0-42fc-f710-01315e4ea188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-568e7a368531>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'] = 'others'\n",
            "<ipython-input-11-568e7a368531>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('computer|software',case=False)] = 'it'\n",
            "<ipython-input-11-568e7a368531>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('computer|software',case=False)] = 'it'\n",
            "<ipython-input-11-568e7a368531>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('chief|management',case=False)] = 'manager'\n",
            "<ipython-input-11-568e7a368531>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('chief|management',case=False)] = 'manager'\n",
            "<ipython-input-11-568e7a368531>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('mechanical',case=False)] = 'mechanical'\n",
            "<ipython-input-11-568e7a368531>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('mechanical',case=False)] = 'mechanical'\n",
            "<ipython-input-11-568e7a368531>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('database|Analyst',case=False)] = 'database'\n",
            "<ipython-input-11-568e7a368531>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('database|Analyst',case=False)] = 'database'\n",
            "<ipython-input-11-568e7a368531>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('sales|market',case=False)] = 'scm'\n",
            "<ipython-input-11-568e7a368531>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('sales|market',case=False)] = 'scm'\n",
            "<ipython-input-11-568e7a368531>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('financial',case=False)] = 'finance'\n",
            "<ipython-input-11-568e7a368531>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('financial',case=False)] = 'finance'\n",
            "<ipython-input-11-568e7a368531>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('public|fundraising',case=False)] = 'pr'\n",
            "<ipython-input-11-568e7a368531>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('public|fundraising',case=False)] = 'pr'\n",
            "<ipython-input-11-568e7a368531>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('education|law',case=False)] = 'administrative'\n",
            "<ipython-input-11-568e7a368531>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('education|law',case=False)] = 'administrative'\n",
            "<ipython-input-11-568e7a368531>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('auditors|compliance',case=False)] = 'audit'\n",
            "<ipython-input-11-568e7a368531>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('auditors|compliance',case=False)] = 'audit'\n",
            "<ipython-input-11-568e7a368531>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('distribution|logistics',case=False)] = 'scm'\n",
            "<ipython-input-11-568e7a368531>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('distribution|logistics',case=False)] = 'scm'\n",
            "<ipython-input-11-568e7a368531>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('recruiters|human',case=False)] = 'hr'\n",
            "<ipython-input-11-568e7a368531>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('recruiters|human',case=False)] = 'hr'\n",
            "<ipython-input-11-568e7a368531>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('agricultural|farm',case=False)] = 'agri'\n",
            "<ipython-input-11-568e7a368531>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('agricultural|farm',case=False)] = 'agri'\n",
            "<ipython-input-11-568e7a368531>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('construction|architectural',case=False)] = 'estate'\n",
            "<ipython-input-11-568e7a368531>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('construction|architectural',case=False)] = 'estate'\n",
            "<ipython-input-11-568e7a368531>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('forencsic|health',case=False)] = 'medical'\n",
            "<ipython-input-11-568e7a368531>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('forencsic|health',case=False)] = 'medical'\n",
            "<ipython-input-11-568e7a368531>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('teachers',case=False)] = 'education'\n",
            "<ipython-input-11-568e7a368531>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['SOC_NAME1'][df['SOC_NAME'].str.contains('teachers',case=False)] = 'education'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Unnamed: 0', 'EMPLOYER_NAME', 'SOC_NAME','JOB_TITLE','WORKSITE', 'lon','lat'], axis = 1)\n"
      ],
      "metadata": {
        "id": "1pI2NxRANn92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df.SOC_NAME1)\n",
        "# print list(le.classes_)\n",
        "df['SOC_N']=le.transform(df['SOC_NAME1'])"
      ],
      "metadata": {
        "id": "q7NsezUNN56j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['SOC_NAME1'], axis=1)"
      ],
      "metadata": {
        "id": "mWmT9bRUN528"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPLYING TABULAR GANS"
      ],
      "metadata": {
        "id": "Sah6efs1OPOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HIDE OUTPUT\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "\n",
        "COLS_USED = ['CASE_STATUS', 'FULL_TIME_POSITION', 'PREVAILING_WAGE', 'YEAR',\n",
        "       'SOC_N']\n",
        "COLS_TRAIN = ['FULL_TIME_POSITION', 'PREVAILING_WAGE', 'YEAR',\n",
        "       'SOC_N']\n",
        "\n",
        "df = df[COLS_USED]\n",
        "\n",
        "# Split into training and test sets\n",
        "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(\n",
        "    df.drop(\"CASE_STATUS\", axis=1),\n",
        "    df[\"CASE_STATUS\"],\n",
        "    test_size=0.20,\n",
        "    #shuffle=False,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# Create dataframe versions for tabular GAN\n",
        "df_x_test, df_y_test = df_x_test.reset_index(drop=True), \\\n",
        "  df_y_test.reset_index(drop=True)\n",
        "df_y_train = pd.DataFrame(df_y_train)\n",
        "df_y_test = pd.DataFrame(df_y_test)\n",
        "\n",
        "# Pandas to Numpy\n",
        "x_train = df_x_train.values\n",
        "x_test = df_x_test.values\n",
        "y_train = df_y_train.values\n",
        "y_test = df_y_test.values\n"
      ],
      "metadata": {
        "id": "qemUGR_U0XBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network\n",
        "model = Sequential()\n",
        "# Hidden 1\n",
        "model.add(Dense(50, input_dim=x_train.shape[1], activation='relu')) \n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(12, activation='relu')) # Hidden 3\n",
        "model.add(Dense(1)) # Output\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=5, verbose=1, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "        callbacks=[monitor], verbose=2,epochs=1000)"
      ],
      "metadata": {
        "id": "l8Pnn4dC0W9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97f0c92-f793-48a8-c5dd-752edb3f3758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "250/250 - 4s - loss: 1108869.1250 - val_loss: 5989.3931 - 4s/epoch - 17ms/step\n",
            "Epoch 2/1000\n",
            "250/250 - 2s - loss: 4836.1084 - val_loss: 4220.8486 - 2s/epoch - 6ms/step\n",
            "Epoch 3/1000\n",
            "250/250 - 2s - loss: 3286.5107 - val_loss: 2938.4939 - 2s/epoch - 7ms/step\n",
            "Epoch 4/1000\n",
            "250/250 - 2s - loss: 1860.7419 - val_loss: 1443.0402 - 2s/epoch - 7ms/step\n",
            "Epoch 5/1000\n",
            "250/250 - 2s - loss: 966.3812 - val_loss: 660.3069 - 2s/epoch - 6ms/step\n",
            "Epoch 6/1000\n",
            "250/250 - 1s - loss: 417.2041 - val_loss: 266.0686 - 1s/epoch - 6ms/step\n",
            "Epoch 7/1000\n",
            "250/250 - 2s - loss: 182.4713 - val_loss: 125.6804 - 2s/epoch - 7ms/step\n",
            "Epoch 8/1000\n",
            "250/250 - 1s - loss: 54.4471 - val_loss: 31.1705 - 1s/epoch - 5ms/step\n",
            "Epoch 9/1000\n",
            "250/250 - 1s - loss: 16.9839 - val_loss: 7.4403 - 795ms/epoch - 3ms/step\n",
            "Epoch 10/1000\n",
            "250/250 - 1s - loss: 4.6554 - val_loss: 2.6037 - 877ms/epoch - 4ms/step\n",
            "Epoch 11/1000\n",
            "250/250 - 1s - loss: 2.3374 - val_loss: 1.5921 - 782ms/epoch - 3ms/step\n",
            "Epoch 12/1000\n",
            "250/250 - 1s - loss: 1.6336 - val_loss: 1.6135 - 842ms/epoch - 3ms/step\n",
            "Epoch 13/1000\n",
            "250/250 - 1s - loss: 1.6204 - val_loss: 1.3880 - 1s/epoch - 5ms/step\n",
            "Epoch 14/1000\n",
            "250/250 - 1s - loss: 1.5772 - val_loss: 1.3333 - 1s/epoch - 5ms/step\n",
            "Epoch 15/1000\n",
            "250/250 - 1s - loss: 1.5286 - val_loss: 1.3129 - 1s/epoch - 4ms/step\n",
            "Epoch 16/1000\n",
            "250/250 - 1s - loss: 1.4784 - val_loss: 2.0726 - 841ms/epoch - 3ms/step\n",
            "Epoch 17/1000\n",
            "250/250 - 1s - loss: 1.7486 - val_loss: 1.2483 - 805ms/epoch - 3ms/step\n",
            "Epoch 18/1000\n",
            "250/250 - 1s - loss: 1.5213 - val_loss: 2.5705 - 796ms/epoch - 3ms/step\n",
            "Epoch 19/1000\n",
            "250/250 - 1s - loss: 1.7332 - val_loss: 1.4613 - 788ms/epoch - 3ms/step\n",
            "Epoch 20/1000\n",
            "250/250 - 1s - loss: 1.7944 - val_loss: 1.1252 - 853ms/epoch - 3ms/step\n",
            "Epoch 21/1000\n",
            "250/250 - 1s - loss: 11.0556 - val_loss: 1.3741 - 807ms/epoch - 3ms/step\n",
            "Epoch 22/1000\n",
            "250/250 - 1s - loss: 5.8003 - val_loss: 67.0665 - 832ms/epoch - 3ms/step\n",
            "Epoch 23/1000\n",
            "250/250 - 1s - loss: 69.2551 - val_loss: 106.7093 - 799ms/epoch - 3ms/step\n",
            "Epoch 24/1000\n",
            "250/250 - 1s - loss: 2608.4028 - val_loss: 1364.7849 - 811ms/epoch - 3ms/step\n",
            "Epoch 25/1000\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "250/250 - 1s - loss: 45.0528 - val_loss: 1.3949 - 817ms/epoch - 3ms/step\n",
            "Epoch 25: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9fa020f0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuAkDPCrKkQd",
        "outputId": "564e7396-c9f1-4f06-be86-f989c26c3c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 50)                250       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                312       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,850\n",
            "Trainable params: 1,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "WaxHv9W-LaEk",
        "outputId": "ce792190-3cd2-4ebf-ac0e-e202b072e438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASkAAAIECAIAAADKIU+gAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVwT974//s9A9pCwyCqIsqhUQK3VHkC82EsPrXoAEResaNVLi9aWouihiFJEcClWuFi4PSrl3GqvgMADl4Jt1YO9PERrrygUviqggEoRVCBAwpr5/TG/zslhCUlI8knw/fzLzPKZz8zkZWZj3gRJkggAoHUGuDsAwCsKsgcAHpA9APCA7AGAB0P2Q1lZ2dGjR3F1BYCJzdPTc8eOHfTHf/nde/z4cV5enta7NAHl5eU9efIEdy804saNGzdu3MDdC/1z48aNsrIy2SGM4ROdPXtWW/2ZsAiC2L59++rVq3F3RP1WrVqF4EuiPGq7yYLzPQDwgOwBgAdkDwA8IHsA4AHZAwCP8WYvLCxMIBAQBHHnzh21dEhlRUVFxsbGFy5cwNsNlel7/4fYsmUL8YfQ0FDZUZcvX46JicnPz3d0dKQmWL9+vewEfn5+AoHA0NDQ1dX19u3b2u34P/X09Li4uOzZswchdP78+cOHDw8ODtJjCwsL6RU0NzdXof3xZu/kyZMnTpwYZyNqoe9/kKHv/R/OzMysuLj4/v37mZmZ9MDPP/88LS1t9+7dwcHBDx8+dHJymjRp0unTp7///nt6mh9//PHs2bP+/v5VVVXz5s3D0XeEEIqNjb1//z7174CAAA6H4+vr297eTg0JDAx88uTJzz//vHTpUtXanzjHnMuWLevo6PD399dQ+xKJxMvLS0ONI/3v/3BcLvfdd9+dMWMGm82mhhw6dCg7Ozs3N1cgENCTpaWlGRgYhIeHd3R0aLN78l2/fv23336THfLpp5/OmTNn6dKlAwMDCCGCIGxtbRctWjR9+nTVFqGG7BEEMf5GdF9mZmZLSwvuXqgOe/9ra2v37t27b98+DocjO9zLyysyMvLp06c7d+7E1bchJBLJrl27UlNThwyPj4+/c+fO8OGqUSV7JEkmJyfPnDmTzWYbGxvv2rWLHjU4OBgXF2dvb8/lcmfPnp2Tk4MQysjI4PP5PB7v3LlzS5YsEQqFdnZ2Z86coWa5du3am2++yePxhEKhu7u7SCQarR05SktL7e3tCYL46quv5C8xLS2Nw+FYWlpu2bLFxsaGw+F4eXndvHkTIRQREcFisaytrak2t23bxufzCYJ4/vx5ZGRkVFRUXV0dQRDOzs4qbDRd6/+lS5eEQmFSUpLa12U0aWlpJEkGBAQMH5WYmDhjxoyTJ09evnx5+FiSJI8ePfraa6+x2WxTU9Ply5ffu3cPjfW9UvYrJCs2Nnbbtm0WFhZDhpuamvr4+KSmpqrnBIGUQfWPHEtsbCxBEF9++WVbW5tYLE5PT0cIlZeXkyS5c+dONpudl5fX1ta2e/duAwODW7duUbMghK5cudLR0dHS0rJo0SI+n9/X19fV1SUUCg8fPiyRSJqbm1esWNHa2iqnHTkeP36MEDp27BjdyRGXSJJkeHg4n8+vrq7u6empqqpasGCBQCBobGwkSXLdunVWVlZ0m8nJyQghqkvBwcFOTk5jbhwKQignJ0fBibH0/+LFiwKBICEhQalOkiS5cuXKlStXjjlZeHi4ra2t7BBHR8dZs2YNmczJyenRo0ckSV6/ft3AwGDatGldXV0kSRYXFwcGBlLTxMXFsVisU6dOtbe3V1RUzJs3z9zcvLm5Wf5WUuErRCktLQ0ICCBJsrW1lcqh7NiYmBj620759NNPJ02aNGazw7eb0r97EokkJSXl7bff3rFjh4mJCZfLNTMzo0b19PRkZGQEBQUFBwebmJjs2bOHyWRmZWXR83p5eQmFQgsLi5CQkO7u7sbGxvr6epFI5OrqyuFwrKys8vPzzc3Nx2xHccOXSA1nMBjU/6OzZs3KyMjo7OxUrX1N01z/ly1bJhKJ9u7dq4Fej6C7u/vRo0dOTk6jTeDp6bl9+/b6+vrPPvtMdrhEIjl69OiKFStCQ0ONjY3d3d2//vrr58+fHz9+nJ5m+FZS+SskkUgiIyMzMjJGm4A6u6usrFRoteVSOnu1tbVisdjX13f4qPv374vFYjc3N+ojl8u1tramDg+GYLFYCKH+/n5HR0dLS8vQ0ND4+Pj6+npl21EcvcTho+bPn8/j8cbZvqbpe/9bWlpIkuTxeHKmSUxMnDlzZnp6emlpKT2wqqqqq6tr/vz59JAFCxawWCzqMHsIeiup/BXavXv3hx9+aGtrO9oE1Co8e/ZszKbGpHT2qD+NGX4ojBDq7u5GCO3Zs4e+79HQ0CAWi+W0xuVyr1696u3tnZSU5OjoGBISIpFIVGhnnNhsNnWAoad0v/89PT0IIfqC54g4HE5WVhZBEJs3b5ZIJNRA6pq+kZGR7JQmJiadnZ1ymlLtK1RaWlpZWRkWFiZnGi6XS6/OOCmdPeoiVW9v7/BRVCBTUlJkD2qH/M3ScK6urhcuXGhqaoqOjs7JyTly5Ihq7aisv7+/vb3dzs5OQ+1rml70n/rKyt6bHhH116U1NTX79++nhpiYmCCEhiRtzPVV7SuUmZl55coVAwMDKq5UI0lJSQRB/Prrr9Q0fX199OqMk9LZc3NzMzAwuHbt2vBRU6ZM4XA4Sj3g0tTUVF1djRCysLA4ePDgvHnzqqurVWhnPEpKSkiS9PDwQAgxGIwRj+t0mV7039LSkiAIRe7g7d+/38XFpby8nPro5uZmZGREf/URQjdv3uzr63vjjTfkNKLaVygrK0s2q7LXWuiDXmoVrKyslGp5REpnz8LCIjg4OC8vLzMzUyQSVVRU0Ge9HA5n06ZNZ86cycjIEIlEg4ODT548+f333+W01tTUtGXLlnv37vX19ZWXlzc0NHh4eKjQjrKkUmlbW9vAwEBFRUVkZKS9vf3GjRsRQs7Ozi9fviwsLOzv729tbW1oaKBnMTMza2pqqq+v7+zsxP79Hn//i4uLtXmPgcfjOTo6KvK3/NSRp6GhIf0xKiqqoKDg9OnTIpGosrJy69atNjY24eHh8hsZ7SsUEhJiZWWl8qNq1Cq4u7urNvu/kA26gvcYOjs7w8LCJk2aZGRk5O3tHRcXhxCys7O7e/dub29vdHS0vb09g8GgUlpVVZWenk6doU6fPr2uru748eNCoRAhNHXq1J9++snLy8vU1NTQ0HDy5MmxsbEDAwMkSY7YjpwuHTt2jLqvxePxAgIC5CzxwYMH4eHhTCbT1taWwWAIhcLly5fX1dVR7bx48eKtt97icDgODg6ffPIJdevS2dm5sbHx9u3bU6dO5XK53t7e1AVuOZCS9xi03/+ioiKBQJCYmKh4Jykq32OIiIhgMplisZj6WFBQQF32NDc3//jjj4fMvmvXLvoeg1QqTU5Onj59OpPJNDU1DQoKun//PkmS8rfSaF+hoKAghFBcXNyYqzDiPYZly5bZ2tpKpVJ6iMr3GFTJnr4LDw83MzPT6CKUzZ5StNB/OVTOXk1NDYPBOHXqlMa6ppDBwcFFixZlZmaqMO/z5885HM6RI0dkB2rv/t7EMOZJv47Ti/5LJJIffvihpqaGuj7h7OyckJCQkJDQ1dWFq0uDg4OFhYWdnZ0hISEqzB4fHz937tyIiAiEEEmSTU1NpaWltbW1qnVGb7J37949YnSqbUqgUS9fvqSepd68eTM1JCYmZtWqVSEhIbgemy4pKcnPzy8uLpZ/p3FER48evXPnTlFREZPJRAidO3eOepZa9i8wlCP7I/gqHHPGxMRQd2CnTZt29uxZDS0FaeyYUzv9l0PBY045fvjhh+joaHX1RzsKCwsPHDhAXYxQzfDtRpAyT4Xm5uauWbOGnHB/SKZ9BEHk5OTAOwIBbfh205tjTgAmGMgeAHhA9gDAA7IHAB6QPQAwkb3oqdTf1QMAlDLkHsMIdYgggeO3Zs2ayMhIT09P3B1Rv5SUFITQ9u3bcXdEz1DbTdYI2ZuQd6W0bM2aNZ6enhNyS1J3qCbkqmnU8DuicL4HAB6QPQDwgOwBgAdkDwA8IHsA4KF69m7cuPHaa69RL3WysrJKTExUY7dGJFs1ytraekhlKaBToAbY2IbfW1fqr5LeeecdhFBbW5tSc42Hk5OTsbGx1hanGqTJd0bgpfg7I+gaYD09PfTwuLg4f39/kUhEfaRqgCGELl68KDu77DvhcdmxYweSeV9Lamqqj48P/VWXSqV0DbCJ+c4I7Veu0nFq2SDa2apQA0w+Xc8e9spVukYtGwTLVoUaYEOoM3u6UHnrf//3f2fNmmVsbMzhcNzd3X/44QeEUFhYGHVc7uTkRL10ddOmTTwez9jY+Pz58yMWi/riiy94PJ5AIGhpaYmKirK1taVLkKoLOUppK8U3iH7VA4MaYCOsGG3853taqLwl/3zv7Nmz8fHxL1++fPHihYeHB30gHhwcbGho+PTpU3rK99577/z58+RYdcs+/fTTY8eOrVix4v/9v/+n+GZBCpzvySltpfgG0X49MKgBhnDVAFMExspbK1eu/Pzzz01NTc3MzAICAl68eEFtwa1btw4ODtKLE4lEt27dWrp06ZjFog4dOvTxxx/n5+e7uLiosZ+KlLZSkF7UA4MaYMNp9nwPb+Uq6l1u1HXhf//3f58xY8Y333xDkiRCKDs7OyQkxNDQUBP1xhShVGkrxelsPTCoATYczmstmqhc9f333y9evNjCwoLNZv/1r3+lhxMEsWXLlocPH165cgUh9O233/7Hf/wHUrVY1PipVtpKEbpZDwxqgA2HLXvqrVz1888/p6SkNDY2BgUFWVtb37x5s6Oj4/Dhw7LTbNy4kcPhnDx58v79+0KhcOrUqUjVYlHjp1ppqzHpbD0wqAE2HLbsqbdy1f/93//x+fzKysr+/v6PPvrI0dGRw+EQBCE7jamp6Zo1awoLC48cOfLBBx9QA7Vcb4wmv7SVyhtEZ+uBQQ2w4bSaPU1U3urv73/27FlJSQmfz7e3t0cIXb58uaenp6amZvgpwdatW3t7ey9evOjv708N0UK9sRHJL22l1AbRi3pgUANsBLJBV+oew40bN1xdXQ0MDBBC1tbWSUlJmq5c9V//9V9yLpQVFBSQJBkdHW1mZmZiYrJq1aqvvvoKIeTk5ERdc6e8/vrrMTExsisyYrGow4cPU8cVU6ZMUaF0DlLgHsNopa0U3yDNzc3arwcGNcD0rwYY3spVtKVLlz58+FDTS1Eke2qh/a0KNcD0sgYYrspV9MFqRUUF9TuApRsaorP1wKAGmHy6/jynWkRHR9fU1Dx48GDTpk30BTSgaVADbAyyP4KaO+bEW7kqNjbWwMBgypQp1ENkWoC0csyJZatCDTDVQA0wLYEaYGAIqAEGgK6A7AGAB2QPADwgewDgMUI9htzcXO33Y+LRwgPZWFAPVcGXRFlPnjwZ+vy37EVPqEAEgObIu8cA9MsEvpPxKoDzPQDwgOwBgAdkDwA8IHsA4AHZAwAPyB4AeED2AMADsgcAHpA9APCA7AGAB2QPADwgewDgAdkDAA/IHgB4QPYAwAOyBwAekD0A8IDsAYAHZA8APCB7AOAB2QMAD8geAHhA9gDAA7IHAB6QPQDwgOwBgAdkDwA8IHsA4AHZAwAPyB4AeED2AMADsgcAHpA9APAYod460FknTpx4+fKl7JBz5849evSI/rhp0yZLS0ut9wuoAmo+65MtW7b87W9/Y7PZw0f19/ebmpo2NzczGPD/qX6AY059snbtWoRQ70gMDQ3fe+89CJ4egd89fUKSpK2t7e+//z7i2OvXr3t6emq5S0Bl8LunTwiCWLduHYvFGj5q8uTJHh4e2u8SUBlkT8+sXbu2r69vyEAWi/X+++8TBIGlS0A1cMypf6ZPn15bWztkYEVFhbu7O5b+ANXA757+CQ0NZTKZskOcnZ0heHoHsqd/QkNDBwYG6I9MJnPTpk0Y+wNUA8ecemnu3LkVFRXUviMIoq6uzsHBAXengHLgd08vbdiwwdDQECFEEMQbb7wBwdNHkD29tHbtWqlUihAyNDTcsGED7u4AVUD29JKNjc3ChQsJgpBKpatWrcLdHaAKyJ6+Wr9+PUmSixcvtra2xt0XoBJS3VauXIl7nQBQP7UnRSOP3np4eGzfvl0TLWvTmjVrIiMjdfkJyZSUlA8//JDP56swI0JoAuwj7SgrK0tNTVV7sxrJnp2d3erVqzXRsjatWbPG09NTl1fE29t78uTJKsx49uxZhJAur5qu0UT24HxPj6kWPKAjIHsA4AHZAwAPyB4AeED2AMBDh7IXFhYmEAgIgrhz5w7uvqioqKjI2Nj4woULuDuiQZcvX46JicnPz3d0dCQIgiCI9evXy07g5+cnEAgMDQ1dXV1v376Nq589PT0uLi579uxBCJ0/f/7w4cODg4O4OjMiHcreyZMnT5w4gbsX40JO9D8K+fzzz9PS0nbv3h0cHPzw4UMnJ6dJkyadPn36+++/p6f58ccfz5496+/vX1VVNW/ePFxdjY2NvX//PvXvgIAADofj6+vb3t6Oqz/D6VD2JoBly5Z1dHT4+/trqH2JROLl5aWhxsd06NCh7Ozs3NxcgUBAD0xLSzMwMAgPD+/o6MDVseGuX7/+22+/yQ759NNP58yZs3TpUtk/fcRLt7IHbxyRLzMzs6WlBcuia2tr9+7du2/fPg6HIzvcy8srMjLy6dOnO3fuxNKx4SQSya5du4bfDY+Pj79z544m7pKrBnP2SJJMTk6eOXMmm802NjbetWsXPWpwcDAuLs7e3p7L5c6ePTsnJwchlJGRwefzeTzeuXPnlixZIhQK7ezszpw5Q81y7dq1N998k8fjCYVCd3d3kUg0WjuaUFpaam9vTxDEV199Jb+raWlpHA7H0tJyy5YtNjY2HA7Hy8vr5s2bCKGIiAgWi0U/Hr1t2zY+n08QxPPnzyMjI6Oiourq6giCcHZ2RghdunRJKBQmJSVpaI1kpaWlkSQZEBAwfFRiYuKMGTNOnjx5+fLl4WNJkjx69Ohrr73GZrNNTU2XL19+7949NNauHM9ei42N3bZtm4WFxZDhpqamPj4+qampunJqoPYnRFeuXLly5UoFJ46NjSUI4ssvv2xraxOLxenp6Qih8vJykiR37tzJZrPz8vLa2tp2795tYGBw69YtahaE0JUrVzo6OlpaWhYtWsTn8/v6+rq6uoRC4eHDhyUSSXNz84oVK1pbW+W0MyaEUE5OjlLr/vjxY4TQsWPH6LUbsaskSYaHh/P5/Orq6p6enqqqqgULFggEgsbGRpIk161bZ2VlRbeZnJyMEKLWJTg42MnJiR518eJFgUCQkJCgVCdJJfcRxdHRcdasWUMGOjk5PXr0iCTJ69evGxgYTJs2rauriyTJ4uLiwMBAapq4uDgWi3Xq1Kn29vaKiop58+aZm5s3NzfL3z4q77XS0tKAgACSJFtbWxFCsbGxsmNjYmLoL5jiqOQrNYsicP7uSSSSlJSUt99+e8eOHSYmJlwu18zMjBrV09OTkZERFBQUHBxsYmKyZ88eJpOZlZVFz+vl5SUUCi0sLEJCQrq7uxsbG+vr60UikaurK4fDsbKyys/PNzc3H7MdLRjeVWo4g8Ggfg1mzZqVkZHR2dmpbMeWLVsmEon27t2rgV7/i+7u7kePHjk5OY02gaen5/bt2+vr6z/77DPZ4RKJ5OjRoytWrAgNDTU2NnZ3d//666+fP39+/Phxeprh20flvSaRSCIjIzMyMkabYPr06QihyspKhVZbw3Bmr7a2ViwW+/r6Dh91//59sVjs5uZGfeRyudbW1tSxyhDUi2L7+/sdHR0tLS1DQ0Pj4+Pr6+uVbUcL6K4OHzV//nwej4erY2NqaWkhSZLH48mZJjExcebMmenp6aWlpfTAqqqqrq6u+fPn00MWLFjAYrGoA+wh6O2j8l7bvXv3hx9+aGtrO9oE1Co8e/ZszKa0AGf2njx5ghAaflyOEOru7kYI7dmzh/hDQ0ODWCyW0xqXy7169aq3t3dSUpKjo2NISIhEIlGhHVzYbDZ1mKSDenp6EEIj1mChcTicrKwsgiA2b94skUiogdQ1fSMjI9kpTUxMOjs75TSl2l4rLS2trKwMCwuTMw2Xy6VXBzuc2aOumPX29g4fRQUyJSVF9vi4rKxMfoOurq4XLlxoamqKjo7Oyck5cuSIau1oX39/f3t7u52dHe6OjIz6yo55b9rT03PHjh01NTX79++nhpiYmCCEhiRtzDVVba9lZmZeuXLFwMCAiivVSFJSEkEQv/76KzUN9UpvanWww5k9Nzc3AwODa9euDR81ZcoUDoej1AMuTU1N1dXVCCELC4uDBw/OmzevurpahXawKCkpIUmSKqjAYDBGPC7FyNLSkiAIRe7g7d+/38XFpby8nPro5uZmZGREf/URQjdv3uzr63vjjTfkNKLaXsvKypLNquy1Fvqgl1oFKysrpVrWEJzZs7CwCA4OzsvLy8zMFIlEFRUV9Ck4h8PZtGnTmTNnMjIyRCLR4ODgkydPRqu/Q2lqatqyZcu9e/f6+vrKy8sbGho8PDxUaEdrpFJpW1vbwMBARUVFZGSkvb39xo0bEULOzs4vX74sLCzs7+9vbW1taGigZzEzM2tqaqqvr+/s7Ozv7y8uLtbOPQYej+fo6EidI8hHHXlS7y+kPkZFRRUUFJw+fVokElVWVm7dutXGxiY8PFx+I6PttZCQECsrK5UfVaNWQVfe4a32K6dKXb/u7OwMCwubNGmSkZGRt7d3XFwcQsjOzu7u3bu9vb3R0dH29vYMBoNKaVVVVXp6OnW6PH369Lq6uuPHjwuFQoTQ1KlTf/rpJy8vL1NTU0NDw8mTJ8fGxg4MDJAkOWI7ivQNKXmP4dixY9R9OR6PFxAQIKerDx48CA8PZzKZtra2DAZDKBQuX768rq6OaufFixdvvfUWh8NxcHD45JNPqHuezs7OjY2Nt2/fnjp1KpfL9fb2bm5uLioqEggEiYmJineSosI9hoiICCaTKRaLqY8FBQXUZU9zc/OPP/54yMS7du2i7zFIpdLk5OTp06czmUxTU9OgoKD79++TJCl/+4y214KCghBCcXFxY3Z4xHsMy5Yts7W1lUqlSq27hu4xYM6eLlM2e0oJDw83MzPTUONjUmEf1dTUMBiMU6dOaahLChocHFy0aFFmZqYK8z5//pzD4Rw5ckTZGSfg/b1XnK49Vi+fs7NzQkJCQkJCV1cXrj4MDg4WFhZ2dnaGhISoMHt8fPzcuXMjIiLU3jHVQPaAomJiYlatWhUSEoLrsemSkpL8/Pzi4mL5dxpHdPTo0Tt37hQVFQ0p4YQRZA+D3bt3Z2VldXR0ODg45OXl4e6OEpKSkiIiIg4ePIhl6b6+vt99950K7wI+d+5cb29vSUmJqampJjqmGo28IxDId+DAgQMHDuDuhYr8/Pz8/Pxw90I5gYGBgYGBuHsxFPzuAYAHZA8APCB7AOAB2QMAD41ca3ny5Elubq4mWtYyHXzqWi2oR6smxj7SAk19DdR+tx5qgIEJSe1J0cgxJzxTpuMmzHN/2qGhd/zA+R4AeED2AMADsgcAHpA9APCA7AGAB2QPADzwZE+2ghSFxWJZWlouXrw4OTm5ra0NS6/AaHS57ldiYiLxr+gXeyKESktLFy5cyOPxbGxsoqOjqZfi6UhJMDzZoytIGRsbkyQplUpbWlpyc3MdHByio6NdXV1l32wF8NKjul9DVFVV+fn5+fr6tra2FhQUfPPNN1u3bkU6UxJMJ445CYIwMTFZvHhxVlZWbm7us2fPqGJauPulKWop5aWdemB6UfdryFtk6Opf+/fvt7a23rdvH5/P9/T0jI6O/vvf/06931oXSoLpRPZkrVy5cuPGjS0tLV9//TXuvmiKWkp5aaEemB7V/RpuYGDg+++/9/HxoQvLLVmyhCTJc+fOUR+xlwTTuewhhKjXVBYXFyOdrwRGjlLgSvFSXrpcD0yP6n4N9/Dhw66uLnt7e3oI9VLDiooK6iP+kmBqf/hN8WcF6fO9Iai0TJkyhcRaCQwp8DynnAJXipfy0n49MAX3kV7U/dq/f7+dnZ2JiQmTyZw2bVpgYOAvv/xCkiT1vvPk5GTZiblcrq+vL/1RwZJgr9A7AgUCAUEQnZ2dOl4JTJECVwrSwXpg+lL36/333z9//vzjx4+7urrOnDnT2Njo4+NTVVVFXdKk35BNYTKZdJ0WhLskmC5mr7u7myRJoVCo45XAlCpwpTgdqQemL3W/pkyZ8vrrrxsZGbFYLA8Pj6ysLIlEkp6eTp2jDrmU0tfXJ1sIBW9JMF3M3oMHDxBCLi4uOl4JTLUCV4rQhXpgelH3azh3d3dDQ8MHDx5Q58nU+QtFLBb39PTY2NjQQ/CWBNPF7F26dAkhtGTJEh2vBKZagasx6Ug9ML2o+zWcVCqVSqVsNtvBwUEgEMhWkqmtrUUIzZ49mx6CtySYzmWvubk5JSXFzs5u8+bNOl4JTH6BK5VLeelIPTC9qPuFEHrnnXdkP1KXZzw9PRkMxtKlS3/++WepVEqNKi4uJghC9rIt3pJgmLNHkmRXVxdVF6a1tTUnJ2fhwoWGhoaFhYVCoVDHK4HJL3CleCkvpJP1wPSl7tfTp0+zs7Pb29v7+/vLysrCwsLs7e2p51f27t377Nmzzz//vLu7u6ysLDk5eePGjTNnzqTnxVwSTO1XThW5fn3+/PnZs2fzeDwWi2VgYID+eLTlzTffTEhIePHiBT0lxkpgSIF7DKMVuCKVKeWl/XpgCt5j0Iu6X1FRUU5OTnw+n8Fg2NnZffDBB01NTfRY6mYvm822sbHZtWtXT0+P7LwKlgSDGmDapkj21EL79cAU3EcToO6XHIqXBHuF7u+9grA/Uz+iCVD3Sw7sJcEge0Aeva77JYculASD7GGm+/XA9LTulxw6UhIMaoBhphf1wPSx7pccOlISDH73AMADsgcAHpA9APCA7AGAh0autdy4cWPVqlWaaFnLUlJSzp49i7sX6hAS2k0AACAASURBVHfjxg2E0MTYR1qgyIN1KiBIdf/B/NGjRydq2Tpdc+XKFTc3N1yPAr9q1P6/sPqzB7SGIIicnJzVq1fj7ghQBZzvAYAHZA8APCB7AOAB2QMAD8geAHhA9gDAA7IHAB6QPQDwgOwBgAdkDwA8IHsA4AHZAwAPyB4AeED2AMADsgcAHpA9APCA7AGAB2QPADwgewDgAdkDAA/IHgB4QPYAwAOyBwAekD0A8IDsAYAHZA8APCB7AOAB2QMAD8geAHhA9gDAA7IHAB6QPQDwgOwBgAfUndUnGzZsKC8vpz8+fvx40qRJPB6P+shkMi9evDh58mRMvQPKYeDuAFDCzJkzT506JTuko6OD/vesWbMgeHoEjjn1SWhoKEEQI45iMpkbN27UbnfAuMAxp56ZP3/+7du3h+81giAePnw4bdo0HJ0CqoDfPT2zYcMGQ0PDIQMNDAw8PDwgePoFsqdnQkJCpFLpkIEGBgYbNmzA0h+gMsienrG0tPTx8Rny00eS5IoVK3B1CagGsqd/1q9fL3u+Z2ho+Pbbb1taWmLsElABZE//BAcHMxj/vDlEkmRoaCjG/gDVQPb0j1AoXLJkCR0/BoMREBCAt0tABZA9vRQaGjo4OIgQYjAYgYGBQqEQd4+A0iB7eukvf/kL9SjZ4ODgunXrcHcHqAKyp5c4HE5wcDBCiM/nv/vuu7i7A1Qxruc5c3Nz1dUPoCw7OzuE0IIFC86dO4e7L68uLy8vakeoghwHta4FAPonJydH5fiM95hzPMvWRytXrly5ciXuXvz/EhMTBwYG1NVaTk4OGt//xa+acWYHzvf0WHR09PBnO4G+gOzpMdk77EDvQPYAwAOyBwAekD0A8IDsAYCHVrMXFhYmEAgIgrhz5442lzsaqVSakpLi5eWl0aUUFRUZGxtfuHBBo0vRvsuXL8fExOTn5zs6OhIEQRDE+vXrZSfw8/MTCASGhoaurq63b9/WZt8SExOJf+Xm5kaPLS0tXbhwIY/Hs7GxiY6O7u3tRQidP3/+8OHD1FOy2qHV7J08efLEiRPaXKIcNTU1//Zv/7Zjxw6xWKzRBY3/RpAO+vzzz9PS0nbv3h0cHPzw4UMnJ6dJkyadPn36+++/p6f58ccfz5496+/vX1VVNW/ePIy9lVVVVeXn5+fr69va2lpQUPDNN99s3boVIRQQEMDhcHx9fdvb27XTk1f0mPPu3bufffbZ1q1b586dq+llLVu2rKOjw9/fX0PtSyQSTf90D3Ho0KHs7Ozc3FyBQEAPTEtLMzAwCA8Pl31tIUanTp2SvQ/+22+/UcP3799vbW29b98+Pp/v6ekZHR3997///d69ewihTz/9dM6cOUuXLh0YGNBCD7WdvdFecadlc+bMyc/PX7duHZvNxt2X8crMzGxpadHa4mpra/fu3btv3z4OhyM73MvLKzIy8unTpzt37tRaZ5Q1MDDw/fff+/j40N/DJUuWkCRJPxMbHx9/586d1NRULXRG49kjSTI5OXnmzJlsNtvY2HjXrl30qMHBwbi4OHt7ey6XO3v2bOqZpoyMDD6fz+Pxzp07t2TJEqFQaGdnd+bMGWqWa9euvfnmmzweTygUuru7i0Si0drREaWlpfb29gRBfPXVV0ju2qWlpXE4HEtLyy1bttjY2HA4HC8vr5s3byKEIiIiWCyWtbU11ea2bdv4fD5BEM+fP4+MjIyKiqqrqyMIwtnZGSF06dIloVCYlJSkoTVKS0sjSXLEv9ZNTEycMWPGyZMnL1++PHwsSZJHjx597bXX2Gy2qanp8uXLqV8b+XtcvTv34cOHXV1d9vb29BAnJyeEUEVFBfXR1NTUx8cnNTVVG2cK43yebcznOWNjYwmC+PLLL9va2sRicXp6OkKovLycJMmdO3ey2ey8vLy2trbdu3cbGBjcunWLmgUhdOXKlY6OjpaWlkWLFvH5/L6+vq6uLqFQePjwYYlE0tzcvGLFitbWVjntKOJPf/rTnDlzFF9lFZ7nfPz4MULo2LFj9AYZce1IkgwPD+fz+dXV1T09PVVVVQsWLBAIBI2NjSRJrlu3zsrKim4zOTkZIUStfnBwsJOTEz3q4sWLAoEgISFBqU6SCj/P6ejoOGvWrCEDnZycHj16RJLk9evXDQwMpk2b1tXVRZJkcXFxYGAgNU1cXByLxTp16lR7e3tFRcW8efPMzc2bm5vlbxPVdu7+/fvt7OxMTEyYTOa0adMCAwN/+eUXkiSvXbuGEEpOTpadmMvl+vr60h9jYmLor6h8inz/5dDs755EIklJSXn77bd37NhhYmLC5XLNzMyoUT09PRkZGUFBQcHBwSYmJnv27GEymVlZWfS8Xl5eQqHQwsIiJCSku7u7sbGxvr5eJBK5urpyOBwrK6v8/Hxzc/Mx29FNw9eOGs5gMKhfhlmzZmVkZHR2diq7LsuWLROJRHv37tVAr1F3d/ejR4+o34oReXp6bt++vb6+/rPPPpMdLpFIjh49umLFitDQUGNjY3d396+//vr58+fHjx+npxm+TVTeue+///758+cfP37c1dV15syZxsZGHx+fqqoq6pLmkIdgmUymRCKhP06fPh0hVFlZqfBWUZFms1dbWysWi319fYePun//vlgspq/8crlca2tr6iBkCBaLhRDq7+93dHS0tLQMDQ2Nj4+vr69Xth3dRK/d8FHz58/n8Xg6tS4tLS0kSdLVV0aUmJg4c+bM9PT00tJSemBVVVVXV9f8+fPpIQsWLGCxWNRB9RD0NlF5506ZMuX11183MjJisVgeHh5ZWVkSiSQ9PZ06Rx1yKaWvr4/L5dIfqbV79uzZmEsZJ81m78mTJwghCwuL4aO6u7sRQnv27KHvwDQ0NMi/3M/lcq9evert7Z2UlOTo6BgSEiKRSFRoR4+w2ezW1lbcvfinnp4ehJD8C1QcDicrK4sgiM2bN9O/J9SFeyMjI9kpTUxMOjs75TSlrp3r7u5uaGj44MED6pyZukxAEYvFPT09NjY29BAqh9SaapRms0f9N0P90A9BBTIlJUX2CLisrEx+g66urhcuXGhqaoqOjs7JyTly5Ihq7eiF/v7+9vZ21f8sWgOo7+WYN6A9PT137NhRU1Ozf/9+aoiJiQlCaEjSxlw7de1cqVQqlUrZbLaDg4NAIGhoaKBH1dbWIoRmz55ND+nr60N/rKlGaTZ7bm5uBgYG1AnuEFOmTOFwOEo94NLU1FRdXY0QsrCwOHjw4Lx586qrq1VoR1+UlJSQJOnh4YEQYjAYIx6XapmlpSVBEIrcwdu/f7+LiwtdLdDNzc3IyOjXX3+lJ7h582ZfX98bb7whpxGVd+4777wj+5G6POPp6clgMJYuXfrzzz/T79UvLi4mCEL2si21dlZWVsouVFmazZ6FhUVwcHBeXl5mZqZIJKqoqKDPrTkczqZNm86cOZORkSESiQYHB588efL777/Laa2pqWnLli337t3r6+srLy9vaGjw8PBQoR1dJpVK29raBgYGKioqIiMj7e3tqcpezs7OL1++LCws7O/vb21tlf2f28zMrKmpqb6+vrOzs7+/v7i4WHP3GHg8nqOjI3UqIR915Elf1eBwOFFRUQUFBadPnxaJRJWVlVu3brWxsQkPD5ffyGg7NyQkxMrKarRH1Z4+fZqdnd3e3t7f319WVhYWFmZvb089v7J3795nz559/vnn3d3dZWVlycnJGzdunDlzJj0vtXbu7u4KbxVVqXyFlFTsGmtnZ2dYWNikSZOMjIy8vb3j4uIQQnZ2dnfv3u3t7Y2Ojra3t2cwGFRKq6qq0tPTqZPd6dOn19XVHT9+nHr55NSpU3/66ScvLy9TU1NDQ8PJkyfHxsZSb0wYsR35vSorK1u4cCF9lG9tbe3l5XXt2rUxV1nZewzHjh2jzjF4PF5AQICctXvw4EF4eDiTybS1tWUwGEKhcPny5XV1dVQ7L168eOuttzgcjoODwyeffELdJnV2dm5sbLx9+/bUqVO5XK63t3dzc3NRUZFAIEhMTFS8kxQF7zFEREQwmUyxWEx9LCgooC57mpubf/zxx0Mm3rVrF32PQSqVJicnT58+nclkmpqaBgUF3b9/nyRJ+dtktJ0bFBSEEIqLixuxk1FRUU5OTnw+n8Fg2NnZffDBB01NTfRY6i4xm822sbHZtWtXT0+P7LzLli2ztbWVSqVjbgpFvv/yZld5zvEvWx9p9H0t4eHhZmZmGmp8TApmr6amhsFgDHliS/sGBwcXLVqUmZmp3mafP3/O4XCOHDmiyMTj/P6/os9z6ixtPkevGmdn54SEhISEhK6uLlx9GBwcLCws7OzsDAkJUW/L8fHxc+fOjYiIUG+zI5qY2bt37x4xOrXvsFdNTEzMqlWrQkJCcD02XVJSkp+fX1xcLP9Oo7KOHj16586doqIiJpOpxmZHMzGz5+LiIue3Pjs7G3cHR7B79+6srKyOjg4HB4e8vDzc3RlDUlJSRETEwYMHsSzd19f3u+++ox9wVYtz58719vaWlJSYmpqqsVk54EVXuuLAgQMHDhzA3Qsl+Pn5+fn54e6F2gQGBgYGBmpziRPzdw8A3QfZAwAPyB4AeED2AMBjvNdaUlJSzp49q5au6IUbN24ghFatWoW7I+pHPUs1IVdNN8HvHgB4jPd3b/v27atXr1ZLV/QC9bMwIX/qc3Nz16xZMyFXTUPG+eIv+N0DAA/IHgB4QPYAwAOyBwAekD0A8MCTPdniNRQWi2Vpabl48eLk5OS2tjYsvQJK0eU6RAkJCbNmzRIKhWw229nZ+a9//Sv914ajlSjSfh0inH+37uTkZGxsTJIk9ZKSf/zjHxs3biQIwsbGRvEXS2uZRv9uHS8F/26dEhcX5+/vLxKJqI9UHSKE0MWLF2Unk30vtTb5+Pikp6e/ePFCJBLl5OQwmcx3332XGkW/Oo3m6upKjUpNTfXx8Wlra1NwKeP8/uvEMSdBECYmJosXL87KysrNzX327BlVuwd3v7RNLRWFtFCWSPfrEBkZGVEv4BAIBKtXrw4KCrp06RL1cn40eomiCV6HaEwrV67cuHFjS0vL119/jbsv2qaWikKaLkukF3WILl68KPvid3Nzc4SQIi/VnVB1iFRAvRWvuLgY6W2tInKUmjuKVxTS2bJE+liH6OnTp1wu18HBYcwpJ1QdIjno870hqLRMmTKF1I1aRbIUPN+TU3NH8YpCWi5LNJHqEMnq7u4WCAQRERHUx9FKFNG0VodIF7NHkiR1BiiRSHg8XkhICDVQLBaz2eyPPvqI/GNvSSQSahRVWqy2tpY6dh9yxi+nHWUpkj2xWGxkZEQvjiTJX375BSFEBUCp7Mlun1u3biGE9u3bp1QjilMke11dXQRB+Pv7DxlOZ48kyaioKIQQ9a5OOnvyt8loe1MtOy42NnbGjBn0ZSHqjaadnZ29vb1lZWWvv/46l8v97bff6Om/+eYbhNC33347Zsvj/P7r4jFnd3c3SZJCoVBPaxUpVXNHcbpQlkhf6hDRCgoKcnNzf/jhB/qy0GgliuhZJkgdItU8ePAAIeTi4qKntYpUq7mjCOxlifSrDlF2dvahQ4dKSkqmTZs22jR0iSJ6yASpQ6SaS5cuIYSWLFmip7WKVKu5MyZdKEukR3WIjh07dvr06atXr06ePFnOZHSJInrIBKlDpILm5uaUlBQ7O7vNmzfraa0i+TV3VK4opAtlifSiDhFJktHR0ZWVlYWFhUN+adHoJYroIROkDtGYSJLs6uqi6k60trbm5OQsXLjQ0NCwsLBQKBTqaa0i+TV3FK8ohHSvLJFe1CGqrq7+4osvTpw4wWQyZZ8dO3LkCJJboogyceoQjej8+fOzZ8/m8XgsFsvAwAD98WjLm2++mZCQ8OLFC3pKjLWKRqTgPYbRau6QylQU0nJZoglTh2i0UunJycnkWCWKSKhDpLO0+TynlssSQR0iEuoQAZoOliWCOkTqAtkDSoM6RGoB2dNROl6WCOoQjR/UIdJRul+WCOoQjRP87gGAB2QPADwgewDgAdkDAA/IHgCYqHxXntTCH9UDoNvG81zLuO4xaPqtJ0C+NWvWREZGyj6DD7RsPK+EI+DnS38RBJGTk/NK1WCbSOB8DwA8IHsA4AHZAwAPyB4AeED2AMADsgcAHpA9APCA7AGAB2QPADwgewDgAdkDAA/IHgB4QPYAwAOyBwAekD0A8IDsAYAHZA8APCB7AOAB2QMAD8geAHhA9gDAA7IHAB6QPQDwgOwBgAdkDwA8IHsA4AHZAwAPyB4AeED2AMADsgcAHpA9APCA7AGAx7jqzgIta2hoGBwclB3y7Nmzhw8f0h8nT57M4XC03i+gCqg7q0+WLVtWVFQ02lgmk/ns2TNTU1NtdgmoDI459UlISMhoowwMDPz8/CB4egSyp09WrFgx2iElSZLr16/Xcn/AeED29Amfz//LX/7CZDKHj2Kz2X/5y1+03yWgMsienlm3bt3AwMCQgUwmc8WKFXw+H0uXgGoge3pm6dKlRkZGQwb29/evW7cOS3+AyiB7eobFYq1atYrFYskOFAqFb7/9Nq4uAdVA9vTPe++919fXR39kMplr164dkkag++D+nv6RSqXW1tatra30kGvXrv3bv/0bxi4BFcDvnv4xMDBYt24dfbXTwsLC29sbb5eACiB7emnt2rX9/f0IIRaLtXHjRgMD2I/6B4459RJJktOmTWtsbEQI/frrr2+88QbuHgGlwf+XeokgiA0bNiCEHB0dIXh6alx/x7Bq1Sp19QMoSyQSIYQ4HA7sBYx27Njh6emp2rzj+t3Ly8t78uTJeFrQOzdu3Lhx4wbuXiCEkFAoNDExmTJliroafPLkSV5enrpaexXk5eU9fvxY5dnH+/d727dvX7169Tgb0SPUj8zZs2dxdwQhhC5fvqzGW+q5ublr1qzRkVXTCwRBjGd2ON/TY/Asi16D7AGAB2QPADwgewDgAdkDAA+tZi8sLEwgEBAEcefOHW0ud7iEhIRZs2YJhUI2m+3s7PzXv/61q6tLQ8sqKioyNja+cOGChtrH5fLlyzExMfn5+Y6OjgRBEAQx5KUVfn5+AoHA0NDQ1dX19u3b2uybnP2bmJhI/Cs3NzeE0Pnz5w8fPjzkNXAapdXsnTx58sSJE9pc4miuXr368ccf19fXP3/+/MCBA6mpqZq7Qz0hn9r7/PPP09LSdu/eHRwc/PDhQycnp0mTJp0+ffr777+np/nxxx/Pnj3r7+9fVVU1b948bXZPhf0bEBDA4XB8fX3b29u108lX9JjTyMgoPDzczMxMIBCsXr06KCjo0qVL47lPKseyZcs6Ojr8/f010ThCSCKReHl5aajxER06dCg7Ozs3N1cgENAD09LSDAwMwsPDOzo6tNmZEcnfv6dOnSJl/Pbbb9TwTz/9dM6cOUuXLh3+Vg5N0Hb2xnk7Ul0uXrxoaGhIfzQ3N0cIicVifD1SXWZmZktLi9YWV1tbu3fv3n379g15Y5qXl1dkZOTTp0937typtc6MRuX9Gx8ff+fOndTUVA127g8azx5JksnJyTNnzmSz2cbGxrt27aJHDQ4OxsXF2dvbc7nc2bNn5+TkIIQyMjL4fD6Pxzt37tySJUuEQqGdnd2ZM2eoWa5du/bmm2/yeDyhUOju7k490zhiO0p5+vQpl8t1cHBQ00r/U2lpqb29PUEQX331FZK7dmlpaRwOx9LScsuWLTY2NhwOx8vL6+bNmwihiIgIFotlbW1Ntblt2zY+n08QxPPnzyMjI6Oiourq6giCcHZ2RghdunRJKBQmJSWpfV0oaWlpJEkGBAQMH5WYmDhjxoyTJ09evnx5+FiSJI8ePfraa6+x2WxTU9Ply5ffu3dP/jZB6ti5SJn9a2pq6uPjk5qaqo0zBXIcEEI5OTnyp4mNjSUI4ssvv2xraxOLxenp6Qih8vJykiR37tzJZrPz8vLa2tp2795tYGBw69YtahaE0JUrVzo6OlpaWhYtWsTn8/v6+rq6uoRC4eHDhyUSSXNz84oVK1pbW+W0o6Du7m6BQBAREaHIxCtXrly5cqXijZMkSR3qHDt2jN4gI64dSZLh4eF8Pr+6urqnp6eqqmrBggUCgaCxsZEkyXXr1llZWdFtJicnI4So1Q8ODnZycqJHXbx4USAQJCQkKNVJkiSpr/WYkzk6Os6aNWvIQCcnp0ePHpEkef36dQMDg2nTpnV1dZEkWVxcHBgYSE0TFxfHYrFOnTrV3t5eUVExb948c3Pz5uZm+dtknDuXHLZ/9+/fb2dnZ2JiwmQyp02bFhgY+Msvv8hOHxMTQ39F5VPk+y9vdpXnVGTZYrGYx+P9+c9/podQ/5+Vl5dLJBIejxcSEkJPyWazP/roI/KPPSGRSKhRVFxra2up4/KLFy/KLkJOOwqKjY2dMWOGSCRSZGJ1ZW/42pEkGR4ebmxsTM9469YthNC+fftIZbKnMkWy19XVRRCEv7//kOF09kiSjIqKQgh9/PHHpEz2xGKxkZERvZtIkvzll18QQtT/EaNtk/HvXHLY/m1sbLx9+3ZnZ2dvb29ZWdnrr7/O5XJ/++03evpvvvkGIfTtt9+O2fI4s6fZY87a2lqxWOzr6zt81P3798ViMXV5FyHE5XKtra2pg5AhqLcA9ff3Ozo6WlpahoaGxsfH19fXK9vOiAoKCnJzc3/44QfZywbaRK/d8FHz58/n8XiKr4sWtLS0kCTJ4/HkTJOYmDhz5sz09PTS0lJ6YFVVVVdX1/z58+khCxYsYLFY1EH1EPQ2GefORSPt3ylTprz++utGRkYsFsvDwyMrK0sikVBpp1Br9+zZM8WXohrNZo/6CyMLC4vho7q7uxFCe/bsoW+zNDQ0yD8b5nK5V69e9fb2TkpKcnR0DAkJkUgkKrRDy87OPnToUElJybRp01RYOy1gs9my70TCrqenByHEZrPlTMPhcLKysgiC2Lx5s0QioQZSF+6HvFnUxMSks7NTTlPj2blIsf3r7u5uaGj44MEDegiXy0V/rKlGaTZ71KWw3t7e4aOoQKakpMj+CpeVlclv0NXV9cKFC01NTdHR0Tk5OUeOHFGtHYTQsWPHTp8+ffXq1cmTJ6uybprX39/f3t5uZ2eHuyP/RH0vx7wB7enpuWPHjpqamv3791NDTExMEEJDkjbm2qm8c5HC+1cqlUqlUtn/Taj3L1JrqlGazZ6bm5uBgcG1a9eGj5oyZQqHw1HqAZempqbq6mqEkIWFxcGDB+fNm1ddXa1COyRJRkdHV1ZWFhYWDn/Hs+4oKSkhSdLDwwMhxGAwRjwu1TJLS0uCIBS5g7d//34XF5fy8nLqo5ubm5GR0a+//kpPcPPmzb6+PvkvvFBh56Kx9u8777wj+5G6ciP7t+fU2llZWSm1UBVoNnsWFhbBwcF5eXmZmZkikaiiouL48ePUKA6Hs2nTpjNnzmRkZIhEosHBwSdPnvz+++9yWmtqatqyZcu9e/f6+vrKy8sbGho8PDxUaKe6uvqLL744ceIEk8mUfbboyJEj6lx5lUil0ra2toGBgYqKisjISHt7+40bNyKEnJ2dX758WVhY2N/f39ra2tDQQM9iZmbW1NRUX1/f2dnZ399fXFysuXsMPB7P0dFRkZcVUEee9E02DocTFRVVUFBw+vRpkUhUWVm5detWGxub8PBw+Y2MtnNDQkKsrKxGfFRN/v59+vRpdnZ2e3t7f39/WVlZWFiYvb391q1b6dmptXN3d1dmw6hE5as0pGLXeTo7O8PCwiZNmmRkZOTt7R0XF4cQsrOzu3v3bm9vb3R0tL29PYPBoFJaVVWVnp5OnexOnz69rq7u+PHjQqEQITR16tSffvrJy8vL1NTU0NBw8uTJsbGxAwMDJEmO2I6cLlVWVo64KZKTk8dcZWWvcx47doy6L8fj8QICAuSs3YMHD8LDw5lMpq2tLYPBEAqFy5cvr6uro9p58eLFW2+9xeFwHBwcPvnkE+o2qbOzM3XVburUqVwu19vbu7m5uaioSCAQJCYmKt5JioL3GCIiIphMplgspj4WFBQ4OTkhhMzNzalrm7J27dpF32OQSqXJycnTp09nMpmmpqZBQUH3798nSVL+Nhlt5wYFBSGE4uLihvdQ/v6NiopycnLi8/kMBsPOzu6DDz5oamqSnX3ZsmW2trZSqXTMTaHI91/e7CrPOf5l6yMV7jEojnoMSkONj0nB7NXU1DAYjCGPZWnf4ODgokWLMjMz1dvs8+fPORzOkSNHFJl4nN//V/R5Tp2lzefoVePs7JyQkJCQkKC5v/wY0+DgYGFhYWdnp5xCvKqJj4+fO3duRESEepsd0cTM3r1794jRqX2HvWpiYmJWrVoVEhKC67HpkpKS/Pz84uJi+XcalXX06NE7d+4UFRWNWF1U7SZm9lxcXOT81mdnZ+Pu4Ah2796dlZXV0dHh4OCg++/qS0pKioiIOHjwIJal+/r6fvfdd/QDrmpx7ty53t7ekpISrdWsH+87AoG6HDhw4MCBA7h7oQQ/Pz8/Pz/cvVCbwMDAwMBAbS5xYv7uAaD7IHsA4AHZAwAPyB4AeED2AMBE5bvy5ER8/RYAShnPcy3jvccQGRmpcv0xfZSSkoIQ2r59O+6OqF9ZWVlqaqpqL0R5Na1Zs2Y8s483e56enq9UDTCqRNZEXeXU1NSJumqaMM7swfkeAHhA9gDAA7IHAB6QPQDwgOwBgAee7MkWjqKwWCxLS8vFixcnJye3tbVh6RVQii7XAKNIpdKUlJQhhWJGKw+m/RpgON8Z4eTkRL2GmXpB0D/+8Y+NGzcSBGFjY6Pse7+1RqPvjMBLwXdGUOLi4vz9/emXPVM1wNCwt4bLvhNeyx48eLBw4UKE0Jw5c2SH+/j4pKenv3jxQiQS5eTkMJnMd999lxqVmprq4+PT1tam4CLG+f3XiWNOgiBMTEwWL16clZWV+7Z+CwAAE6lJREFUm5v77Nkzqm4W7n5pm1qqeWmhJJju1wC7e/fuZ599tnXr1rlz5w4ZJac82ASvATamlStXbty4saWl5euvv8bdF21TSzUvTZcE04saYHPmzMnPz1+3bt3wV2jLLw82oWqAqYB6I2VxcTHSpTphSiFHqXeleDUvnS0Jpo81wOQYUh5sQtUAk4M+3xuCSsuUKVNInakTRlPwfE9OvSvFKwppuSTYhKwB9qc//WnI+Z6sEcu/TZAaYPKNlj2SJKkzQN2pE0ZTJHvy610plT1tlgSbkDXA5GdvxPJvE6QGmGq6u7tJkhQKhTpSJ0xZStW7UpwulATTuxpgcoxW/m2C1ABTDVWQycXFRRfqhKlAtXpXisBeEky/aoDJIac82ASpAaaaS5cuIYSWLFmCvU6YalSrdzUmXSgJpkc1wOSQXx5sgtQAU0Fzc3NKSoqdnd3mzZsx1gkbD/n1rlSu5qULJcH0ogaYHKQC5d8mSA2wMZEk2dXVRdV8aW1tzcnJWbhwoaGhYWFhoVAoxFgnbDzk17tSvJoX0r2SYHpRA0wORcq/TZwaYCM6f/787NmzeTwei8UyMDBAfzza8uabbyYkJLx48YKeEledsNEoeI9htHpXpDLVvLRcEmzC1AAjSbKsrGzhwoU2NjbUl9za2trLy+vatWuKlH+DGmA6SpvPc2q5JBjUACOhBhig6WBJMKgBpi6QPaA0qAGmFpA9HaXjJcGgBtj4QQ0wHaX7JcGgBtg4we8eAHhA9gDAA7IHAB6QPQDwGO+1Fs09kaybqAeOcnNzcXdE/ahdOSFXTUepfFeehBpg4JU3nudaCIiQ/iIIIicnByoH6Sk43wMAD8geAHhA9gDAA7IHAB6QPQDwgOwBgAdkDwA8IHsA4AHZAwAPyB4AeED2AMADsgcAHpA9APCA7AGAB2QPADwgewDgAdkDAA/IHgB4QPYAwAOyBwAekD0A8IDsAYAHZA8APCB7AOAB2QMAD8geAHhA9gDAA7IHAB6QPQDwgOwBgAdkDwA8IHsA4AHZAwCP8dZbB9p04sSJly9fyg45d+7co0eP6I+bNm2ytLTUer+AKqDmsz7ZsmXL3/72NzabPXxUf3+/qalpc3MzgwH/n+oHOObUJ2vXrkUI9Y7E0NDwvffeg+DpEfjd0yckSdra2v7+++8jjr1+/bqnp6eWuwRUBr97+oQgiHXr1rFYrOGjJk+e7OHhof0uAZVB9vTM2rVr+/r6hgxksVjvv/8+QRBYugRUA8ec+mf69Om1tbVDBlZUVLi7u2PpD1AN/O7pn9DQUCaTKTvE2dkZgqd3IHv6JzQ0dGBggP7IZDI3bdqEsT9ANXDMqZfmzp1bUVFB7TuCIOrq6hwcHHB3CigHfvf00oYNGwwNDRFCBEG88cYbEDx9BNnTS2vXrpVKpQghQ0PDDRs24O4OUAVkTy/Z2NgsXLiQIAipVLpq1Src3QGqgOzpq/Xr15MkuXjxYmtra9x9ASohxwF33wHALCcnR+X4jPfR28jIyFfqGcKUlBSE0Pbt23F3BCGEUlJSPvzwQz6fr5bWysrKUlNTc3Jy1NLaq2DNmjXjmX282fP09Fy9evU4G9EjZ8+eRQjpyCp7e3tPnjxZjQ2mpqbqyKrphXFmD8739Jh6gwe0DLIHAB6QPQDwgOwBgAdkDwA8tJq9sLAwgUBAEMSdO3e0udzhDh8+7OLiwuVy+Xy+i4vL3r17RSKRhpZVVFRkbGx84cIFDbWPy+XLl2NiYvLz8x0dHQmCIAhi/fr1shP4+fkJBAJDQ0NXV9fbt29rv4dSqTQlJcXLy0t2YEJCwqxZs4RCIZvNdnZ2/utf/9rV1YUQOn/+/OHDhwcHB7XXv3HeW1f23uKZM2cQQuXl5eNZ7vgtW7bsyJEjLS0tnZ2dubm5TCbzz3/+syIzrly5cuXKlUot6+LFi0Kh8Pz58yr1VHuoO3sKThwXF+fv7y8SiaiPTk5OkyZNQghdvHhRdrLi4uLAwEA1d1QxDx48WLhwIUJozpw5ssN9fHzS09NfvHghEolycnKYTOa7775LjUpNTfXx8Wlra1NwESp8/2W9osecLBZr27ZtFhYWRkZGq1atWr58+U8//TTaO4jGadmyZR0dHf7+/ppoHCEkkUiG/NeuaYcOHcrOzs7NzRUIBPTAtLQ0AwOD8PDwjo4ObXZmRHfv3v3ss8+2bt06d+7cIaOMjIzCw8PNzMwEAsHq1auDgoIuXbr0+PFjhNCnn346Z86cpUuXyv55pOZoO3s68k6RgoICDodDf7S1tUUIUcceeiczM7OlpUVri6utrd27d+++fftkNyBCyMvLKzIy8unTpzt37tRaZ0YzZ86c/Pz8devWDX+X6cWLF6k/v6KYm5sjhMRiMfUxPj7+zp07qampWuikxrNHkmRycvLMmTPZbLaxsfGuXbvoUYODg3Fxcfb29lwud/bs2dQxT0ZGBp/P5/F4586dW7JkiVAotLOzo45UEULXrl178803eTyeUCh0d3enTtJGbEcpNTU1JiYmU6dOVdNK/1Npaam9vT1BEF999RWSu3ZpaWkcDsfS0nLLli02NjYcDsfLy+vmzZsIoYiICBaLRT8zvW3bNj6fTxDE8+fPIyMjo6Ki6urqCIJwdnZGCF26dEkoFCYlJal9XShpaWkkSQYEBAwflZiYOGPGjJMnT16+fHn4WJIkjx49+tprr7HZbFNT0+XLl9+7d0/+NkHq2LnyPX36lMvl0n8AaWpq6uPjk5qaSmrhcWWVj1YVPN6NjY0lCOLLL79sa2sTi8Xp6enoj/O9nTt3stnsvLy8tra23bt3GxgY3Lp1i5oFIXTlypWOjo6WlpZFixbx+fy+vr6uri6hUHj48GGJRNLc3LxixYrW1lY57Yypr6/vyZMnx44dY7PZp06dUmQWFc73qOOZY8eO0RtkxLUjSTI8PJzP51dXV/f09FRVVS1YsEAgEDQ2NpIkuW7dOisrK7rN5ORkhBC1+sHBwU5OTvSoixcvCgSChIQEpTpJKny+5+joOGvWrCEDnZycHj16RJLk9evXDQwMpk2b1tXVRf7r+V5cXByLxTp16lR7e3tFRcW8efPMzc2bm5vlbxOVdy7lT3/605DzPVnd3d0CgSAiIkJ2YExMDFLskoQi3395s6s8pyLLFovFPB5P9jIGfa1FIpHweLyQkBB6Sjab/dFHH5F/7AmJREKNouJaW1v722+/oWFn83LaGZOVlRVCaNKkSf/5n/9J7ekxqSt7w9eOJMnw8HBjY2N6xlu3biGE9u3bRyqTPZUpkr2uri6CIPz9/YcMp7NHkmRUVBRC6OOPPyZlsicWi42MjOjdRJLkL7/8ghCi/o8YbZuMZ+dS5GcvNjZ2xowZ9BUjyjfffIMQ+vbbb8dsfJzZ0+wxZ21trVgs9vX1HT7q/v37YrHYzc2N+sjlcq2tramDkCGoV8H29/c7OjpaWlqGhobGx8fX19cr285wjx8/bmlp+Z//+Z///u//fv3117V51kSj1274qPnz5/N4PAXXRTtaWlpIkuTxeHKmSUxMnDlzZnp6emlpKT2wqqqqq6tr/vz59JAFCxawWCzqoHoIepuMZ+eOqaCgIDc394cffpC9YoQQotbu2bNnalmKHJrN3pMnTxBCFhYWw0d1d3cjhPbs2UP8oaGhgT7lHRGXy7169aq3t3dSUpKjo2NISIhEIlGhHRqTybSwsPDz88vOzq6qqjpw4IAqK6lJbDa7tbUVdy/+qaenByE0YjEWGofDycrKIghi8+bNEomEGtje3o4QMjIykp3SxMSks7NTTlPj2bnyZWdnHzp0qKSkZNq0aUNGcblc9MeaapRms0ddCuvt7R0+igpkSkqK7K9wWVmZ/AZdXV0vXLjQ1NQUHR2dk5Nz5MgR1doZwtnZ2dDQsKqqSqm5NK2/v7+9vd3Ozg53R/6J+l6OeQPa09Nzx44dNTU1+/fvp4aYmJgghIYkbcy1U8vOHe7YsWOnT5++evXqiH8IQr32m1pTjdJs9tzc3AwMDK5duzZ81JQpUzgcjlIPuDQ1NVVXVyOELCwsDh48OG/evOrqahXaefHixXvvvSc7pKamZnBwcMqUKYo3ogUlJSUkSVJVFhgMxojHpVpmaWlJEIQid/D279/v4uJSXl5OfXRzczMyMvr111/pCW7evNnX1/fGG2/IaUSFnSsfSZLR0dGVlZWFhYVDfoRp1NpR1wI0SrPZs7CwCA4OzsvLy8zMFIlEFRUVx48fp0ZxOJxNmzadOXMmIyNDJBINDg4+efJE/t3tpqamLVu23Lt3r6+vr7y8vKGhwcPDQ4V2+Hz+jz/+ePXqVZFI1N/fX15e/v777/P5/B07dqhz5VUilUrb2toGBgYqKioiIyPt7e03btyIEHJ2dn758mVhYWF/f39ra2tDQwM9i5mZWVNTU319fWdnZ39/f3FxsebuMfB4PEdHR+pUQj7qyJO+k8bhcKKiogoKCk6fPi0SiSorK7du3WpjYxMeHi6/kdF2bkhIiJWVlbKPqlVXV3/xxRcnTpxgMpmEjCNHjtDTUGunjfd8q3yVhlTsOk9nZ2dYWNikSZOMjIy8vb3j4uIQQnZ2dnfv3u3t7Y2Ojra3t2cwGFRKq6qq0tPTqZPd6dOn19XVHT9+XCgUIoSmTp36008/eXl5mZqaGhoaTp48OTY2dmBggCTJEduR36uAgAAHBwcjIyM2m+3k5BQSElJZWanIKit7nfPYsWPUfTkejxcQECBn7R48eBAeHs5kMm1tbRkMhlAoXL58eV1dHdXOixcv3nrrLQ6H4+Dg8Mknn1C3SZ2dnRsbG2/fvj116lQul+vt7d3c3FxUVCQQCBITExXvJEXBewwRERFMJlMsFlMfCwoKnJycEELm5ubUtU1Zu3btou8xSKXS5OTk6dOnM5lMU1PToKCg+/fvkyQpf5uMtnODgoIQQnFxcSN2sqysbOHChTY2NtSX3Nra2svL69q1a5WVlSOmIDk5mZ532bJltra2Uql0zE2hyPdf3uwqzzn+ZesjFe4xKI561klDjY9JwezV1NQwGAwFb4dqzuDg4KJFizIzM9Xb7PPnzzkczpEjRxSZeJzf/1f0eU6dpdXn6FXi7OyckJCQkJCA8RG8wcHBwsLCzs7OkJAQ9bYcHx8/d+7ciIgI9TY7oomZvXv37hGjU/sOe9XExMSsWrUqJCQE12PTJSUl+fn5xcXF8u80Kuvo0aN37twpKioaUuZJQyZm9lxcXOT81mdnZ+Pu4Ah2796dlZXV0dHh4OCQl5eHuztjSEpKioiIOHjwIJal+/r6fvfdd+p9KfC5c+d6e3tLSkpMTU3V2Kwc431HIFCXAwcO6ODNfTn8/Pz8/Pxw90JtAgMDAwMDtbnEifm7B4Dug+wBgAdkDwA8IHsA4DHeay3jf7BVv1APHOXm5uLuiPpRu3JCrpqOUvmuPAk1wMArD2cNsJycnFeqcg1V5JWqRjTB5ObmrlmzBv5LVdw4X/wF53sA4AHZAwAPyB4AeED2AMADsgcAHpA9APDAkz3ZwlEUFotlaWm5ePHi5OTktrY2LL0C46GPJcEw1P2SNc576+O5t+jk5ES9hpl6QdA//vGPjRs3EgRhY2Oj1Hu/tUmj74zAS6kaYEPob0kwZet+yRrn918njjkJgjD5/9q7ex1jojCA48dnZBNDQTSr3EQIpQSNVlTWFgrFZu+ASkHjAugm06lJJKLhElyDhqh8rGaY0M0W866crGWPM5xzeJ9fufG1e+bJmGHn7/Wm0+lWq9XpdBaLhdHN4v26WLtKzQuSYMfOJMEYd79wQswe7u3t7f39fblcKorC+7WwdpWaFyTBjp1JgiG23S+ccLOHEDKuSDkYDJBInbCL6Cd6V+Q1L0iCMUuCMe1+4ajfrZp/v3s43vvBmJZgMKgL0An7gfB470zvirwoxDgJRne89xhJMPLuF87k9i/ifs/tdlssls1ms9/vZVnO5XL5fN7r9VarVYfD0Wq1DrdMJpOSJPn9/kKhoGnabDabTqeqqkYiEZfLFQgEut2uz+f783Gua7fbNRqN19fXYrHo8Xii0aiiKJ+fn4drcpOz2+3GniEcDsuyvNlsLn3Z2WxWVdVarXbpU5PQNG0ymRjXxv1VIpEolUrT6bRSqeA/J/kTHS/u7dbx5eUFIXTqyrk3IuLsaZqm67okSSJ0wihc1LsiB0mw260js+4XTsTZG4/HCKFQKCRCJ4wCXe+KBCTB0G3WkVn3Cyfi7A2HQ4RQJpMRqhNGjq539SdIgt1uHZl1v3DCzd58Pm82m8/Pzx8fHxw7YWac711R17wgCXa7dWTW/cJxnj1d17fbrdF8Wa1W7XY7lUrZbLZerydJEsdOmBnne1fkNS8ESbCjB7luEuyAXfcLR32GVDdxjrXf78disaenJ6fTabVa0fdXW+LxeL1eX6/Xh1ty7IT9ivAzhlO9K/2SmhfjJBjdZwx3nQQ73IC8+4Wj3v7/3Z36nuaf+x6x/D4n4yQY3ew9QBLsou4XzuT2L9zxHsBBEoyEySQYy+4XDmYPmHXXSTDG3S8czJ6gIAlGjjoJxr77hYMGmKAgCcYA++4XDvZ7APABswcAHzB7APABswcAH2bPtTSbzYcMg5wyGo3QdxHlwRjfq3rIX01MFt3E/8nDOoH/XLlcTiQSdPc1NXsAAGpwvAcAHzB7APABswcAHzB7APDxBegwNZ76Z70DAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
        "print(\"Final score: {}\".format(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jubuP55WXxTT",
        "outputId": "910df7cd-7999-46be-817c-a090db414903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "Final score: 1.0607558087331188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabgan.sampler import GANGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "gen_x, gen_y = GANGenerator(gen_x_times=1.1, cat_cols=None,\n",
        "           bot_filter_quantile=0.001, top_filter_quantile=0.999, \\\n",
        "              is_post_process=True,\n",
        "           adversarial_model_params={\n",
        "               \"metrics\": \"rmse\", \"max_depth\": 2, \"max_bin\": 100, \n",
        "               \"learning_rate\": 0.02, \"random_state\": \\\n",
        "                42, \"n_estimators\": 500,\n",
        "           }, pregeneration_frac=2, only_generated_data=False,\\\n",
        "           gan_params = {\"batch_size\": 500, \"patience\": 25, \\\n",
        "          \"epochs\" : 500,}).generate_data_pipe(df_x_train, df_y_train,\\\n",
        "          df_x_test, deep_copy=True, only_adversarial=False, \\\n",
        "          use_adversarial=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "WbM-6qiJ0W8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "66ea9ebe0c2d4c0c979b22e6f8dfa9fb",
            "dd073c0deab74b1c84c757dd04f4b4d0",
            "5e590e7c9eba46709b683dfa4d23f855",
            "928f0f7e628a41f1bbfc933240b970f7",
            "9781fd2ea4de4239857507f5287c511d",
            "dab2c77192024d829cb439087eb07b6c",
            "a84f54dfea304a3381bd7df92a038675",
            "a881253636c74692bce1a59636be9755",
            "35c8417d55cf4921911438863fc15afa",
            "5d1b5af1bd474b80a0f6dd4573405af6",
            "1ff99bd12a5345358ed1d912b8fd73c1",
            "b8dfc1e3d398469fb00f1ed34c2d6ea8",
            "f0e4d0f5e5604c7e9e651128186b22a3",
            "25d13fdd77f64989a6f6e8939d88a91e",
            "e044d893282e4ef49db3c9a9d9220ee2",
            "89ab8d472d7245e8be1b2265c311af80",
            "77739df8df61493dabab6438f41b96d6",
            "f4bdb70a850346d9b176ef1593dd53eb",
            "d7aaf27384b8488fb9707c5dfb99a904",
            "88870b8507494eadb9e375460be74917",
            "6d13bd1ce79746019c0fda7f040afb4f",
            "8955f5164b774bfcacfd142b42168564"
          ]
        },
        "outputId": "7c1b5e36-9fb5-4e42-91b5-1db0193052c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/_ctgan/synthesizer.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fitting CTGAN transformers for each column:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66ea9ebe0c2d4c0c979b22e6f8dfa9fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training CTGAN, epochs::   0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8dfc1e3d398469fb00f1ed34c2d6ea8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.9/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_x['YEAR'] = gen_x['YEAR'].round(decimals = 0)\n"
      ],
      "metadata": {
        "id": "0kVplJIPYuHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6iVmRoeqksW3",
        "outputId": "fb110e2e-5586-4849-c25c-cd147255de5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   FULL_TIME_POSITION  PREVAILING_WAGE    YEAR  SOC_N\n",
              "0                   0    174152.509617  2012.0      2\n",
              "1                   0    148966.752939  2012.0      2\n",
              "2                   0    171603.975017  2012.0      2\n",
              "3                   0    163984.045412  2012.0      2\n",
              "4                   0    179405.353601  2012.0      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-330a2d4c-94e8-4d8c-9dd7-e9e1d6ce4637\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FULL_TIME_POSITION</th>\n",
              "      <th>PREVAILING_WAGE</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>SOC_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>174152.509617</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>148966.752939</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>171603.975017</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>163984.045412</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>179405.353601</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-330a2d4c-94e8-4d8c-9dd7-e9e1d6ce4637')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-330a2d4c-94e8-4d8c-9dd7-e9e1d6ce4637 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-330a2d4c-94e8-4d8c-9dd7-e9e1d6ce4637');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "pred = model.predict(gen_x.values)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred,gen_y.values))\n",
        "print(\"Final score : {}\".format(score))"
      ],
      "metadata": {
        "id": "ER0lb3Kc0W1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86be1ed5-0210-4a6b-8412-d83aa7655838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "583/583 [==============================] - 1s 2ms/step\n",
            "Final score : 1.5759845612951957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [df.drop(['CASE_STATUS'],axis=1), gen_x]\n",
        "new_x = pd.concat(frames)\n",
        "frames = [df['CASE_STATUS'], gen_y]\n",
        "new_y = pd.concat(frames)"
      ],
      "metadata": {
        "id": "9XITA07ZjPy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFICATION ALGORITHMS BEFORE GANS"
      ],
      "metadata": {
        "id": "mzWtWeLxkEg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train0, x_test0, y_train0, y_test0 = train_test_split(df.drop(['CASE_STATUS'],axis=1), df['CASE_STATUS'], test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "reWPjExIkIvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Logistic Regression (ORIGINAL DATA)"
      ],
      "metadata": {
        "id": "xOwGB-1_kSGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(x_train0, y_train0)\n",
        "score = logisticRegr.score(x_test0, y_test0)\n",
        "print(\"ACCURACY: \"+str(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sHVmOctkIsU",
        "outputId": "b343c280-863c-4e50-97a3-c2e81976b331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY: 0.8718975180144115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Random Forest (ORIGINAL DATA)"
      ],
      "metadata": {
        "id": "Hg3Y-lSSkfeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators = 100)  \n",
        "  \n",
        "clf.fit(x_train0, y_train0)\n",
        "  \n",
        "# performing predictions on the test dataset\n",
        "y_pred = clf.predict(x_test0)\n",
        "  \n",
        "# metrics are used to find accuracy or error\n",
        "from sklearn import metrics  \n",
        "print()\n",
        "  \n",
        "# using metrics module for accuracy calculation\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test0, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_EorJ2vkf_k",
        "outputId": "c8733e6c-86d5-43a6-fdc7-4e7ff4ec1f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ACCURACY OF THE MODEL:  0.8050440352281826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> K Nearest Neighbors (ORIGINAL DATA)"
      ],
      "metadata": {
        "id": "pCUcX6uZFutU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_train0, y_train0)\n",
        "y_pred  =knn.predict(x_test0)\n",
        "# metrics are used to find accuracy or error\n",
        "from sklearn import metrics  \n",
        "print()\n",
        "  \n",
        "# using metrics module for accuracy calculation\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test0, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS0_zsp7FvIW",
        "outputId": "21ce6ba4-ca2f-40d6-c0de-55f09a321527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ACCURACY OF THE MODEL:  0.858343337334934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Gradient Boosting Ensemble (ORIGINAL DATA)"
      ],
      "metadata": {
        "id": "FLY5499zJXEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(x_train0, y_train0)\n",
        "clf.score(x_test0, y_test0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzvuL5P4Ja3K",
        "outputId": "6798e241-a209-446d-ed65-b58145b44be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8787515006002401"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFICATION ALGORITHMS AFTER GANS"
      ],
      "metadata": {
        "id": "ke8t3GBhfe5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(new_x, new_y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "69aXh7Dy0WTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Logistic Regression (GAN Synthesized data)"
      ],
      "metadata": {
        "id": "gBEseNaGfhnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(x_train1, y_train1)\n",
        "score = logisticRegr.score(x_test1, y_test1)\n",
        "print(\"ACCURACY: \"+str(score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMVmjYtlgbDh",
        "outputId": "aa48e47c-175f-4364-99e6-4440bdf7b5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY: 0.7381271800375637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> RandomForest (GAN Synthesized data)"
      ],
      "metadata": {
        "id": "Zqy4-O8Efkkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators = 100)  \n",
        "  \n",
        "clf.fit(x_train1, y_train1)\n",
        "  \n",
        "# performing predictions on the test dataset\n",
        "y_pred = clf.predict(x_test1)\n",
        "  \n",
        "# metrics are used to find accuracy or error\n",
        "from sklearn import metrics  \n",
        "print()\n",
        "  \n",
        "# using metrics module for accuracy calculation\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test1, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUgiiTYpfl0B",
        "outputId": "0dd4c519-293d-4aed-99a4-24f2cb4c6417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ACCURACY OF THE MODEL:  0.7000268312315535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> K Nearest Neighbors (GAN Synthesised Data)"
      ],
      "metadata": {
        "id": "Qzem3HrsGpxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_train1, y_train1)\n",
        "y_pred  =knn.predict(x_test1)\n",
        "# metrics are used to find accuracy or error\n",
        "from sklearn import metrics  \n",
        "print()\n",
        "  \n",
        "# using metrics module for accuracy calculation\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test1, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4sZunHKKDHk",
        "outputId": "48d44362-4ae6-48f6-c9de-445e0c654455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY OF THE MODEL: 0.7147449336128582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Gradient Boosting Ensemble (GAN Synthesised Data)"
      ],
      "metadata": {
        "id": "DU4fTtp5J0z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(x_train1, y_train1)\n",
        "clf.score(x_test1, y_test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBeQ8YAKJ5tU",
        "outputId": "62acda82-1515-4313-c4d6-cfc3ba75056c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7132075471698113"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reshaping it into 25x100 images for noise to feed it into generator network in GAN"
      ],
      "metadata": {
        "id": "sVQG0ejxjpaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before_img = pd.concat([gen_x,gen_y],axis=1).values"
      ],
      "metadata": {
        "id": "4c5HFAI6hGbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26MYWsvZxcEv",
        "outputId": "08e668c3-270b-4c83-b308-faf416951972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19826, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "before_img = np.reshape(before_img,(1,-1))[0][:2500*math.floor(before_img.shape[0]*before_img.shape[1]/2500)]"
      ],
      "metadata": {
        "id": "Jywwh6sex__T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_img=np.reshape(before_img,(-1,25,100))"
      ],
      "metadata": {
        "id": "zjJq_nK4yh2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXrzQZR7hlhy",
        "outputId": "960e8693-e62b-4a1b-a509-c3be15731e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39, 25, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "before_img = stats.zscore(before_img)\n",
        "\n",
        "#before_img = (before_img/np.linalg.norm(before_img))"
      ],
      "metadata": {
        "id": "OCLRNgJDrl1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(before_img[0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "fyaqP7M9m1-M",
        "outputId": "b8713d28-7e5e-4f95-b687-46a2b50e6d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GANs for Images"
      ],
      "metadata": {
        "id": "HKg7Nokkztky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "QqqhKlGLhmfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define input image dimensions\n",
        "#Large images take too much time and resources.\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)"
      ],
      "metadata": {
        "id": "E-DDqJgpjurX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\n",
        "    noise_shape = (100,) #1D array of size 100 (latent vector / noise)\n",
        "\n",
        "#Define your generator network \n",
        "#Here we are only using Dense layers. But network can be complicated based\n",
        "#on the application. For example, you can use VGG for super res. GAN.         \n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_shape=noise_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    \n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=noise_shape)\n",
        "    img = model(noise)    #Generated image\n",
        "\n",
        "    return Model(noise, img)"
      ],
      "metadata": {
        "id": "_4Hr0Xn2juoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)"
      ],
      "metadata": {
        "id": "soIcr-Zpjulg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    #noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    noise = before_img[0]\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "    plt.close()\n",
        "#This function saves images to view"
      ],
      "metadata": {
        "id": "JIvwSR1ZkPy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(0.0002, 0.5)  #Learning rate and momentum.\n",
        "\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "generator = build_generator()\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        " \n",
        "z = Input(shape=(100,))   \n",
        "img = generator(z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOljJTIHkWQ6",
        "outputId": "c24d6ab9-1bc3-4a14-fd31-38909b6b6eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.trainable = False  \n",
        "\n",
        "  \n",
        "valid = discriminator(img)  \n",
        "\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n"
      ],
      "metadata": {
        "id": "BO3RZltrkdOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "    # Load the dataset\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Convert to float and Rescale -1 to 1 \n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "#Add channels dimension. As the input to our gen and discr. has a shape 28x28x1.\n",
        "    X_train = np.expand_dims(X_train, axis=3) \n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # TRAIN DISCRIMINATOR\n",
        "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        " \n",
        "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator on real and fake images, separately\n",
        "        #Research showed that separate training is more effective. \n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    #take average loss from real and fake images. \n",
        "    \n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
        "\n",
        "        # TRAIN GENERATOR\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
        "        valid_y = np.array([1] * batch_size) \n",
        "\n",
        "        g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "        if epoch % save_interval == 0:\n",
        "            save_imgs(epoch)"
      ],
      "metadata": {
        "id": "G0rw9LmhhrtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create images/ folder before running "
      ],
      "metadata": {
        "id": "0KLz9nJ7ulGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(epochs=5000, batch_size=32, save_interval=500)\n",
        "\n",
        "generator.save('generator_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xEbnHnIkfI5",
        "outputId": "49f823c5-d811-456b-b427-f2ac11bfd772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2502 [D loss: 0.562326, acc.: 75.00%] [G loss: 0.965783]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2503 [D loss: 0.577355, acc.: 65.62%] [G loss: 1.002471]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2504 [D loss: 0.625917, acc.: 53.12%] [G loss: 0.906733]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2505 [D loss: 0.552099, acc.: 75.00%] [G loss: 0.939006]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2506 [D loss: 0.689081, acc.: 56.25%] [G loss: 0.871612]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2507 [D loss: 0.572946, acc.: 71.88%] [G loss: 0.923404]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2508 [D loss: 0.671703, acc.: 62.50%] [G loss: 0.968615]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2509 [D loss: 0.585679, acc.: 78.12%] [G loss: 0.888256]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2510 [D loss: 0.500231, acc.: 68.75%] [G loss: 1.053443]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2511 [D loss: 0.658800, acc.: 56.25%] [G loss: 0.913485]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2512 [D loss: 0.736815, acc.: 59.38%] [G loss: 0.865328]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2513 [D loss: 0.675626, acc.: 59.38%] [G loss: 0.819929]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2514 [D loss: 0.636409, acc.: 62.50%] [G loss: 0.911139]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2515 [D loss: 0.625309, acc.: 59.38%] [G loss: 1.054804]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2516 [D loss: 0.641193, acc.: 68.75%] [G loss: 1.039299]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2517 [D loss: 0.623568, acc.: 68.75%] [G loss: 1.050298]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2518 [D loss: 0.654753, acc.: 56.25%] [G loss: 1.001058]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2519 [D loss: 0.695989, acc.: 50.00%] [G loss: 0.933194]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2520 [D loss: 0.721661, acc.: 53.12%] [G loss: 0.920568]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2521 [D loss: 0.617440, acc.: 68.75%] [G loss: 0.916117]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2522 [D loss: 0.563125, acc.: 78.12%] [G loss: 0.891627]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2523 [D loss: 0.596978, acc.: 65.62%] [G loss: 0.789860]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2524 [D loss: 0.619805, acc.: 65.62%] [G loss: 0.844905]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2525 [D loss: 0.634105, acc.: 78.12%] [G loss: 0.795000]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2526 [D loss: 0.691754, acc.: 43.75%] [G loss: 0.864227]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2527 [D loss: 0.556363, acc.: 75.00%] [G loss: 0.888643]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2528 [D loss: 0.574721, acc.: 78.12%] [G loss: 0.858777]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2529 [D loss: 0.637384, acc.: 56.25%] [G loss: 0.893329]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2530 [D loss: 0.663007, acc.: 59.38%] [G loss: 0.904206]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2531 [D loss: 0.623586, acc.: 71.88%] [G loss: 1.053526]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2532 [D loss: 0.733354, acc.: 50.00%] [G loss: 0.919327]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2533 [D loss: 0.567301, acc.: 71.88%] [G loss: 0.975479]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2534 [D loss: 0.685362, acc.: 53.12%] [G loss: 1.037469]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2535 [D loss: 0.547093, acc.: 71.88%] [G loss: 0.986695]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2536 [D loss: 0.651953, acc.: 62.50%] [G loss: 0.871499]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2537 [D loss: 0.731483, acc.: 56.25%] [G loss: 0.842009]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2538 [D loss: 0.634647, acc.: 68.75%] [G loss: 0.931530]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2539 [D loss: 0.619525, acc.: 62.50%] [G loss: 0.958566]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2540 [D loss: 0.577448, acc.: 68.75%] [G loss: 0.957953]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2541 [D loss: 0.577442, acc.: 59.38%] [G loss: 0.909645]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2542 [D loss: 0.648758, acc.: 62.50%] [G loss: 0.929535]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2543 [D loss: 0.593727, acc.: 56.25%] [G loss: 0.896015]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2544 [D loss: 0.650480, acc.: 65.62%] [G loss: 0.967758]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2545 [D loss: 0.633158, acc.: 65.62%] [G loss: 0.924920]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2546 [D loss: 0.611832, acc.: 68.75%] [G loss: 0.885233]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2547 [D loss: 0.507032, acc.: 81.25%] [G loss: 0.945936]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2548 [D loss: 0.610630, acc.: 56.25%] [G loss: 0.986541]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2549 [D loss: 0.612732, acc.: 71.88%] [G loss: 0.947465]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2550 [D loss: 0.670425, acc.: 68.75%] [G loss: 0.847850]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2551 [D loss: 0.621561, acc.: 62.50%] [G loss: 0.822817]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2552 [D loss: 0.694159, acc.: 43.75%] [G loss: 0.894021]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2553 [D loss: 0.647402, acc.: 62.50%] [G loss: 0.892614]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2554 [D loss: 0.587663, acc.: 75.00%] [G loss: 0.879596]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2555 [D loss: 0.582370, acc.: 75.00%] [G loss: 0.918482]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2556 [D loss: 0.633137, acc.: 65.62%] [G loss: 0.867574]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2557 [D loss: 0.664719, acc.: 59.38%] [G loss: 0.916718]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2558 [D loss: 0.699529, acc.: 65.62%] [G loss: 0.930728]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2559 [D loss: 0.636210, acc.: 71.88%] [G loss: 0.979975]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2560 [D loss: 0.571311, acc.: 81.25%] [G loss: 1.029881]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2561 [D loss: 0.567186, acc.: 78.12%] [G loss: 1.015893]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2562 [D loss: 0.631295, acc.: 65.62%] [G loss: 0.852599]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2563 [D loss: 0.748000, acc.: 46.88%] [G loss: 0.804839]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2564 [D loss: 0.612772, acc.: 65.62%] [G loss: 0.909868]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2565 [D loss: 0.633667, acc.: 71.88%] [G loss: 0.860675]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2566 [D loss: 0.622743, acc.: 62.50%] [G loss: 0.896597]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "2567 [D loss: 0.675893, acc.: 59.38%] [G loss: 0.913395]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "2568 [D loss: 0.615013, acc.: 65.62%] [G loss: 0.924390]\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "2569 [D loss: 0.618236, acc.: 68.75%] [G loss: 0.884366]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2570 [D loss: 0.541550, acc.: 65.62%] [G loss: 0.935766]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "2571 [D loss: 0.609870, acc.: 65.62%] [G loss: 0.891527]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "2572 [D loss: 0.680262, acc.: 65.62%] [G loss: 0.893056]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2573 [D loss: 0.576623, acc.: 75.00%] [G loss: 0.895535]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "2574 [D loss: 0.634760, acc.: 56.25%] [G loss: 0.868712]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2575 [D loss: 0.733494, acc.: 46.88%] [G loss: 0.901490]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2576 [D loss: 0.533062, acc.: 78.12%] [G loss: 0.912836]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "2577 [D loss: 0.683354, acc.: 56.25%] [G loss: 0.943799]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "2578 [D loss: 0.575938, acc.: 68.75%] [G loss: 0.911986]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2579 [D loss: 0.596894, acc.: 65.62%] [G loss: 0.907951]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2580 [D loss: 0.627072, acc.: 65.62%] [G loss: 0.987967]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "2581 [D loss: 0.646239, acc.: 71.88%] [G loss: 0.999007]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "2582 [D loss: 0.600571, acc.: 65.62%] [G loss: 0.888184]\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "2583 [D loss: 0.655639, acc.: 59.38%] [G loss: 0.805403]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2584 [D loss: 0.636288, acc.: 62.50%] [G loss: 0.839536]\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "2585 [D loss: 0.674147, acc.: 56.25%] [G loss: 0.900459]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2586 [D loss: 0.582709, acc.: 68.75%] [G loss: 0.988899]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2587 [D loss: 0.519317, acc.: 78.12%] [G loss: 0.967119]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2588 [D loss: 0.646654, acc.: 65.62%] [G loss: 0.992631]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2589 [D loss: 0.693592, acc.: 59.38%] [G loss: 0.878120]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2590 [D loss: 0.635547, acc.: 68.75%] [G loss: 0.895296]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2591 [D loss: 0.487904, acc.: 90.62%] [G loss: 1.000749]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2592 [D loss: 0.567295, acc.: 71.88%] [G loss: 1.001275]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2593 [D loss: 0.658125, acc.: 59.38%] [G loss: 0.921713]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2594 [D loss: 0.683196, acc.: 62.50%] [G loss: 0.885158]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2595 [D loss: 0.637165, acc.: 62.50%] [G loss: 0.870430]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2596 [D loss: 0.796861, acc.: 53.12%] [G loss: 0.981642]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2597 [D loss: 0.618096, acc.: 68.75%] [G loss: 0.897459]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2598 [D loss: 0.612168, acc.: 71.88%] [G loss: 0.969624]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2599 [D loss: 0.744832, acc.: 34.38%] [G loss: 0.829150]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2600 [D loss: 0.674788, acc.: 53.12%] [G loss: 0.811200]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2601 [D loss: 0.645186, acc.: 62.50%] [G loss: 0.922599]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2602 [D loss: 0.571742, acc.: 71.88%] [G loss: 0.979285]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2603 [D loss: 0.572957, acc.: 71.88%] [G loss: 0.925727]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2604 [D loss: 0.674180, acc.: 62.50%] [G loss: 0.876959]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2605 [D loss: 0.602760, acc.: 62.50%] [G loss: 0.855778]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2606 [D loss: 0.530275, acc.: 87.50%] [G loss: 0.851700]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2607 [D loss: 0.579539, acc.: 62.50%] [G loss: 0.833235]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2608 [D loss: 0.610075, acc.: 65.62%] [G loss: 0.955674]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2609 [D loss: 0.622236, acc.: 62.50%] [G loss: 0.929811]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2610 [D loss: 0.619559, acc.: 62.50%] [G loss: 0.961328]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2611 [D loss: 0.663879, acc.: 56.25%] [G loss: 1.074509]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2612 [D loss: 0.604035, acc.: 65.62%] [G loss: 1.021294]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2613 [D loss: 0.641238, acc.: 71.88%] [G loss: 0.976557]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2614 [D loss: 0.652337, acc.: 62.50%] [G loss: 0.901366]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2615 [D loss: 0.629788, acc.: 68.75%] [G loss: 0.950849]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2616 [D loss: 0.616112, acc.: 62.50%] [G loss: 0.888110]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2617 [D loss: 0.719440, acc.: 50.00%] [G loss: 0.907288]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2618 [D loss: 0.577093, acc.: 78.12%] [G loss: 0.850270]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2619 [D loss: 0.603938, acc.: 71.88%] [G loss: 0.905745]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2620 [D loss: 0.641255, acc.: 65.62%] [G loss: 1.024791]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2621 [D loss: 0.611559, acc.: 78.12%] [G loss: 1.033780]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2622 [D loss: 0.525270, acc.: 81.25%] [G loss: 0.990120]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2623 [D loss: 0.579529, acc.: 75.00%] [G loss: 1.011175]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2624 [D loss: 0.679656, acc.: 53.12%] [G loss: 0.861248]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2625 [D loss: 0.663727, acc.: 50.00%] [G loss: 1.002152]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2626 [D loss: 0.640392, acc.: 62.50%] [G loss: 0.969358]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2627 [D loss: 0.677726, acc.: 62.50%] [G loss: 1.113541]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2628 [D loss: 0.679946, acc.: 59.38%] [G loss: 0.987524]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2629 [D loss: 0.663425, acc.: 59.38%] [G loss: 0.889026]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2630 [D loss: 0.633916, acc.: 71.88%] [G loss: 0.876402]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2631 [D loss: 0.648607, acc.: 62.50%] [G loss: 0.957437]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2632 [D loss: 0.642077, acc.: 59.38%] [G loss: 0.852244]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2633 [D loss: 0.643659, acc.: 59.38%] [G loss: 0.831056]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2634 [D loss: 0.619825, acc.: 62.50%] [G loss: 0.772204]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2635 [D loss: 0.722929, acc.: 59.38%] [G loss: 0.870603]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2636 [D loss: 0.618940, acc.: 59.38%] [G loss: 0.964764]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2637 [D loss: 0.560813, acc.: 78.12%] [G loss: 0.907609]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2638 [D loss: 0.603137, acc.: 65.62%] [G loss: 0.912765]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2639 [D loss: 0.631688, acc.: 65.62%] [G loss: 0.839923]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2640 [D loss: 0.665962, acc.: 62.50%] [G loss: 0.887648]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2641 [D loss: 0.499877, acc.: 81.25%] [G loss: 0.924542]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2642 [D loss: 0.673477, acc.: 56.25%] [G loss: 0.838623]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2643 [D loss: 0.690821, acc.: 56.25%] [G loss: 0.871312]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2644 [D loss: 0.611421, acc.: 59.38%] [G loss: 0.873587]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2645 [D loss: 0.571311, acc.: 75.00%] [G loss: 0.933400]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2646 [D loss: 0.626109, acc.: 59.38%] [G loss: 0.899574]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2647 [D loss: 0.583529, acc.: 75.00%] [G loss: 0.956972]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2648 [D loss: 0.752133, acc.: 53.12%] [G loss: 0.879133]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2649 [D loss: 0.634069, acc.: 59.38%] [G loss: 0.970860]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2650 [D loss: 0.611707, acc.: 65.62%] [G loss: 0.869996]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2651 [D loss: 0.580134, acc.: 75.00%] [G loss: 0.896490]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2652 [D loss: 0.591902, acc.: 68.75%] [G loss: 0.992417]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2653 [D loss: 0.632951, acc.: 62.50%] [G loss: 0.932297]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2654 [D loss: 0.658979, acc.: 56.25%] [G loss: 0.873446]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2655 [D loss: 0.689464, acc.: 59.38%] [G loss: 0.904441]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2656 [D loss: 0.679539, acc.: 50.00%] [G loss: 0.857864]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2657 [D loss: 0.600980, acc.: 68.75%] [G loss: 0.889291]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2658 [D loss: 0.621890, acc.: 68.75%] [G loss: 0.862073]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2659 [D loss: 0.595121, acc.: 68.75%] [G loss: 0.906328]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2660 [D loss: 0.555438, acc.: 78.12%] [G loss: 0.833661]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2661 [D loss: 0.554415, acc.: 71.88%] [G loss: 0.913968]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2662 [D loss: 0.699811, acc.: 59.38%] [G loss: 0.819201]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2663 [D loss: 0.691850, acc.: 53.12%] [G loss: 0.828381]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2664 [D loss: 0.631199, acc.: 71.88%] [G loss: 0.914627]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2665 [D loss: 0.615551, acc.: 71.88%] [G loss: 0.878478]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2666 [D loss: 0.644384, acc.: 65.62%] [G loss: 0.910610]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2667 [D loss: 0.679617, acc.: 62.50%] [G loss: 0.874393]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2668 [D loss: 0.657857, acc.: 68.75%] [G loss: 0.928900]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2669 [D loss: 0.584783, acc.: 84.38%] [G loss: 0.886727]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2670 [D loss: 0.622092, acc.: 65.62%] [G loss: 0.936273]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "2671 [D loss: 0.659454, acc.: 56.25%] [G loss: 0.870355]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2672 [D loss: 0.689376, acc.: 62.50%] [G loss: 0.794946]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2673 [D loss: 0.635386, acc.: 65.62%] [G loss: 0.803527]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2674 [D loss: 0.579714, acc.: 68.75%] [G loss: 0.915493]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2675 [D loss: 0.728895, acc.: 46.88%] [G loss: 0.959319]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "2676 [D loss: 0.710130, acc.: 56.25%] [G loss: 0.978109]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "2677 [D loss: 0.641483, acc.: 56.25%] [G loss: 0.912734]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2678 [D loss: 0.601680, acc.: 71.88%] [G loss: 0.940562]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2679 [D loss: 0.725268, acc.: 50.00%] [G loss: 0.889005]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2680 [D loss: 0.686067, acc.: 46.88%] [G loss: 0.910799]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2681 [D loss: 0.588555, acc.: 81.25%] [G loss: 0.890910]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2682 [D loss: 0.665870, acc.: 56.25%] [G loss: 0.918872]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "2683 [D loss: 0.541674, acc.: 75.00%] [G loss: 0.911362]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2684 [D loss: 0.681344, acc.: 65.62%] [G loss: 0.947795]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2685 [D loss: 0.683372, acc.: 59.38%] [G loss: 0.860966]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2686 [D loss: 0.610214, acc.: 71.88%] [G loss: 0.902022]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2687 [D loss: 0.618188, acc.: 62.50%] [G loss: 0.969998]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2688 [D loss: 0.566481, acc.: 78.12%] [G loss: 0.954637]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "2689 [D loss: 0.636792, acc.: 59.38%] [G loss: 0.915352]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2690 [D loss: 0.541174, acc.: 78.12%] [G loss: 0.885552]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2691 [D loss: 0.570998, acc.: 75.00%] [G loss: 0.891372]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2692 [D loss: 0.608237, acc.: 68.75%] [G loss: 0.843722]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "2693 [D loss: 0.634414, acc.: 62.50%] [G loss: 0.853381]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2694 [D loss: 0.600191, acc.: 68.75%] [G loss: 0.925859]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2695 [D loss: 0.717240, acc.: 53.12%] [G loss: 0.896718]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2696 [D loss: 0.602416, acc.: 71.88%] [G loss: 0.982752]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2697 [D loss: 0.603500, acc.: 75.00%] [G loss: 0.941404]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2698 [D loss: 0.655203, acc.: 62.50%] [G loss: 0.933956]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2699 [D loss: 0.650910, acc.: 59.38%] [G loss: 0.906345]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2700 [D loss: 0.654368, acc.: 59.38%] [G loss: 0.988266]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2701 [D loss: 0.636764, acc.: 59.38%] [G loss: 0.914818]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2702 [D loss: 0.671126, acc.: 56.25%] [G loss: 0.926835]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2703 [D loss: 0.612996, acc.: 75.00%] [G loss: 0.871199]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2704 [D loss: 0.544651, acc.: 71.88%] [G loss: 0.882858]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2705 [D loss: 0.624554, acc.: 68.75%] [G loss: 0.894061]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2706 [D loss: 0.662859, acc.: 56.25%] [G loss: 0.797498]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2707 [D loss: 0.619136, acc.: 68.75%] [G loss: 0.802292]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2708 [D loss: 0.558347, acc.: 75.00%] [G loss: 0.872060]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2709 [D loss: 0.574662, acc.: 71.88%] [G loss: 0.871652]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2710 [D loss: 0.632399, acc.: 62.50%] [G loss: 0.841549]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2711 [D loss: 0.635532, acc.: 59.38%] [G loss: 0.894303]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2712 [D loss: 0.651674, acc.: 56.25%] [G loss: 0.869215]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2713 [D loss: 0.652420, acc.: 53.12%] [G loss: 0.962091]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2714 [D loss: 0.614925, acc.: 71.88%] [G loss: 0.847138]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2715 [D loss: 0.712409, acc.: 53.12%] [G loss: 0.918674]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2716 [D loss: 0.710243, acc.: 59.38%] [G loss: 0.864057]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "2717 [D loss: 0.569416, acc.: 78.12%] [G loss: 0.922211]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2718 [D loss: 0.656440, acc.: 71.88%] [G loss: 0.869629]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2719 [D loss: 0.655705, acc.: 62.50%] [G loss: 0.917894]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2720 [D loss: 0.638207, acc.: 62.50%] [G loss: 0.915025]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2721 [D loss: 0.651035, acc.: 59.38%] [G loss: 0.857452]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2722 [D loss: 0.618771, acc.: 62.50%] [G loss: 0.902714]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2723 [D loss: 0.633342, acc.: 68.75%] [G loss: 0.928815]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2724 [D loss: 0.634231, acc.: 62.50%] [G loss: 0.922835]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2725 [D loss: 0.588960, acc.: 71.88%] [G loss: 0.938856]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2726 [D loss: 0.658931, acc.: 62.50%] [G loss: 0.899483]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2727 [D loss: 0.684676, acc.: 56.25%] [G loss: 0.927567]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2728 [D loss: 0.569216, acc.: 75.00%] [G loss: 0.894499]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "2729 [D loss: 0.490863, acc.: 78.12%] [G loss: 0.949868]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2730 [D loss: 0.670721, acc.: 50.00%] [G loss: 0.923644]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2731 [D loss: 0.695831, acc.: 65.62%] [G loss: 0.903972]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2732 [D loss: 0.607027, acc.: 68.75%] [G loss: 0.897951]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2733 [D loss: 0.561691, acc.: 75.00%] [G loss: 0.877144]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2734 [D loss: 0.615857, acc.: 62.50%] [G loss: 0.778992]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2735 [D loss: 0.659338, acc.: 56.25%] [G loss: 0.942762]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2736 [D loss: 0.647921, acc.: 59.38%] [G loss: 0.951189]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2737 [D loss: 0.587104, acc.: 78.12%] [G loss: 0.904982]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2738 [D loss: 0.666575, acc.: 59.38%] [G loss: 0.887856]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2739 [D loss: 0.678465, acc.: 59.38%] [G loss: 0.935404]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2740 [D loss: 0.650646, acc.: 65.62%] [G loss: 0.922018]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2741 [D loss: 0.780453, acc.: 46.88%] [G loss: 0.866950]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2742 [D loss: 0.661465, acc.: 59.38%] [G loss: 0.946442]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2743 [D loss: 0.624076, acc.: 75.00%] [G loss: 0.875858]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2744 [D loss: 0.541620, acc.: 84.38%] [G loss: 0.872429]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2745 [D loss: 0.557033, acc.: 75.00%] [G loss: 0.857977]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2746 [D loss: 0.639356, acc.: 65.62%] [G loss: 0.882187]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2747 [D loss: 0.613924, acc.: 68.75%] [G loss: 0.909848]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2748 [D loss: 0.591940, acc.: 68.75%] [G loss: 0.939965]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2749 [D loss: 0.563413, acc.: 75.00%] [G loss: 0.940055]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2750 [D loss: 0.591214, acc.: 68.75%] [G loss: 0.912259]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2751 [D loss: 0.618492, acc.: 59.38%] [G loss: 0.981504]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2752 [D loss: 0.591306, acc.: 65.62%] [G loss: 0.931815]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2753 [D loss: 0.580581, acc.: 65.62%] [G loss: 0.876237]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2754 [D loss: 0.670566, acc.: 56.25%] [G loss: 0.854359]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2755 [D loss: 0.471544, acc.: 87.50%] [G loss: 1.015893]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2756 [D loss: 0.634967, acc.: 71.88%] [G loss: 1.043986]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2757 [D loss: 0.611034, acc.: 68.75%] [G loss: 1.007819]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2758 [D loss: 0.672926, acc.: 50.00%] [G loss: 0.964461]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2759 [D loss: 0.604800, acc.: 68.75%] [G loss: 0.902331]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2760 [D loss: 0.659995, acc.: 65.62%] [G loss: 0.845067]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2761 [D loss: 0.685118, acc.: 56.25%] [G loss: 0.897485]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2762 [D loss: 0.656914, acc.: 62.50%] [G loss: 0.968505]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2763 [D loss: 0.587916, acc.: 71.88%] [G loss: 0.955444]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2764 [D loss: 0.632216, acc.: 59.38%] [G loss: 0.991384]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2765 [D loss: 0.576945, acc.: 65.62%] [G loss: 0.972421]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2766 [D loss: 0.579186, acc.: 75.00%] [G loss: 0.991500]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2767 [D loss: 0.720514, acc.: 50.00%] [G loss: 0.951675]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2768 [D loss: 0.690828, acc.: 59.38%] [G loss: 0.959650]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2769 [D loss: 0.648878, acc.: 62.50%] [G loss: 1.069267]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2770 [D loss: 0.642632, acc.: 62.50%] [G loss: 0.956014]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2771 [D loss: 0.571626, acc.: 71.88%] [G loss: 1.011631]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2772 [D loss: 0.611694, acc.: 71.88%] [G loss: 1.014183]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2773 [D loss: 0.584748, acc.: 68.75%] [G loss: 0.937041]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2774 [D loss: 0.706625, acc.: 50.00%] [G loss: 0.872616]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2775 [D loss: 0.604529, acc.: 68.75%] [G loss: 0.973474]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2776 [D loss: 0.533749, acc.: 78.12%] [G loss: 0.964963]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2777 [D loss: 0.665218, acc.: 53.12%] [G loss: 0.865179]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2778 [D loss: 0.785748, acc.: 50.00%] [G loss: 1.031160]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2779 [D loss: 0.610518, acc.: 59.38%] [G loss: 0.986321]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2780 [D loss: 0.607911, acc.: 75.00%] [G loss: 0.934731]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2781 [D loss: 0.683009, acc.: 53.12%] [G loss: 1.011402]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2782 [D loss: 0.537362, acc.: 84.38%] [G loss: 0.927518]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2783 [D loss: 0.595406, acc.: 71.88%] [G loss: 0.885156]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2784 [D loss: 0.561877, acc.: 78.12%] [G loss: 0.925815]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2785 [D loss: 0.667523, acc.: 56.25%] [G loss: 0.926807]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2786 [D loss: 0.521641, acc.: 81.25%] [G loss: 0.862079]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2787 [D loss: 0.595691, acc.: 65.62%] [G loss: 0.978051]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "2788 [D loss: 0.604892, acc.: 56.25%] [G loss: 0.973647]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "2789 [D loss: 0.608418, acc.: 65.62%] [G loss: 0.953913]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2790 [D loss: 0.595130, acc.: 71.88%] [G loss: 1.015207]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2791 [D loss: 0.675329, acc.: 56.25%] [G loss: 0.970015]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2792 [D loss: 0.641776, acc.: 62.50%] [G loss: 0.945538]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "2793 [D loss: 0.615810, acc.: 65.62%] [G loss: 0.901337]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "2794 [D loss: 0.617818, acc.: 65.62%] [G loss: 0.875522]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2795 [D loss: 0.712602, acc.: 56.25%] [G loss: 0.871390]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2796 [D loss: 0.691838, acc.: 59.38%] [G loss: 0.933065]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2797 [D loss: 0.583258, acc.: 75.00%] [G loss: 0.870811]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2798 [D loss: 0.619427, acc.: 68.75%] [G loss: 0.831579]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2799 [D loss: 0.623233, acc.: 65.62%] [G loss: 0.885055]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2800 [D loss: 0.612815, acc.: 65.62%] [G loss: 0.903687]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "2801 [D loss: 0.539297, acc.: 84.38%] [G loss: 0.981286]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "2802 [D loss: 0.628896, acc.: 68.75%] [G loss: 1.039778]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "2803 [D loss: 0.703623, acc.: 43.75%] [G loss: 0.944986]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2804 [D loss: 0.514622, acc.: 78.12%] [G loss: 1.038325]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2805 [D loss: 0.639745, acc.: 59.38%] [G loss: 1.047875]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2806 [D loss: 0.688677, acc.: 62.50%] [G loss: 0.886754]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2807 [D loss: 0.586731, acc.: 71.88%] [G loss: 1.072224]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2808 [D loss: 0.709900, acc.: 56.25%] [G loss: 0.988245]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "2809 [D loss: 0.712423, acc.: 53.12%] [G loss: 0.920987]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "2810 [D loss: 0.613204, acc.: 68.75%] [G loss: 0.947757]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2811 [D loss: 0.552297, acc.: 84.38%] [G loss: 0.935297]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2812 [D loss: 0.631822, acc.: 68.75%] [G loss: 0.864219]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2813 [D loss: 0.592327, acc.: 68.75%] [G loss: 0.916097]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2814 [D loss: 0.538775, acc.: 71.88%] [G loss: 0.926420]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2815 [D loss: 0.619819, acc.: 59.38%] [G loss: 0.843230]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2816 [D loss: 0.656926, acc.: 68.75%] [G loss: 0.962533]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2817 [D loss: 0.608909, acc.: 68.75%] [G loss: 0.952229]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2818 [D loss: 0.632958, acc.: 59.38%] [G loss: 0.916902]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2819 [D loss: 0.559436, acc.: 71.88%] [G loss: 1.003119]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2820 [D loss: 0.635462, acc.: 65.62%] [G loss: 0.911460]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2821 [D loss: 0.759143, acc.: 50.00%] [G loss: 0.940630]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2822 [D loss: 0.562275, acc.: 87.50%] [G loss: 0.981036]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2823 [D loss: 0.567133, acc.: 71.88%] [G loss: 1.043534]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2824 [D loss: 0.735575, acc.: 50.00%] [G loss: 0.965530]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2825 [D loss: 0.540245, acc.: 78.12%] [G loss: 0.984935]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2826 [D loss: 0.596293, acc.: 75.00%] [G loss: 0.887079]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2827 [D loss: 0.608447, acc.: 68.75%] [G loss: 0.845223]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2828 [D loss: 0.622305, acc.: 53.12%] [G loss: 0.816886]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2829 [D loss: 0.466112, acc.: 87.50%] [G loss: 0.930639]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2830 [D loss: 0.658584, acc.: 59.38%] [G loss: 0.882730]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2831 [D loss: 0.563017, acc.: 78.12%] [G loss: 0.899149]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2832 [D loss: 0.672358, acc.: 59.38%] [G loss: 0.794201]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2833 [D loss: 0.662668, acc.: 62.50%] [G loss: 0.902145]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2834 [D loss: 0.658299, acc.: 62.50%] [G loss: 0.866517]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2835 [D loss: 0.603210, acc.: 65.62%] [G loss: 0.982760]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2836 [D loss: 0.649264, acc.: 68.75%] [G loss: 1.012075]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2837 [D loss: 0.535346, acc.: 78.12%] [G loss: 1.012545]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2838 [D loss: 0.552890, acc.: 78.12%] [G loss: 0.892537]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2839 [D loss: 0.566373, acc.: 78.12%] [G loss: 0.923921]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2840 [D loss: 0.633509, acc.: 62.50%] [G loss: 0.911283]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2841 [D loss: 0.679994, acc.: 56.25%] [G loss: 0.976707]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2842 [D loss: 0.627503, acc.: 71.88%] [G loss: 1.038758]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2843 [D loss: 0.615575, acc.: 56.25%] [G loss: 1.056038]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2844 [D loss: 0.643162, acc.: 53.12%] [G loss: 0.928765]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2845 [D loss: 0.553483, acc.: 78.12%] [G loss: 0.998051]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2846 [D loss: 0.644841, acc.: 56.25%] [G loss: 0.870870]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2847 [D loss: 0.573933, acc.: 75.00%] [G loss: 0.877821]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2848 [D loss: 0.608909, acc.: 71.88%] [G loss: 0.984075]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2849 [D loss: 0.629315, acc.: 71.88%] [G loss: 0.936445]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2850 [D loss: 0.641591, acc.: 56.25%] [G loss: 1.037922]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2851 [D loss: 0.534491, acc.: 78.12%] [G loss: 0.999441]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2852 [D loss: 0.637163, acc.: 65.62%] [G loss: 0.943380]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2853 [D loss: 0.581625, acc.: 71.88%] [G loss: 0.913176]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2854 [D loss: 0.653959, acc.: 75.00%] [G loss: 0.929283]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2855 [D loss: 0.584401, acc.: 68.75%] [G loss: 1.000265]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2856 [D loss: 0.781689, acc.: 43.75%] [G loss: 0.845057]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2857 [D loss: 0.571901, acc.: 78.12%] [G loss: 0.861513]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2858 [D loss: 0.624832, acc.: 68.75%] [G loss: 0.898697]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2859 [D loss: 0.603187, acc.: 65.62%] [G loss: 0.829668]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2860 [D loss: 0.579372, acc.: 71.88%] [G loss: 0.881364]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2861 [D loss: 0.650907, acc.: 68.75%] [G loss: 0.953811]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2862 [D loss: 0.643561, acc.: 53.12%] [G loss: 0.942578]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2863 [D loss: 0.640550, acc.: 65.62%] [G loss: 0.923334]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2864 [D loss: 0.508117, acc.: 81.25%] [G loss: 0.952146]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2865 [D loss: 0.672264, acc.: 62.50%] [G loss: 0.890793]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2866 [D loss: 0.638274, acc.: 56.25%] [G loss: 0.838843]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2867 [D loss: 0.630577, acc.: 65.62%] [G loss: 0.784637]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2868 [D loss: 0.589735, acc.: 75.00%] [G loss: 0.868236]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2869 [D loss: 0.667428, acc.: 53.12%] [G loss: 0.907563]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2870 [D loss: 0.745623, acc.: 46.88%] [G loss: 0.885881]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2871 [D loss: 0.648399, acc.: 62.50%] [G loss: 0.992141]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2872 [D loss: 0.562058, acc.: 75.00%] [G loss: 1.022858]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2873 [D loss: 0.665680, acc.: 62.50%] [G loss: 0.996360]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2874 [D loss: 0.610126, acc.: 59.38%] [G loss: 0.875466]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2875 [D loss: 0.650547, acc.: 71.88%] [G loss: 0.985681]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2876 [D loss: 0.722520, acc.: 53.12%] [G loss: 1.005637]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2877 [D loss: 0.597850, acc.: 65.62%] [G loss: 0.969170]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2878 [D loss: 0.641818, acc.: 68.75%] [G loss: 0.898583]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2879 [D loss: 0.721702, acc.: 53.12%] [G loss: 0.945427]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2880 [D loss: 0.612818, acc.: 62.50%] [G loss: 1.008907]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2881 [D loss: 0.795585, acc.: 43.75%] [G loss: 0.968534]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2882 [D loss: 0.528649, acc.: 84.38%] [G loss: 1.009099]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2883 [D loss: 0.650952, acc.: 43.75%] [G loss: 0.941146]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2884 [D loss: 0.599355, acc.: 59.38%] [G loss: 0.917452]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2885 [D loss: 0.616150, acc.: 71.88%] [G loss: 0.926773]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2886 [D loss: 0.593709, acc.: 71.88%] [G loss: 1.030557]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2887 [D loss: 0.542375, acc.: 68.75%] [G loss: 1.059508]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2888 [D loss: 0.581668, acc.: 71.88%] [G loss: 1.000369]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2889 [D loss: 0.567944, acc.: 71.88%] [G loss: 0.898164]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2890 [D loss: 0.670783, acc.: 50.00%] [G loss: 0.872107]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2891 [D loss: 0.666207, acc.: 59.38%] [G loss: 0.870993]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2892 [D loss: 0.546988, acc.: 78.12%] [G loss: 0.967117]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2893 [D loss: 0.649248, acc.: 65.62%] [G loss: 0.916281]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2894 [D loss: 0.646022, acc.: 65.62%] [G loss: 0.940272]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2895 [D loss: 0.604773, acc.: 75.00%] [G loss: 0.893287]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2896 [D loss: 0.677097, acc.: 59.38%] [G loss: 0.867636]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2897 [D loss: 0.623583, acc.: 62.50%] [G loss: 0.840537]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2898 [D loss: 0.573101, acc.: 75.00%] [G loss: 0.879528]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2899 [D loss: 0.674992, acc.: 59.38%] [G loss: 0.878345]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2900 [D loss: 0.688704, acc.: 56.25%] [G loss: 0.837192]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2901 [D loss: 0.597975, acc.: 71.88%] [G loss: 0.943695]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2902 [D loss: 0.619116, acc.: 71.88%] [G loss: 1.053433]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "2903 [D loss: 0.610904, acc.: 71.88%] [G loss: 0.944537]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2904 [D loss: 0.572593, acc.: 71.88%] [G loss: 0.949305]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2905 [D loss: 0.609552, acc.: 65.62%] [G loss: 0.960979]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "2906 [D loss: 0.683972, acc.: 50.00%] [G loss: 0.903197]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2907 [D loss: 0.685078, acc.: 53.12%] [G loss: 0.936335]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2908 [D loss: 0.633283, acc.: 68.75%] [G loss: 0.933308]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2909 [D loss: 0.616904, acc.: 68.75%] [G loss: 0.950438]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2910 [D loss: 0.595836, acc.: 65.62%] [G loss: 0.860502]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "2911 [D loss: 0.620872, acc.: 62.50%] [G loss: 0.875508]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2912 [D loss: 0.630519, acc.: 65.62%] [G loss: 0.930100]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2913 [D loss: 0.648923, acc.: 75.00%] [G loss: 0.929485]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "2914 [D loss: 0.644488, acc.: 65.62%] [G loss: 0.929238]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2915 [D loss: 0.647220, acc.: 59.38%] [G loss: 0.866707]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2916 [D loss: 0.601735, acc.: 68.75%] [G loss: 0.928069]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2917 [D loss: 0.663413, acc.: 65.62%] [G loss: 0.899971]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2918 [D loss: 0.674117, acc.: 56.25%] [G loss: 0.913666]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2919 [D loss: 0.607712, acc.: 62.50%] [G loss: 0.896975]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2920 [D loss: 0.558671, acc.: 75.00%] [G loss: 0.989836]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2921 [D loss: 0.638205, acc.: 68.75%] [G loss: 1.012691]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2922 [D loss: 0.644931, acc.: 56.25%] [G loss: 0.966018]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2923 [D loss: 0.597150, acc.: 71.88%] [G loss: 0.998314]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2924 [D loss: 0.625313, acc.: 62.50%] [G loss: 0.994022]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2925 [D loss: 0.646957, acc.: 71.88%] [G loss: 0.930806]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2926 [D loss: 0.603059, acc.: 65.62%] [G loss: 1.036923]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2927 [D loss: 0.620250, acc.: 68.75%] [G loss: 0.950736]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2928 [D loss: 0.555584, acc.: 68.75%] [G loss: 1.028133]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2929 [D loss: 0.615404, acc.: 65.62%] [G loss: 0.920049]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2930 [D loss: 0.718051, acc.: 53.12%] [G loss: 0.830806]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2931 [D loss: 0.566830, acc.: 78.12%] [G loss: 0.882799]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2932 [D loss: 0.616755, acc.: 68.75%] [G loss: 0.909541]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2933 [D loss: 0.592117, acc.: 68.75%] [G loss: 0.993501]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2934 [D loss: 0.712732, acc.: 53.12%] [G loss: 0.981238]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2935 [D loss: 0.638908, acc.: 59.38%] [G loss: 0.826538]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2936 [D loss: 0.685287, acc.: 56.25%] [G loss: 0.838892]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2937 [D loss: 0.622763, acc.: 65.62%] [G loss: 0.900854]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2938 [D loss: 0.604202, acc.: 75.00%] [G loss: 0.978266]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2939 [D loss: 0.523856, acc.: 81.25%] [G loss: 0.947382]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2940 [D loss: 0.580389, acc.: 71.88%] [G loss: 0.954118]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2941 [D loss: 0.660732, acc.: 59.38%] [G loss: 0.975168]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2942 [D loss: 0.578169, acc.: 68.75%] [G loss: 0.920841]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2943 [D loss: 0.610180, acc.: 71.88%] [G loss: 0.955272]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2944 [D loss: 0.575388, acc.: 78.12%] [G loss: 0.950179]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2945 [D loss: 0.575801, acc.: 68.75%] [G loss: 0.935157]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2946 [D loss: 0.560763, acc.: 75.00%] [G loss: 0.894239]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2947 [D loss: 0.684539, acc.: 53.12%] [G loss: 0.881040]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2948 [D loss: 0.660765, acc.: 56.25%] [G loss: 0.924120]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2949 [D loss: 0.652634, acc.: 59.38%] [G loss: 0.912488]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2950 [D loss: 0.577917, acc.: 71.88%] [G loss: 0.968363]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2951 [D loss: 0.597183, acc.: 75.00%] [G loss: 0.998407]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2952 [D loss: 0.491709, acc.: 81.25%] [G loss: 0.958515]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2953 [D loss: 0.595599, acc.: 65.62%] [G loss: 1.008358]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2954 [D loss: 0.558015, acc.: 75.00%] [G loss: 1.010006]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2955 [D loss: 0.660531, acc.: 56.25%] [G loss: 0.953581]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2956 [D loss: 0.585283, acc.: 71.88%] [G loss: 0.966251]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2957 [D loss: 0.645356, acc.: 62.50%] [G loss: 0.890456]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2958 [D loss: 0.618566, acc.: 71.88%] [G loss: 0.847477]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2959 [D loss: 0.618665, acc.: 71.88%] [G loss: 0.903274]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2960 [D loss: 0.618394, acc.: 59.38%] [G loss: 0.930057]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2961 [D loss: 0.623966, acc.: 71.88%] [G loss: 0.978499]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2962 [D loss: 0.622345, acc.: 62.50%] [G loss: 0.883459]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2963 [D loss: 0.567944, acc.: 71.88%] [G loss: 0.983453]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2964 [D loss: 0.660360, acc.: 59.38%] [G loss: 0.964865]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2965 [D loss: 0.562225, acc.: 71.88%] [G loss: 0.925150]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2966 [D loss: 0.552238, acc.: 75.00%] [G loss: 0.934622]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2967 [D loss: 0.686407, acc.: 56.25%] [G loss: 0.935360]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2968 [D loss: 0.552700, acc.: 75.00%] [G loss: 0.923397]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2969 [D loss: 0.556873, acc.: 78.12%] [G loss: 0.913071]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2970 [D loss: 0.629798, acc.: 62.50%] [G loss: 0.930783]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2971 [D loss: 0.616295, acc.: 65.62%] [G loss: 0.923546]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2972 [D loss: 0.619553, acc.: 65.62%] [G loss: 0.926420]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2973 [D loss: 0.601660, acc.: 71.88%] [G loss: 0.983988]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2974 [D loss: 0.576385, acc.: 81.25%] [G loss: 0.920742]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2975 [D loss: 0.703753, acc.: 59.38%] [G loss: 0.811268]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2976 [D loss: 0.585224, acc.: 75.00%] [G loss: 0.913868]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2977 [D loss: 0.593760, acc.: 68.75%] [G loss: 0.963145]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2978 [D loss: 0.682572, acc.: 56.25%] [G loss: 0.958024]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2979 [D loss: 0.597120, acc.: 75.00%] [G loss: 0.937563]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2980 [D loss: 0.643739, acc.: 59.38%] [G loss: 0.953134]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2981 [D loss: 0.623244, acc.: 62.50%] [G loss: 0.869880]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2982 [D loss: 0.619715, acc.: 65.62%] [G loss: 0.920045]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2983 [D loss: 0.693958, acc.: 62.50%] [G loss: 0.958556]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2984 [D loss: 0.638976, acc.: 62.50%] [G loss: 1.037407]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2985 [D loss: 0.676622, acc.: 68.75%] [G loss: 0.979995]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2986 [D loss: 0.685333, acc.: 53.12%] [G loss: 0.946846]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2987 [D loss: 0.612917, acc.: 68.75%] [G loss: 0.935067]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2988 [D loss: 0.667661, acc.: 59.38%] [G loss: 0.874363]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2989 [D loss: 0.705054, acc.: 50.00%] [G loss: 0.816648]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2990 [D loss: 0.600098, acc.: 71.88%] [G loss: 0.882056]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2991 [D loss: 0.663592, acc.: 68.75%] [G loss: 0.905916]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2992 [D loss: 0.648128, acc.: 50.00%] [G loss: 0.924481]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2993 [D loss: 0.631344, acc.: 62.50%] [G loss: 0.881698]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2994 [D loss: 0.673868, acc.: 62.50%] [G loss: 0.823013]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2995 [D loss: 0.697552, acc.: 50.00%] [G loss: 0.841357]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2996 [D loss: 0.690039, acc.: 65.62%] [G loss: 0.879727]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2997 [D loss: 0.682370, acc.: 46.88%] [G loss: 0.878350]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2998 [D loss: 0.622303, acc.: 62.50%] [G loss: 0.898418]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2999 [D loss: 0.695387, acc.: 53.12%] [G loss: 0.888618]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3000 [D loss: 0.618584, acc.: 62.50%] [G loss: 0.839915]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3001 [D loss: 0.660372, acc.: 59.38%] [G loss: 0.953535]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3002 [D loss: 0.635419, acc.: 65.62%] [G loss: 0.850161]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3003 [D loss: 0.624502, acc.: 71.88%] [G loss: 0.859789]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "3004 [D loss: 0.663885, acc.: 59.38%] [G loss: 0.964835]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3005 [D loss: 0.607802, acc.: 71.88%] [G loss: 0.903961]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3006 [D loss: 0.626006, acc.: 65.62%] [G loss: 0.908325]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3007 [D loss: 0.600057, acc.: 65.62%] [G loss: 1.020882]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3008 [D loss: 0.705141, acc.: 50.00%] [G loss: 0.923208]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3009 [D loss: 0.583477, acc.: 71.88%] [G loss: 0.918883]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3010 [D loss: 0.613671, acc.: 65.62%] [G loss: 0.973526]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "3011 [D loss: 0.566440, acc.: 75.00%] [G loss: 0.994529]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3012 [D loss: 0.653183, acc.: 59.38%] [G loss: 0.909075]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3013 [D loss: 0.622638, acc.: 65.62%] [G loss: 1.014043]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3014 [D loss: 0.689072, acc.: 56.25%] [G loss: 0.938685]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3015 [D loss: 0.674748, acc.: 53.12%] [G loss: 0.849907]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3016 [D loss: 0.566586, acc.: 71.88%] [G loss: 0.874468]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3017 [D loss: 0.651126, acc.: 65.62%] [G loss: 0.889403]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3018 [D loss: 0.671833, acc.: 68.75%] [G loss: 0.933353]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3019 [D loss: 0.620222, acc.: 62.50%] [G loss: 0.928953]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3020 [D loss: 0.653643, acc.: 65.62%] [G loss: 0.896242]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3021 [D loss: 0.646776, acc.: 56.25%] [G loss: 0.896714]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3022 [D loss: 0.633831, acc.: 78.12%] [G loss: 0.919102]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3023 [D loss: 0.675658, acc.: 59.38%] [G loss: 0.937908]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3024 [D loss: 0.570064, acc.: 81.25%] [G loss: 0.986143]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3025 [D loss: 0.627943, acc.: 56.25%] [G loss: 0.937935]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3026 [D loss: 0.709217, acc.: 50.00%] [G loss: 0.948328]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3027 [D loss: 0.680677, acc.: 50.00%] [G loss: 0.955500]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3028 [D loss: 0.616249, acc.: 62.50%] [G loss: 0.957555]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3029 [D loss: 0.673411, acc.: 62.50%] [G loss: 0.935623]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3030 [D loss: 0.644001, acc.: 71.88%] [G loss: 1.042776]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3031 [D loss: 0.639453, acc.: 65.62%] [G loss: 1.026459]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3032 [D loss: 0.697311, acc.: 46.88%] [G loss: 0.929091]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3033 [D loss: 0.515109, acc.: 84.38%] [G loss: 0.890014]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3034 [D loss: 0.623094, acc.: 65.62%] [G loss: 0.913152]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3035 [D loss: 0.679172, acc.: 65.62%] [G loss: 0.906540]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3036 [D loss: 0.591847, acc.: 71.88%] [G loss: 0.914669]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3037 [D loss: 0.700897, acc.: 56.25%] [G loss: 0.920057]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3038 [D loss: 0.694792, acc.: 50.00%] [G loss: 0.786700]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3039 [D loss: 0.605639, acc.: 68.75%] [G loss: 0.936098]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3040 [D loss: 0.605905, acc.: 65.62%] [G loss: 0.896907]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3041 [D loss: 0.635723, acc.: 71.88%] [G loss: 0.869819]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3042 [D loss: 0.562778, acc.: 71.88%] [G loss: 0.874630]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3043 [D loss: 0.670376, acc.: 65.62%] [G loss: 0.905233]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3044 [D loss: 0.643439, acc.: 59.38%] [G loss: 0.953559]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3045 [D loss: 0.701269, acc.: 56.25%] [G loss: 0.934915]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3046 [D loss: 0.733231, acc.: 46.88%] [G loss: 0.908326]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3047 [D loss: 0.603772, acc.: 62.50%] [G loss: 1.020344]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3048 [D loss: 0.651307, acc.: 68.75%] [G loss: 1.062462]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3049 [D loss: 0.666697, acc.: 65.62%] [G loss: 0.980602]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3050 [D loss: 0.637507, acc.: 62.50%] [G loss: 0.921421]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3051 [D loss: 0.596537, acc.: 75.00%] [G loss: 0.923608]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3052 [D loss: 0.638502, acc.: 56.25%] [G loss: 1.011031]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3053 [D loss: 0.619109, acc.: 71.88%] [G loss: 0.952871]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3054 [D loss: 0.634784, acc.: 59.38%] [G loss: 0.825879]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3055 [D loss: 0.622764, acc.: 65.62%] [G loss: 0.874176]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3056 [D loss: 0.706445, acc.: 59.38%] [G loss: 0.794213]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3057 [D loss: 0.609891, acc.: 65.62%] [G loss: 0.848776]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3058 [D loss: 0.700257, acc.: 53.12%] [G loss: 0.864149]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3059 [D loss: 0.604152, acc.: 65.62%] [G loss: 0.790584]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3060 [D loss: 0.592472, acc.: 65.62%] [G loss: 0.938515]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3061 [D loss: 0.659265, acc.: 65.62%] [G loss: 0.892572]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3062 [D loss: 0.668412, acc.: 56.25%] [G loss: 0.900345]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3063 [D loss: 0.638761, acc.: 71.88%] [G loss: 0.847369]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3064 [D loss: 0.677752, acc.: 56.25%] [G loss: 0.980874]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3065 [D loss: 0.625961, acc.: 68.75%] [G loss: 0.974882]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3066 [D loss: 0.647391, acc.: 59.38%] [G loss: 0.960718]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3067 [D loss: 0.663177, acc.: 59.38%] [G loss: 0.913736]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3068 [D loss: 0.615469, acc.: 68.75%] [G loss: 0.866823]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3069 [D loss: 0.588401, acc.: 65.62%] [G loss: 0.847478]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3070 [D loss: 0.625475, acc.: 62.50%] [G loss: 0.889882]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3071 [D loss: 0.615459, acc.: 62.50%] [G loss: 0.908737]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3072 [D loss: 0.728640, acc.: 43.75%] [G loss: 0.853094]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3073 [D loss: 0.625794, acc.: 71.88%] [G loss: 0.888189]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3074 [D loss: 0.644456, acc.: 62.50%] [G loss: 0.963089]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3075 [D loss: 0.531660, acc.: 81.25%] [G loss: 1.027360]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3076 [D loss: 0.606271, acc.: 71.88%] [G loss: 0.937081]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3077 [D loss: 0.643552, acc.: 65.62%] [G loss: 0.890844]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3078 [D loss: 0.827640, acc.: 34.38%] [G loss: 0.818820]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3079 [D loss: 0.569250, acc.: 71.88%] [G loss: 0.842020]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3080 [D loss: 0.633180, acc.: 78.12%] [G loss: 0.888102]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3081 [D loss: 0.626014, acc.: 65.62%] [G loss: 0.843034]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3082 [D loss: 0.632058, acc.: 62.50%] [G loss: 0.880623]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3083 [D loss: 0.620861, acc.: 62.50%] [G loss: 0.836475]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3084 [D loss: 0.648722, acc.: 62.50%] [G loss: 0.957719]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3085 [D loss: 0.647822, acc.: 59.38%] [G loss: 0.855448]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3086 [D loss: 0.740237, acc.: 50.00%] [G loss: 0.902338]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3087 [D loss: 0.663371, acc.: 53.12%] [G loss: 0.888188]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3088 [D loss: 0.710532, acc.: 40.62%] [G loss: 0.907509]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3089 [D loss: 0.677271, acc.: 62.50%] [G loss: 0.942102]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3090 [D loss: 0.643105, acc.: 65.62%] [G loss: 0.964963]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3091 [D loss: 0.607436, acc.: 65.62%] [G loss: 0.878220]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3092 [D loss: 0.638592, acc.: 56.25%] [G loss: 0.887923]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3093 [D loss: 0.617358, acc.: 50.00%] [G loss: 0.928942]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3094 [D loss: 0.696712, acc.: 59.38%] [G loss: 1.016965]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3095 [D loss: 0.664685, acc.: 56.25%] [G loss: 0.989340]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3096 [D loss: 0.603277, acc.: 71.88%] [G loss: 0.951742]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3097 [D loss: 0.703079, acc.: 50.00%] [G loss: 0.850780]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3098 [D loss: 0.619850, acc.: 71.88%] [G loss: 0.879942]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3099 [D loss: 0.681908, acc.: 59.38%] [G loss: 0.934170]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3100 [D loss: 0.600425, acc.: 71.88%] [G loss: 0.967374]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3101 [D loss: 0.662446, acc.: 56.25%] [G loss: 0.888962]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3102 [D loss: 0.667066, acc.: 53.12%] [G loss: 0.986695]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3103 [D loss: 0.628285, acc.: 75.00%] [G loss: 0.871801]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3104 [D loss: 0.720964, acc.: 59.38%] [G loss: 0.842554]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3105 [D loss: 0.702243, acc.: 59.38%] [G loss: 0.814821]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3106 [D loss: 0.633333, acc.: 71.88%] [G loss: 0.780039]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3107 [D loss: 0.667367, acc.: 65.62%] [G loss: 0.864457]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3108 [D loss: 0.658442, acc.: 62.50%] [G loss: 0.883055]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3109 [D loss: 0.698344, acc.: 56.25%] [G loss: 0.896803]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3110 [D loss: 0.627254, acc.: 56.25%] [G loss: 0.865487]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3111 [D loss: 0.606379, acc.: 65.62%] [G loss: 0.949428]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "3112 [D loss: 0.663262, acc.: 62.50%] [G loss: 0.957887]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3113 [D loss: 0.586115, acc.: 68.75%] [G loss: 0.939618]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3114 [D loss: 0.606406, acc.: 65.62%] [G loss: 0.912854]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3115 [D loss: 0.614737, acc.: 71.88%] [G loss: 0.928469]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3116 [D loss: 0.670326, acc.: 59.38%] [G loss: 0.863981]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3117 [D loss: 0.597119, acc.: 65.62%] [G loss: 0.918488]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3118 [D loss: 0.626588, acc.: 62.50%] [G loss: 0.922173]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "3119 [D loss: 0.587905, acc.: 68.75%] [G loss: 0.930569]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3120 [D loss: 0.658886, acc.: 65.62%] [G loss: 0.813822]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3121 [D loss: 0.588244, acc.: 65.62%] [G loss: 0.850291]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3122 [D loss: 0.555219, acc.: 75.00%] [G loss: 0.837079]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3123 [D loss: 0.585283, acc.: 68.75%] [G loss: 0.893851]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "3124 [D loss: 0.520979, acc.: 81.25%] [G loss: 0.884184]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "3125 [D loss: 0.602239, acc.: 71.88%] [G loss: 0.886299]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3126 [D loss: 0.814195, acc.: 50.00%] [G loss: 0.924433]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3127 [D loss: 0.699159, acc.: 65.62%] [G loss: 0.891572]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3128 [D loss: 0.655993, acc.: 59.38%] [G loss: 0.867862]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3129 [D loss: 0.562984, acc.: 75.00%] [G loss: 0.878742]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3130 [D loss: 0.644828, acc.: 62.50%] [G loss: 0.883237]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3131 [D loss: 0.654119, acc.: 56.25%] [G loss: 0.905342]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3132 [D loss: 0.598507, acc.: 71.88%] [G loss: 0.853032]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3133 [D loss: 0.637593, acc.: 62.50%] [G loss: 0.895994]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3134 [D loss: 0.711257, acc.: 59.38%] [G loss: 0.907062]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3135 [D loss: 0.653145, acc.: 65.62%] [G loss: 0.920473]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3136 [D loss: 0.678765, acc.: 62.50%] [G loss: 0.965980]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3137 [D loss: 0.643373, acc.: 59.38%] [G loss: 0.876063]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3138 [D loss: 0.631960, acc.: 65.62%] [G loss: 0.943140]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3139 [D loss: 0.579025, acc.: 71.88%] [G loss: 0.946154]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3140 [D loss: 0.661198, acc.: 59.38%] [G loss: 0.946395]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3141 [D loss: 0.682935, acc.: 53.12%] [G loss: 0.878399]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3142 [D loss: 0.643898, acc.: 50.00%] [G loss: 0.958808]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3143 [D loss: 0.687889, acc.: 50.00%] [G loss: 0.904405]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3144 [D loss: 0.648708, acc.: 62.50%] [G loss: 0.870633]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3145 [D loss: 0.674376, acc.: 50.00%] [G loss: 0.920832]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3146 [D loss: 0.628775, acc.: 68.75%] [G loss: 0.916613]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3147 [D loss: 0.576390, acc.: 68.75%] [G loss: 0.937856]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3148 [D loss: 0.588702, acc.: 68.75%] [G loss: 0.877774]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3149 [D loss: 0.773158, acc.: 50.00%] [G loss: 0.834214]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3150 [D loss: 0.604520, acc.: 59.38%] [G loss: 0.893911]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3151 [D loss: 0.668364, acc.: 53.12%] [G loss: 0.898503]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3152 [D loss: 0.566762, acc.: 75.00%] [G loss: 0.927276]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3153 [D loss: 0.673860, acc.: 75.00%] [G loss: 0.910947]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3154 [D loss: 0.695871, acc.: 59.38%] [G loss: 0.947248]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3155 [D loss: 0.645951, acc.: 62.50%] [G loss: 0.863382]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3156 [D loss: 0.736393, acc.: 56.25%] [G loss: 0.707856]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3157 [D loss: 0.697937, acc.: 59.38%] [G loss: 0.824506]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3158 [D loss: 0.599671, acc.: 71.88%] [G loss: 0.830950]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3159 [D loss: 0.614048, acc.: 65.62%] [G loss: 0.846270]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3160 [D loss: 0.606593, acc.: 62.50%] [G loss: 0.907433]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3161 [D loss: 0.543050, acc.: 81.25%] [G loss: 0.868298]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3162 [D loss: 0.534660, acc.: 81.25%] [G loss: 0.926965]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3163 [D loss: 0.621017, acc.: 68.75%] [G loss: 0.937737]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3164 [D loss: 0.657142, acc.: 71.88%] [G loss: 0.909186]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3165 [D loss: 0.582004, acc.: 75.00%] [G loss: 0.949139]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3166 [D loss: 0.661211, acc.: 59.38%] [G loss: 0.893697]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3167 [D loss: 0.712478, acc.: 50.00%] [G loss: 0.880238]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3168 [D loss: 0.601457, acc.: 59.38%] [G loss: 1.042163]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3169 [D loss: 0.664607, acc.: 59.38%] [G loss: 0.968379]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3170 [D loss: 0.663297, acc.: 68.75%] [G loss: 0.966904]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3171 [D loss: 0.597344, acc.: 71.88%] [G loss: 0.865785]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3172 [D loss: 0.635882, acc.: 62.50%] [G loss: 0.846096]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3173 [D loss: 0.608675, acc.: 65.62%] [G loss: 0.829000]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3174 [D loss: 0.612777, acc.: 71.88%] [G loss: 0.905985]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3175 [D loss: 0.536908, acc.: 78.12%] [G loss: 0.929399]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3176 [D loss: 0.630789, acc.: 59.38%] [G loss: 0.904100]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3177 [D loss: 0.554758, acc.: 81.25%] [G loss: 0.975985]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3178 [D loss: 0.668780, acc.: 53.12%] [G loss: 0.953670]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3179 [D loss: 0.667826, acc.: 56.25%] [G loss: 0.883467]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3180 [D loss: 0.539776, acc.: 71.88%] [G loss: 0.943195]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3181 [D loss: 0.500649, acc.: 87.50%] [G loss: 0.934468]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3182 [D loss: 0.595451, acc.: 65.62%] [G loss: 0.921365]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3183 [D loss: 0.611627, acc.: 75.00%] [G loss: 0.870621]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3184 [D loss: 0.649423, acc.: 56.25%] [G loss: 0.910397]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3185 [D loss: 0.581656, acc.: 75.00%] [G loss: 0.909154]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3186 [D loss: 0.630277, acc.: 59.38%] [G loss: 0.965610]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3187 [D loss: 0.589938, acc.: 71.88%] [G loss: 1.041527]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3188 [D loss: 0.631521, acc.: 68.75%] [G loss: 0.934387]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3189 [D loss: 0.647065, acc.: 68.75%] [G loss: 0.930227]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3190 [D loss: 0.634435, acc.: 59.38%] [G loss: 0.925588]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3191 [D loss: 0.706692, acc.: 53.12%] [G loss: 0.959389]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3192 [D loss: 0.696898, acc.: 50.00%] [G loss: 0.900432]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3193 [D loss: 0.553154, acc.: 75.00%] [G loss: 0.900672]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3194 [D loss: 0.628043, acc.: 68.75%] [G loss: 0.883489]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3195 [D loss: 0.616809, acc.: 65.62%] [G loss: 0.877736]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3196 [D loss: 0.524629, acc.: 84.38%] [G loss: 0.979729]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3197 [D loss: 0.685123, acc.: 53.12%] [G loss: 0.879532]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3198 [D loss: 0.606717, acc.: 62.50%] [G loss: 0.873440]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3199 [D loss: 0.721051, acc.: 46.88%] [G loss: 0.873587]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3200 [D loss: 0.578212, acc.: 68.75%] [G loss: 0.876016]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3201 [D loss: 0.644862, acc.: 53.12%] [G loss: 0.896258]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3202 [D loss: 0.661275, acc.: 62.50%] [G loss: 0.848408]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3203 [D loss: 0.578467, acc.: 62.50%] [G loss: 0.880196]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3204 [D loss: 0.629072, acc.: 50.00%] [G loss: 0.873974]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3205 [D loss: 0.617261, acc.: 68.75%] [G loss: 0.912170]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3206 [D loss: 0.713329, acc.: 53.12%] [G loss: 0.741480]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3207 [D loss: 0.596509, acc.: 65.62%] [G loss: 0.893045]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3208 [D loss: 0.647611, acc.: 59.38%] [G loss: 1.008131]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3209 [D loss: 0.609145, acc.: 75.00%] [G loss: 0.956569]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3210 [D loss: 0.667658, acc.: 62.50%] [G loss: 0.905862]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3211 [D loss: 0.627822, acc.: 68.75%] [G loss: 0.929003]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3212 [D loss: 0.563682, acc.: 68.75%] [G loss: 0.932475]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3213 [D loss: 0.592571, acc.: 75.00%] [G loss: 0.832142]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3214 [D loss: 0.721175, acc.: 53.12%] [G loss: 0.896665]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3215 [D loss: 0.511928, acc.: 84.38%] [G loss: 0.792771]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3216 [D loss: 0.593206, acc.: 68.75%] [G loss: 0.855074]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3217 [D loss: 0.533306, acc.: 84.38%] [G loss: 0.904690]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3218 [D loss: 0.578628, acc.: 75.00%] [G loss: 0.962378]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3219 [D loss: 0.538305, acc.: 81.25%] [G loss: 0.999955]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3220 [D loss: 0.487756, acc.: 81.25%] [G loss: 0.996241]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3221 [D loss: 0.629232, acc.: 56.25%] [G loss: 1.037756]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3222 [D loss: 0.630686, acc.: 68.75%] [G loss: 1.030446]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3223 [D loss: 0.609670, acc.: 71.88%] [G loss: 0.827483]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3224 [D loss: 0.691498, acc.: 56.25%] [G loss: 0.830454]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3225 [D loss: 0.728976, acc.: 65.62%] [G loss: 0.920763]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3226 [D loss: 0.569872, acc.: 81.25%] [G loss: 0.822118]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3227 [D loss: 0.700214, acc.: 65.62%] [G loss: 0.905433]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3228 [D loss: 0.692765, acc.: 53.12%] [G loss: 0.951201]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3229 [D loss: 0.628517, acc.: 65.62%] [G loss: 0.945639]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3230 [D loss: 0.668115, acc.: 65.62%] [G loss: 0.883030]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3231 [D loss: 0.573906, acc.: 68.75%] [G loss: 0.991729]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3232 [D loss: 0.648580, acc.: 68.75%] [G loss: 0.900412]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "3233 [D loss: 0.673867, acc.: 62.50%] [G loss: 0.903774]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3234 [D loss: 0.696281, acc.: 50.00%] [G loss: 0.927811]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3235 [D loss: 0.614773, acc.: 68.75%] [G loss: 0.892886]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3236 [D loss: 0.700304, acc.: 62.50%] [G loss: 0.911569]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3237 [D loss: 0.737703, acc.: 50.00%] [G loss: 0.920664]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3238 [D loss: 0.594200, acc.: 71.88%] [G loss: 0.917506]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3239 [D loss: 0.575497, acc.: 75.00%] [G loss: 0.933661]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3240 [D loss: 0.645492, acc.: 59.38%] [G loss: 0.863836]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3241 [D loss: 0.805130, acc.: 53.12%] [G loss: 0.896477]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3242 [D loss: 0.692677, acc.: 43.75%] [G loss: 0.888235]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3243 [D loss: 0.596241, acc.: 68.75%] [G loss: 0.932761]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3244 [D loss: 0.648426, acc.: 59.38%] [G loss: 0.902361]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3245 [D loss: 0.636046, acc.: 53.12%] [G loss: 0.849277]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3246 [D loss: 0.608767, acc.: 65.62%] [G loss: 0.834846]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3247 [D loss: 0.711032, acc.: 56.25%] [G loss: 0.917630]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3248 [D loss: 0.696975, acc.: 53.12%] [G loss: 0.960344]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3249 [D loss: 0.650648, acc.: 62.50%] [G loss: 0.935076]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3250 [D loss: 0.560579, acc.: 75.00%] [G loss: 0.914291]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3251 [D loss: 0.611275, acc.: 68.75%] [G loss: 0.945385]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3252 [D loss: 0.602935, acc.: 68.75%] [G loss: 0.904236]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3253 [D loss: 0.573651, acc.: 75.00%] [G loss: 0.865633]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3254 [D loss: 0.722208, acc.: 46.88%] [G loss: 0.843335]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3255 [D loss: 0.552679, acc.: 81.25%] [G loss: 0.979717]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3256 [D loss: 0.534029, acc.: 71.88%] [G loss: 0.909794]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3257 [D loss: 0.773585, acc.: 53.12%] [G loss: 0.940691]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3258 [D loss: 0.670168, acc.: 68.75%] [G loss: 0.922292]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3259 [D loss: 0.614697, acc.: 71.88%] [G loss: 0.923235]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3260 [D loss: 0.656953, acc.: 53.12%] [G loss: 0.893527]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3261 [D loss: 0.663301, acc.: 50.00%] [G loss: 0.901605]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3262 [D loss: 0.660146, acc.: 65.62%] [G loss: 0.877635]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3263 [D loss: 0.672090, acc.: 53.12%] [G loss: 0.872045]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3264 [D loss: 0.637854, acc.: 65.62%] [G loss: 0.837509]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3265 [D loss: 0.667464, acc.: 59.38%] [G loss: 0.948597]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3266 [D loss: 0.665358, acc.: 65.62%] [G loss: 0.893751]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3267 [D loss: 0.643321, acc.: 68.75%] [G loss: 0.872420]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3268 [D loss: 0.536993, acc.: 78.12%] [G loss: 0.918648]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3269 [D loss: 0.548520, acc.: 71.88%] [G loss: 0.945356]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3270 [D loss: 0.612180, acc.: 62.50%] [G loss: 0.978189]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3271 [D loss: 0.506089, acc.: 75.00%] [G loss: 1.076848]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3272 [D loss: 0.649978, acc.: 59.38%] [G loss: 0.832012]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3273 [D loss: 0.602823, acc.: 71.88%] [G loss: 0.888660]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3274 [D loss: 0.801652, acc.: 46.88%] [G loss: 0.781737]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3275 [D loss: 0.694366, acc.: 50.00%] [G loss: 0.795744]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3276 [D loss: 0.590985, acc.: 68.75%] [G loss: 0.992528]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3277 [D loss: 0.661274, acc.: 62.50%] [G loss: 0.994281]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3278 [D loss: 0.590942, acc.: 84.38%] [G loss: 1.030268]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3279 [D loss: 0.642044, acc.: 59.38%] [G loss: 1.008526]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3280 [D loss: 0.568031, acc.: 62.50%] [G loss: 0.990814]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3281 [D loss: 0.608697, acc.: 71.88%] [G loss: 0.981909]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3282 [D loss: 0.533904, acc.: 78.12%] [G loss: 0.887606]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3283 [D loss: 0.588277, acc.: 65.62%] [G loss: 0.975255]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3284 [D loss: 0.644204, acc.: 68.75%] [G loss: 0.891573]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3285 [D loss: 0.589634, acc.: 68.75%] [G loss: 0.921417]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3286 [D loss: 0.555543, acc.: 71.88%] [G loss: 1.005524]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3287 [D loss: 0.555842, acc.: 75.00%] [G loss: 1.052782]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3288 [D loss: 0.574493, acc.: 68.75%] [G loss: 0.987637]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3289 [D loss: 0.667754, acc.: 62.50%] [G loss: 0.866682]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3290 [D loss: 0.686158, acc.: 56.25%] [G loss: 0.997881]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3291 [D loss: 0.661271, acc.: 56.25%] [G loss: 1.083606]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3292 [D loss: 0.609689, acc.: 59.38%] [G loss: 0.961412]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3293 [D loss: 0.641765, acc.: 65.62%] [G loss: 0.903420]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3294 [D loss: 0.538642, acc.: 81.25%] [G loss: 0.931545]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3295 [D loss: 0.679092, acc.: 62.50%] [G loss: 0.855361]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3296 [D loss: 0.592756, acc.: 68.75%] [G loss: 0.913674]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3297 [D loss: 0.778211, acc.: 43.75%] [G loss: 0.876473]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3298 [D loss: 0.583814, acc.: 62.50%] [G loss: 0.941554]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3299 [D loss: 0.659064, acc.: 59.38%] [G loss: 0.974331]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3300 [D loss: 0.655427, acc.: 62.50%] [G loss: 0.893901]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3301 [D loss: 0.656533, acc.: 68.75%] [G loss: 0.898671]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3302 [D loss: 0.667396, acc.: 62.50%] [G loss: 0.846896]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3303 [D loss: 0.606014, acc.: 59.38%] [G loss: 0.912308]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3304 [D loss: 0.583826, acc.: 68.75%] [G loss: 0.879865]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3305 [D loss: 0.723547, acc.: 50.00%] [G loss: 0.963677]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3306 [D loss: 0.591504, acc.: 68.75%] [G loss: 0.903670]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3307 [D loss: 0.662101, acc.: 62.50%] [G loss: 0.933012]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3308 [D loss: 0.631032, acc.: 62.50%] [G loss: 0.937970]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3309 [D loss: 0.627443, acc.: 68.75%] [G loss: 0.931990]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3310 [D loss: 0.575855, acc.: 71.88%] [G loss: 0.962204]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3311 [D loss: 0.627813, acc.: 62.50%] [G loss: 1.015350]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3312 [D loss: 0.709733, acc.: 50.00%] [G loss: 0.899102]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3313 [D loss: 0.630480, acc.: 68.75%] [G loss: 0.922630]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3314 [D loss: 0.580177, acc.: 75.00%] [G loss: 0.937342]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3315 [D loss: 0.646659, acc.: 56.25%] [G loss: 0.918569]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3316 [D loss: 0.675138, acc.: 68.75%] [G loss: 0.955027]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3317 [D loss: 0.682522, acc.: 62.50%] [G loss: 0.881363]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3318 [D loss: 0.730082, acc.: 46.88%] [G loss: 0.901770]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3319 [D loss: 0.594284, acc.: 75.00%] [G loss: 0.819299]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3320 [D loss: 0.585369, acc.: 65.62%] [G loss: 0.885925]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3321 [D loss: 0.536918, acc.: 84.38%] [G loss: 0.886544]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3322 [D loss: 0.665780, acc.: 59.38%] [G loss: 0.854941]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3323 [D loss: 0.626428, acc.: 59.38%] [G loss: 0.890580]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3324 [D loss: 0.813706, acc.: 40.62%] [G loss: 0.848525]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3325 [D loss: 0.709965, acc.: 56.25%] [G loss: 0.843626]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3326 [D loss: 0.513788, acc.: 87.50%] [G loss: 0.914734]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3327 [D loss: 0.662602, acc.: 53.12%] [G loss: 1.061888]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3328 [D loss: 0.652649, acc.: 56.25%] [G loss: 0.990501]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3329 [D loss: 0.666648, acc.: 71.88%] [G loss: 0.915363]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3330 [D loss: 0.635739, acc.: 68.75%] [G loss: 0.941150]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3331 [D loss: 0.742072, acc.: 43.75%] [G loss: 0.845537]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3332 [D loss: 0.701994, acc.: 53.12%] [G loss: 0.955621]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3333 [D loss: 0.604230, acc.: 71.88%] [G loss: 0.895321]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3334 [D loss: 0.544372, acc.: 84.38%] [G loss: 1.002990]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3335 [D loss: 0.669399, acc.: 56.25%] [G loss: 0.906218]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3336 [D loss: 0.624627, acc.: 65.62%] [G loss: 0.905087]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3337 [D loss: 0.686979, acc.: 50.00%] [G loss: 0.864792]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3338 [D loss: 0.552134, acc.: 75.00%] [G loss: 0.936313]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "3339 [D loss: 0.612452, acc.: 71.88%] [G loss: 0.909230]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3340 [D loss: 0.679676, acc.: 62.50%] [G loss: 0.937204]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3341 [D loss: 0.600406, acc.: 78.12%] [G loss: 0.938454]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3342 [D loss: 0.620928, acc.: 68.75%] [G loss: 0.901466]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3343 [D loss: 0.625287, acc.: 65.62%] [G loss: 0.977001]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3344 [D loss: 0.619913, acc.: 71.88%] [G loss: 0.912747]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3345 [D loss: 0.639506, acc.: 68.75%] [G loss: 0.898577]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "3346 [D loss: 0.540386, acc.: 71.88%] [G loss: 0.955358]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "3347 [D loss: 0.628725, acc.: 62.50%] [G loss: 0.974113]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3348 [D loss: 0.576578, acc.: 75.00%] [G loss: 0.956003]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3349 [D loss: 0.610793, acc.: 68.75%] [G loss: 0.943349]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3350 [D loss: 0.625509, acc.: 65.62%] [G loss: 0.916637]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3351 [D loss: 0.688694, acc.: 62.50%] [G loss: 1.014244]\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "3352 [D loss: 0.649347, acc.: 59.38%] [G loss: 0.960162]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "3353 [D loss: 0.733120, acc.: 56.25%] [G loss: 0.968890]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3354 [D loss: 0.621587, acc.: 65.62%] [G loss: 0.860138]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3355 [D loss: 0.762463, acc.: 43.75%] [G loss: 0.865311]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3356 [D loss: 0.550121, acc.: 78.12%] [G loss: 0.870287]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "3357 [D loss: 0.696506, acc.: 53.12%] [G loss: 0.875244]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3358 [D loss: 0.630706, acc.: 59.38%] [G loss: 0.857827]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3359 [D loss: 0.677977, acc.: 62.50%] [G loss: 0.903831]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3360 [D loss: 0.541799, acc.: 84.38%] [G loss: 1.048893]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3361 [D loss: 0.696905, acc.: 46.88%] [G loss: 0.892539]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3362 [D loss: 0.614184, acc.: 62.50%] [G loss: 0.914529]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3363 [D loss: 0.621743, acc.: 68.75%] [G loss: 1.063822]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3364 [D loss: 0.601320, acc.: 68.75%] [G loss: 1.039541]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3365 [D loss: 0.597605, acc.: 65.62%] [G loss: 0.893324]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3366 [D loss: 0.565250, acc.: 68.75%] [G loss: 0.880101]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3367 [D loss: 0.571524, acc.: 75.00%] [G loss: 0.978424]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3368 [D loss: 0.606850, acc.: 71.88%] [G loss: 0.982613]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3369 [D loss: 0.679034, acc.: 59.38%] [G loss: 0.956920]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3370 [D loss: 0.561338, acc.: 71.88%] [G loss: 0.998976]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3371 [D loss: 0.698757, acc.: 56.25%] [G loss: 0.845910]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3372 [D loss: 0.722530, acc.: 53.12%] [G loss: 0.874138]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3373 [D loss: 0.645857, acc.: 56.25%] [G loss: 0.859448]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3374 [D loss: 0.605791, acc.: 71.88%] [G loss: 0.843700]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3375 [D loss: 0.632773, acc.: 59.38%] [G loss: 0.905624]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3376 [D loss: 0.649558, acc.: 62.50%] [G loss: 0.933390]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3377 [D loss: 0.633825, acc.: 62.50%] [G loss: 1.004537]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3378 [D loss: 0.625000, acc.: 68.75%] [G loss: 0.902596]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3379 [D loss: 0.677032, acc.: 68.75%] [G loss: 0.909303]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3380 [D loss: 0.692612, acc.: 53.12%] [G loss: 0.843316]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3381 [D loss: 0.588620, acc.: 75.00%] [G loss: 0.841026]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3382 [D loss: 0.673458, acc.: 59.38%] [G loss: 0.949599]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3383 [D loss: 0.554815, acc.: 71.88%] [G loss: 1.015949]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3384 [D loss: 0.598829, acc.: 68.75%] [G loss: 0.977233]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3385 [D loss: 0.733893, acc.: 46.88%] [G loss: 0.901501]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3386 [D loss: 0.632801, acc.: 62.50%] [G loss: 0.895011]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3387 [D loss: 0.607883, acc.: 62.50%] [G loss: 0.948910]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3388 [D loss: 0.638482, acc.: 62.50%] [G loss: 0.871746]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3389 [D loss: 0.622583, acc.: 62.50%] [G loss: 1.024747]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3390 [D loss: 0.638530, acc.: 65.62%] [G loss: 0.936249]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3391 [D loss: 0.579258, acc.: 75.00%] [G loss: 1.042157]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3392 [D loss: 0.661034, acc.: 62.50%] [G loss: 0.930316]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3393 [D loss: 0.671895, acc.: 62.50%] [G loss: 1.005987]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3394 [D loss: 0.527434, acc.: 78.12%] [G loss: 0.929095]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3395 [D loss: 0.695760, acc.: 65.62%] [G loss: 0.905849]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3396 [D loss: 0.523491, acc.: 71.88%] [G loss: 0.899303]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3397 [D loss: 0.649401, acc.: 56.25%] [G loss: 0.896980]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3398 [D loss: 0.664426, acc.: 59.38%] [G loss: 0.875733]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3399 [D loss: 0.722030, acc.: 56.25%] [G loss: 1.001324]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3400 [D loss: 0.684140, acc.: 50.00%] [G loss: 0.913620]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3401 [D loss: 0.702671, acc.: 56.25%] [G loss: 0.885743]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3402 [D loss: 0.583514, acc.: 71.88%] [G loss: 1.001771]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3403 [D loss: 0.551876, acc.: 71.88%] [G loss: 0.924566]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3404 [D loss: 0.536508, acc.: 81.25%] [G loss: 1.061089]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3405 [D loss: 0.690611, acc.: 46.88%] [G loss: 1.036796]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3406 [D loss: 0.637028, acc.: 62.50%] [G loss: 0.946176]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3407 [D loss: 0.714030, acc.: 56.25%] [G loss: 0.930286]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3408 [D loss: 0.534233, acc.: 75.00%] [G loss: 0.960755]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3409 [D loss: 0.749003, acc.: 34.38%] [G loss: 0.869989]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3410 [D loss: 0.683264, acc.: 56.25%] [G loss: 0.865717]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3411 [D loss: 0.782848, acc.: 40.62%] [G loss: 0.846322]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3412 [D loss: 0.639737, acc.: 62.50%] [G loss: 0.954720]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3413 [D loss: 0.678330, acc.: 59.38%] [G loss: 0.946678]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3414 [D loss: 0.680816, acc.: 53.12%] [G loss: 0.922264]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3415 [D loss: 0.651516, acc.: 56.25%] [G loss: 1.015229]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3416 [D loss: 0.669145, acc.: 59.38%] [G loss: 0.976417]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3417 [D loss: 0.568649, acc.: 81.25%] [G loss: 0.967535]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3418 [D loss: 0.577483, acc.: 78.12%] [G loss: 0.851695]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3419 [D loss: 0.713124, acc.: 59.38%] [G loss: 0.822427]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3420 [D loss: 0.669095, acc.: 56.25%] [G loss: 0.867560]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3421 [D loss: 0.627055, acc.: 62.50%] [G loss: 0.878950]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3422 [D loss: 0.560185, acc.: 71.88%] [G loss: 0.852944]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3423 [D loss: 0.721103, acc.: 50.00%] [G loss: 0.890715]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3424 [D loss: 0.610064, acc.: 81.25%] [G loss: 0.856268]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3425 [D loss: 0.684024, acc.: 65.62%] [G loss: 0.962873]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3426 [D loss: 0.630655, acc.: 62.50%] [G loss: 0.915057]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3427 [D loss: 0.572593, acc.: 68.75%] [G loss: 1.002988]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3428 [D loss: 0.668746, acc.: 71.88%] [G loss: 0.963829]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3429 [D loss: 0.709761, acc.: 56.25%] [G loss: 0.892989]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3430 [D loss: 0.677280, acc.: 53.12%] [G loss: 0.860819]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3431 [D loss: 0.673634, acc.: 46.88%] [G loss: 0.879668]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3432 [D loss: 0.655795, acc.: 68.75%] [G loss: 0.804447]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3433 [D loss: 0.639468, acc.: 62.50%] [G loss: 0.886621]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3434 [D loss: 0.669569, acc.: 62.50%] [G loss: 0.915758]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3435 [D loss: 0.719197, acc.: 56.25%] [G loss: 0.846485]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3436 [D loss: 0.608844, acc.: 71.88%] [G loss: 0.951349]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3437 [D loss: 0.612864, acc.: 65.62%] [G loss: 0.877096]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3438 [D loss: 0.681360, acc.: 62.50%] [G loss: 0.888194]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3439 [D loss: 0.601205, acc.: 78.12%] [G loss: 0.911536]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3440 [D loss: 0.728060, acc.: 59.38%] [G loss: 0.852654]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3441 [D loss: 0.693947, acc.: 43.75%] [G loss: 1.037207]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3442 [D loss: 0.688554, acc.: 59.38%] [G loss: 0.907110]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3443 [D loss: 0.593622, acc.: 78.12%] [G loss: 0.950142]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3444 [D loss: 0.652808, acc.: 50.00%] [G loss: 0.845739]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3445 [D loss: 0.595497, acc.: 68.75%] [G loss: 0.859295]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3446 [D loss: 0.576890, acc.: 68.75%] [G loss: 0.911160]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3447 [D loss: 0.586250, acc.: 71.88%] [G loss: 0.931206]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3448 [D loss: 0.728271, acc.: 59.38%] [G loss: 0.885843]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3449 [D loss: 0.641727, acc.: 68.75%] [G loss: 0.969078]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3450 [D loss: 0.711372, acc.: 50.00%] [G loss: 0.930067]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3451 [D loss: 0.770880, acc.: 50.00%] [G loss: 0.979836]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3452 [D loss: 0.540636, acc.: 81.25%] [G loss: 0.913007]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3453 [D loss: 0.643333, acc.: 56.25%] [G loss: 0.911642]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3454 [D loss: 0.607457, acc.: 56.25%] [G loss: 0.931810]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3455 [D loss: 0.616093, acc.: 62.50%] [G loss: 0.962974]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3456 [D loss: 0.592710, acc.: 75.00%] [G loss: 0.937671]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3457 [D loss: 0.647368, acc.: 65.62%] [G loss: 0.956318]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3458 [D loss: 0.589058, acc.: 84.38%] [G loss: 0.885164]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3459 [D loss: 0.611173, acc.: 75.00%] [G loss: 0.998541]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3460 [D loss: 0.667099, acc.: 59.38%] [G loss: 0.890839]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3461 [D loss: 0.690277, acc.: 56.25%] [G loss: 0.909316]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3462 [D loss: 0.547516, acc.: 75.00%] [G loss: 0.996377]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3463 [D loss: 0.589128, acc.: 68.75%] [G loss: 0.912583]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3464 [D loss: 0.567883, acc.: 71.88%] [G loss: 0.924067]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3465 [D loss: 0.628708, acc.: 71.88%] [G loss: 0.908914]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3466 [D loss: 0.647849, acc.: 62.50%] [G loss: 0.953839]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3467 [D loss: 0.653696, acc.: 56.25%] [G loss: 0.958330]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3468 [D loss: 0.616002, acc.: 62.50%] [G loss: 0.961054]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3469 [D loss: 0.678226, acc.: 62.50%] [G loss: 0.885390]\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "3470 [D loss: 0.676836, acc.: 50.00%] [G loss: 0.876611]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3471 [D loss: 0.621018, acc.: 78.12%] [G loss: 0.894446]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3472 [D loss: 0.580711, acc.: 65.62%] [G loss: 0.928260]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3473 [D loss: 0.583591, acc.: 71.88%] [G loss: 0.966051]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3474 [D loss: 0.709517, acc.: 53.12%] [G loss: 0.966089]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3475 [D loss: 0.545586, acc.: 87.50%] [G loss: 0.838557]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3476 [D loss: 0.607083, acc.: 62.50%] [G loss: 0.874365]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3477 [D loss: 0.571650, acc.: 71.88%] [G loss: 0.956768]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3478 [D loss: 0.614727, acc.: 75.00%] [G loss: 0.894518]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3479 [D loss: 0.585018, acc.: 65.62%] [G loss: 0.915128]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3480 [D loss: 0.636295, acc.: 62.50%] [G loss: 0.936469]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3481 [D loss: 0.668568, acc.: 62.50%] [G loss: 0.963235]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3482 [D loss: 0.642494, acc.: 62.50%] [G loss: 1.061556]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3483 [D loss: 0.654528, acc.: 53.12%] [G loss: 1.020770]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3484 [D loss: 0.661439, acc.: 59.38%] [G loss: 1.023765]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3485 [D loss: 0.671768, acc.: 59.38%] [G loss: 0.966924]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3486 [D loss: 0.589040, acc.: 71.88%] [G loss: 0.949013]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3487 [D loss: 0.562671, acc.: 75.00%] [G loss: 0.877693]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3488 [D loss: 0.601754, acc.: 65.62%] [G loss: 0.879565]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3489 [D loss: 0.728543, acc.: 53.12%] [G loss: 0.902340]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3490 [D loss: 0.652803, acc.: 62.50%] [G loss: 0.869055]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3491 [D loss: 0.607505, acc.: 68.75%] [G loss: 0.971763]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3492 [D loss: 0.638814, acc.: 62.50%] [G loss: 1.001914]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3493 [D loss: 0.609230, acc.: 68.75%] [G loss: 0.874548]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3494 [D loss: 0.621303, acc.: 53.12%] [G loss: 0.858001]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3495 [D loss: 0.735483, acc.: 46.88%] [G loss: 0.949022]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3496 [D loss: 0.657364, acc.: 62.50%] [G loss: 0.893192]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3497 [D loss: 0.631482, acc.: 65.62%] [G loss: 0.945391]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3498 [D loss: 0.596375, acc.: 65.62%] [G loss: 0.954291]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3499 [D loss: 0.773235, acc.: 40.62%] [G loss: 0.809214]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3500 [D loss: 0.584356, acc.: 71.88%] [G loss: 0.842006]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3501 [D loss: 0.589124, acc.: 71.88%] [G loss: 0.866576]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3502 [D loss: 0.687212, acc.: 46.88%] [G loss: 0.904307]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3503 [D loss: 0.726389, acc.: 43.75%] [G loss: 0.920015]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3504 [D loss: 0.643713, acc.: 62.50%] [G loss: 0.845507]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3505 [D loss: 0.605885, acc.: 71.88%] [G loss: 0.884951]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3506 [D loss: 0.659000, acc.: 59.38%] [G loss: 0.900457]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3507 [D loss: 0.742349, acc.: 50.00%] [G loss: 0.963149]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3508 [D loss: 0.655017, acc.: 62.50%] [G loss: 0.939304]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3509 [D loss: 0.568977, acc.: 71.88%] [G loss: 1.023268]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3510 [D loss: 0.780361, acc.: 46.88%] [G loss: 0.897392]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3511 [D loss: 0.659116, acc.: 53.12%] [G loss: 0.824802]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3512 [D loss: 0.648924, acc.: 68.75%] [G loss: 0.832792]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3513 [D loss: 0.658577, acc.: 59.38%] [G loss: 0.891654]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3514 [D loss: 0.616301, acc.: 65.62%] [G loss: 0.917419]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3515 [D loss: 0.621387, acc.: 65.62%] [G loss: 0.846713]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3516 [D loss: 0.626298, acc.: 62.50%] [G loss: 0.885843]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3517 [D loss: 0.649976, acc.: 56.25%] [G loss: 0.842677]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3518 [D loss: 0.570774, acc.: 71.88%] [G loss: 0.867932]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3519 [D loss: 0.631817, acc.: 65.62%] [G loss: 0.876698]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3520 [D loss: 0.599966, acc.: 71.88%] [G loss: 0.926671]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3521 [D loss: 0.650761, acc.: 56.25%] [G loss: 0.952522]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3522 [D loss: 0.652601, acc.: 62.50%] [G loss: 0.973616]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3523 [D loss: 0.679443, acc.: 56.25%] [G loss: 0.841244]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3524 [D loss: 0.626103, acc.: 68.75%] [G loss: 0.909614]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3525 [D loss: 0.654528, acc.: 71.88%] [G loss: 0.934930]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3526 [D loss: 0.694883, acc.: 50.00%] [G loss: 0.799091]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3527 [D loss: 0.617246, acc.: 71.88%] [G loss: 0.914504]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3528 [D loss: 0.642662, acc.: 62.50%] [G loss: 0.855240]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3529 [D loss: 0.681454, acc.: 62.50%] [G loss: 0.898299]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3530 [D loss: 0.604001, acc.: 71.88%] [G loss: 0.838246]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3531 [D loss: 0.649732, acc.: 65.62%] [G loss: 0.843750]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3532 [D loss: 0.610212, acc.: 71.88%] [G loss: 0.896620]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3533 [D loss: 0.635807, acc.: 62.50%] [G loss: 0.944506]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3534 [D loss: 0.623974, acc.: 68.75%] [G loss: 0.925065]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3535 [D loss: 0.616668, acc.: 65.62%] [G loss: 0.938351]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3536 [D loss: 0.695686, acc.: 59.38%] [G loss: 0.939829]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3537 [D loss: 0.621895, acc.: 62.50%] [G loss: 0.947274]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3538 [D loss: 0.562045, acc.: 87.50%] [G loss: 0.817072]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3539 [D loss: 0.618245, acc.: 65.62%] [G loss: 0.902490]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3540 [D loss: 0.583088, acc.: 78.12%] [G loss: 0.902854]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3541 [D loss: 0.568203, acc.: 75.00%] [G loss: 0.871500]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3542 [D loss: 0.561081, acc.: 62.50%] [G loss: 0.967119]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3543 [D loss: 0.700224, acc.: 56.25%] [G loss: 0.860477]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3544 [D loss: 0.612138, acc.: 68.75%] [G loss: 0.937343]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3545 [D loss: 0.620393, acc.: 71.88%] [G loss: 0.890452]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3546 [D loss: 0.659423, acc.: 50.00%] [G loss: 0.925307]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3547 [D loss: 0.561292, acc.: 84.38%] [G loss: 0.995048]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "3548 [D loss: 0.626280, acc.: 65.62%] [G loss: 0.955813]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "3549 [D loss: 0.625462, acc.: 62.50%] [G loss: 0.898047]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3550 [D loss: 0.583909, acc.: 68.75%] [G loss: 0.941384]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3551 [D loss: 0.532541, acc.: 78.12%] [G loss: 0.939834]\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "3552 [D loss: 0.775983, acc.: 50.00%] [G loss: 0.926831]\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "3553 [D loss: 0.652146, acc.: 59.38%] [G loss: 0.962850]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3554 [D loss: 0.696255, acc.: 50.00%] [G loss: 0.946838]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3555 [D loss: 0.632000, acc.: 62.50%] [G loss: 0.997718]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "3556 [D loss: 0.611643, acc.: 71.88%] [G loss: 0.902086]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "3557 [D loss: 0.657877, acc.: 53.12%] [G loss: 0.858119]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3558 [D loss: 0.646577, acc.: 68.75%] [G loss: 0.911764]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "3559 [D loss: 0.697145, acc.: 59.38%] [G loss: 0.978347]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "3560 [D loss: 0.680230, acc.: 56.25%] [G loss: 0.971950]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3561 [D loss: 0.550920, acc.: 81.25%] [G loss: 0.944423]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "3562 [D loss: 0.701870, acc.: 56.25%] [G loss: 0.936738]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3563 [D loss: 0.643214, acc.: 65.62%] [G loss: 0.949772]\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "3564 [D loss: 0.647560, acc.: 59.38%] [G loss: 1.037282]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3565 [D loss: 0.607708, acc.: 62.50%] [G loss: 1.000603]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3566 [D loss: 0.707916, acc.: 68.75%] [G loss: 0.921018]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3567 [D loss: 0.578507, acc.: 71.88%] [G loss: 0.972881]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3568 [D loss: 0.693445, acc.: 50.00%] [G loss: 0.934736]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3569 [D loss: 0.606078, acc.: 65.62%] [G loss: 0.912036]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3570 [D loss: 0.651744, acc.: 62.50%] [G loss: 0.867708]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3571 [D loss: 0.502022, acc.: 84.38%] [G loss: 0.920516]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3572 [D loss: 0.603852, acc.: 75.00%] [G loss: 0.990563]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3573 [D loss: 0.662503, acc.: 53.12%] [G loss: 0.911742]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3574 [D loss: 0.630966, acc.: 56.25%] [G loss: 0.939125]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3575 [D loss: 0.634921, acc.: 65.62%] [G loss: 0.935477]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3576 [D loss: 0.607053, acc.: 65.62%] [G loss: 0.900100]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3577 [D loss: 0.680240, acc.: 56.25%] [G loss: 0.838196]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3578 [D loss: 0.550959, acc.: 78.12%] [G loss: 0.969369]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3579 [D loss: 0.671727, acc.: 53.12%] [G loss: 0.864245]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3580 [D loss: 0.591270, acc.: 68.75%] [G loss: 0.941445]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3581 [D loss: 0.663683, acc.: 53.12%] [G loss: 0.821293]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3582 [D loss: 0.622893, acc.: 65.62%] [G loss: 0.950529]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3583 [D loss: 0.644226, acc.: 53.12%] [G loss: 0.932251]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3584 [D loss: 0.556295, acc.: 71.88%] [G loss: 0.886624]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3585 [D loss: 0.658853, acc.: 62.50%] [G loss: 0.900808]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3586 [D loss: 0.668584, acc.: 59.38%] [G loss: 0.928829]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3587 [D loss: 0.594574, acc.: 65.62%] [G loss: 0.979577]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3588 [D loss: 0.560980, acc.: 75.00%] [G loss: 0.991317]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3589 [D loss: 0.602606, acc.: 71.88%] [G loss: 0.920901]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3590 [D loss: 0.615090, acc.: 71.88%] [G loss: 0.965108]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3591 [D loss: 0.657955, acc.: 62.50%] [G loss: 0.829850]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3592 [D loss: 0.532948, acc.: 68.75%] [G loss: 0.989672]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3593 [D loss: 0.591848, acc.: 78.12%] [G loss: 0.889244]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3594 [D loss: 0.583070, acc.: 65.62%] [G loss: 0.936592]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3595 [D loss: 0.582818, acc.: 78.12%] [G loss: 0.902502]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3596 [D loss: 0.697898, acc.: 71.88%] [G loss: 0.873051]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3597 [D loss: 0.691136, acc.: 59.38%] [G loss: 0.823704]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3598 [D loss: 0.672552, acc.: 56.25%] [G loss: 0.933226]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3599 [D loss: 0.614189, acc.: 68.75%] [G loss: 0.884002]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3600 [D loss: 0.512676, acc.: 78.12%] [G loss: 0.967887]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3601 [D loss: 0.570595, acc.: 71.88%] [G loss: 0.877899]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3602 [D loss: 0.628956, acc.: 68.75%] [G loss: 0.916638]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3603 [D loss: 0.593949, acc.: 65.62%] [G loss: 0.877515]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3604 [D loss: 0.700754, acc.: 59.38%] [G loss: 0.937021]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3605 [D loss: 0.565433, acc.: 78.12%] [G loss: 0.933799]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3606 [D loss: 0.596582, acc.: 68.75%] [G loss: 0.926252]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3607 [D loss: 0.721395, acc.: 46.88%] [G loss: 0.850011]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3608 [D loss: 0.676134, acc.: 59.38%] [G loss: 0.911712]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3609 [D loss: 0.736270, acc.: 50.00%] [G loss: 0.977235]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3610 [D loss: 0.558327, acc.: 71.88%] [G loss: 0.968127]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3611 [D loss: 0.678307, acc.: 59.38%] [G loss: 0.985252]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3612 [D loss: 0.725179, acc.: 46.88%] [G loss: 0.926452]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3613 [D loss: 0.649097, acc.: 56.25%] [G loss: 0.923788]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3614 [D loss: 0.676753, acc.: 59.38%] [G loss: 1.071636]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3615 [D loss: 0.690581, acc.: 56.25%] [G loss: 0.985146]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3616 [D loss: 0.641340, acc.: 59.38%] [G loss: 0.904310]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3617 [D loss: 0.641743, acc.: 68.75%] [G loss: 0.787467]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3618 [D loss: 0.675548, acc.: 62.50%] [G loss: 0.844091]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3619 [D loss: 0.610253, acc.: 81.25%] [G loss: 0.836913]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3620 [D loss: 0.610721, acc.: 65.62%] [G loss: 0.993935]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3621 [D loss: 0.687539, acc.: 62.50%] [G loss: 0.900920]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3622 [D loss: 0.668596, acc.: 50.00%] [G loss: 0.888812]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3623 [D loss: 0.629272, acc.: 65.62%] [G loss: 0.907123]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3624 [D loss: 0.666376, acc.: 56.25%] [G loss: 0.900445]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3625 [D loss: 0.665705, acc.: 56.25%] [G loss: 1.005871]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3626 [D loss: 0.770550, acc.: 46.88%] [G loss: 0.865598]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3627 [D loss: 0.741922, acc.: 50.00%] [G loss: 0.819394]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3628 [D loss: 0.642469, acc.: 56.25%] [G loss: 0.873442]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3629 [D loss: 0.753789, acc.: 50.00%] [G loss: 0.904792]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3630 [D loss: 0.584555, acc.: 75.00%] [G loss: 0.936030]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3631 [D loss: 0.573138, acc.: 75.00%] [G loss: 1.001076]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3632 [D loss: 0.609007, acc.: 71.88%] [G loss: 0.944608]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3633 [D loss: 0.694620, acc.: 50.00%] [G loss: 0.979779]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3634 [D loss: 0.687731, acc.: 56.25%] [G loss: 0.933686]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3635 [D loss: 0.654608, acc.: 59.38%] [G loss: 0.899815]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3636 [D loss: 0.603499, acc.: 65.62%] [G loss: 0.934846]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3637 [D loss: 0.734073, acc.: 50.00%] [G loss: 0.886801]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3638 [D loss: 0.541662, acc.: 84.38%] [G loss: 0.876983]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3639 [D loss: 0.569518, acc.: 78.12%] [G loss: 0.890075]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3640 [D loss: 0.563846, acc.: 71.88%] [G loss: 0.892475]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3641 [D loss: 0.742689, acc.: 50.00%] [G loss: 0.865726]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3642 [D loss: 0.680125, acc.: 59.38%] [G loss: 0.894909]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3643 [D loss: 0.628093, acc.: 68.75%] [G loss: 0.876553]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3644 [D loss: 0.635211, acc.: 65.62%] [G loss: 0.885011]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3645 [D loss: 0.703728, acc.: 50.00%] [G loss: 0.948665]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3646 [D loss: 0.621555, acc.: 75.00%] [G loss: 0.948880]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3647 [D loss: 0.611252, acc.: 65.62%] [G loss: 0.923549]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3648 [D loss: 0.609412, acc.: 68.75%] [G loss: 0.906023]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3649 [D loss: 0.598417, acc.: 65.62%] [G loss: 0.854774]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3650 [D loss: 0.547160, acc.: 75.00%] [G loss: 0.896348]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3651 [D loss: 0.734677, acc.: 50.00%] [G loss: 0.889816]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3652 [D loss: 0.597982, acc.: 65.62%] [G loss: 0.899197]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3653 [D loss: 0.600261, acc.: 68.75%] [G loss: 0.912893]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3654 [D loss: 0.696512, acc.: 50.00%] [G loss: 0.886034]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "3655 [D loss: 0.593870, acc.: 68.75%] [G loss: 0.854806]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3656 [D loss: 0.718159, acc.: 53.12%] [G loss: 0.911575]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3657 [D loss: 0.596841, acc.: 68.75%] [G loss: 0.992452]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3658 [D loss: 0.617117, acc.: 65.62%] [G loss: 0.941402]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3659 [D loss: 0.709004, acc.: 50.00%] [G loss: 0.865906]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3660 [D loss: 0.493707, acc.: 84.38%] [G loss: 0.882053]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "3661 [D loss: 0.638486, acc.: 62.50%] [G loss: 0.880746]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3662 [D loss: 0.644778, acc.: 56.25%] [G loss: 0.971970]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "3663 [D loss: 0.662121, acc.: 59.38%] [G loss: 0.939861]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "3664 [D loss: 0.642160, acc.: 65.62%] [G loss: 0.804627]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3665 [D loss: 0.593201, acc.: 65.62%] [G loss: 0.932289]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3666 [D loss: 0.627634, acc.: 62.50%] [G loss: 0.969778]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3667 [D loss: 0.747670, acc.: 53.12%] [G loss: 0.819585]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3668 [D loss: 0.650170, acc.: 46.88%] [G loss: 0.927192]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3669 [D loss: 0.577617, acc.: 75.00%] [G loss: 0.936807]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3670 [D loss: 0.617453, acc.: 68.75%] [G loss: 0.989391]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3671 [D loss: 0.587907, acc.: 62.50%] [G loss: 0.913648]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "3672 [D loss: 0.602097, acc.: 56.25%] [G loss: 0.926415]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "3673 [D loss: 0.628393, acc.: 56.25%] [G loss: 0.961082]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3674 [D loss: 0.742681, acc.: 50.00%] [G loss: 0.973518]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3675 [D loss: 0.565987, acc.: 75.00%] [G loss: 0.995815]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3676 [D loss: 0.618252, acc.: 56.25%] [G loss: 1.031156]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3677 [D loss: 0.594344, acc.: 65.62%] [G loss: 0.974641]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3678 [D loss: 0.658056, acc.: 59.38%] [G loss: 0.922257]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3679 [D loss: 0.540222, acc.: 75.00%] [G loss: 0.871647]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3680 [D loss: 0.693300, acc.: 50.00%] [G loss: 0.838107]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3681 [D loss: 0.654006, acc.: 56.25%] [G loss: 0.863976]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3682 [D loss: 0.582781, acc.: 68.75%] [G loss: 0.870729]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3683 [D loss: 0.599952, acc.: 62.50%] [G loss: 0.847969]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3684 [D loss: 0.641183, acc.: 71.88%] [G loss: 0.888546]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3685 [D loss: 0.601372, acc.: 71.88%] [G loss: 0.908521]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3686 [D loss: 0.734268, acc.: 43.75%] [G loss: 0.824379]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3687 [D loss: 0.767412, acc.: 46.88%] [G loss: 0.874767]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3688 [D loss: 0.628715, acc.: 62.50%] [G loss: 0.900555]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3689 [D loss: 0.621393, acc.: 65.62%] [G loss: 0.984265]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3690 [D loss: 0.605639, acc.: 68.75%] [G loss: 1.032975]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3691 [D loss: 0.602605, acc.: 71.88%] [G loss: 1.011774]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3692 [D loss: 0.649454, acc.: 65.62%] [G loss: 0.957023]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3693 [D loss: 0.726645, acc.: 62.50%] [G loss: 0.966805]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3694 [D loss: 0.558205, acc.: 78.12%] [G loss: 0.890602]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3695 [D loss: 0.808826, acc.: 53.12%] [G loss: 0.895701]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3696 [D loss: 0.586382, acc.: 75.00%] [G loss: 0.873894]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3697 [D loss: 0.603349, acc.: 59.38%] [G loss: 0.921966]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3698 [D loss: 0.625337, acc.: 65.62%] [G loss: 0.908032]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3699 [D loss: 0.571392, acc.: 75.00%] [G loss: 0.882063]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3700 [D loss: 0.609384, acc.: 65.62%] [G loss: 0.898966]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3701 [D loss: 0.710874, acc.: 56.25%] [G loss: 0.888758]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3702 [D loss: 0.568063, acc.: 68.75%] [G loss: 0.892777]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3703 [D loss: 0.568282, acc.: 75.00%] [G loss: 0.877634]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3704 [D loss: 0.729202, acc.: 46.88%] [G loss: 0.902799]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3705 [D loss: 0.574486, acc.: 75.00%] [G loss: 0.954210]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3706 [D loss: 0.678961, acc.: 53.12%] [G loss: 0.877485]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3707 [D loss: 0.637067, acc.: 68.75%] [G loss: 0.832440]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3708 [D loss: 0.579391, acc.: 71.88%] [G loss: 0.899620]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3709 [D loss: 0.639576, acc.: 65.62%] [G loss: 0.915120]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3710 [D loss: 0.689522, acc.: 59.38%] [G loss: 0.925604]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3711 [D loss: 0.664517, acc.: 59.38%] [G loss: 0.967106]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3712 [D loss: 0.764841, acc.: 53.12%] [G loss: 0.957963]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3713 [D loss: 0.605633, acc.: 68.75%] [G loss: 0.943615]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3714 [D loss: 0.635687, acc.: 65.62%] [G loss: 0.922941]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3715 [D loss: 0.728605, acc.: 50.00%] [G loss: 0.901336]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3716 [D loss: 0.635961, acc.: 59.38%] [G loss: 0.915749]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3717 [D loss: 0.590479, acc.: 62.50%] [G loss: 0.902896]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3718 [D loss: 0.685197, acc.: 53.12%] [G loss: 0.901030]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3719 [D loss: 0.648651, acc.: 62.50%] [G loss: 0.854305]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3720 [D loss: 0.617812, acc.: 65.62%] [G loss: 0.983349]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3721 [D loss: 0.646013, acc.: 65.62%] [G loss: 0.842742]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3722 [D loss: 0.691226, acc.: 53.12%] [G loss: 0.932304]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3723 [D loss: 0.668293, acc.: 62.50%] [G loss: 0.871833]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3724 [D loss: 0.735478, acc.: 56.25%] [G loss: 0.862283]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3725 [D loss: 0.631924, acc.: 65.62%] [G loss: 0.936580]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3726 [D loss: 0.629329, acc.: 59.38%] [G loss: 0.847269]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3727 [D loss: 0.624860, acc.: 68.75%] [G loss: 0.932447]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3728 [D loss: 0.652349, acc.: 62.50%] [G loss: 0.923327]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3729 [D loss: 0.643939, acc.: 59.38%] [G loss: 0.904718]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3730 [D loss: 0.717485, acc.: 53.12%] [G loss: 0.899796]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3731 [D loss: 0.655790, acc.: 62.50%] [G loss: 0.983292]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3732 [D loss: 0.640199, acc.: 59.38%] [G loss: 0.966977]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3733 [D loss: 0.624646, acc.: 62.50%] [G loss: 0.968483]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3734 [D loss: 0.670822, acc.: 59.38%] [G loss: 0.900970]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3735 [D loss: 0.540887, acc.: 71.88%] [G loss: 0.910355]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3736 [D loss: 0.581576, acc.: 65.62%] [G loss: 0.937083]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3737 [D loss: 0.621955, acc.: 71.88%] [G loss: 0.964205]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3738 [D loss: 0.693264, acc.: 50.00%] [G loss: 0.887018]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3739 [D loss: 0.543491, acc.: 81.25%] [G loss: 0.818546]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3740 [D loss: 0.734030, acc.: 56.25%] [G loss: 0.822992]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3741 [D loss: 0.610781, acc.: 68.75%] [G loss: 0.853390]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3742 [D loss: 0.681520, acc.: 59.38%] [G loss: 0.891194]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3743 [D loss: 0.629404, acc.: 62.50%] [G loss: 0.877107]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3744 [D loss: 0.726420, acc.: 56.25%] [G loss: 0.873502]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3745 [D loss: 0.516523, acc.: 81.25%] [G loss: 0.835072]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3746 [D loss: 0.615902, acc.: 75.00%] [G loss: 0.958637]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3747 [D loss: 0.660194, acc.: 59.38%] [G loss: 0.983924]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3748 [D loss: 0.687926, acc.: 56.25%] [G loss: 1.015392]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3749 [D loss: 0.618630, acc.: 75.00%] [G loss: 0.996982]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3750 [D loss: 0.622948, acc.: 65.62%] [G loss: 0.915353]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3751 [D loss: 0.675355, acc.: 62.50%] [G loss: 0.870680]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3752 [D loss: 0.681019, acc.: 56.25%] [G loss: 0.866290]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3753 [D loss: 0.613432, acc.: 68.75%] [G loss: 0.906390]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3754 [D loss: 0.643613, acc.: 62.50%] [G loss: 0.935182]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3755 [D loss: 0.724160, acc.: 46.88%] [G loss: 0.844141]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3756 [D loss: 0.581366, acc.: 71.88%] [G loss: 0.905424]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3757 [D loss: 0.570507, acc.: 75.00%] [G loss: 0.953723]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3758 [D loss: 0.521260, acc.: 75.00%] [G loss: 0.803646]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3759 [D loss: 0.726625, acc.: 50.00%] [G loss: 0.940988]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3760 [D loss: 0.590777, acc.: 65.62%] [G loss: 0.969049]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3761 [D loss: 0.702419, acc.: 46.88%] [G loss: 0.907488]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3762 [D loss: 0.601181, acc.: 65.62%] [G loss: 0.936251]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3763 [D loss: 0.663648, acc.: 62.50%] [G loss: 0.917789]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3764 [D loss: 0.663898, acc.: 56.25%] [G loss: 0.885397]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3765 [D loss: 0.607972, acc.: 62.50%] [G loss: 0.947985]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3766 [D loss: 0.637268, acc.: 68.75%] [G loss: 0.958134]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3767 [D loss: 0.663365, acc.: 62.50%] [G loss: 0.963523]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3768 [D loss: 0.656104, acc.: 65.62%] [G loss: 0.949353]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3769 [D loss: 0.656393, acc.: 56.25%] [G loss: 0.961896]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3770 [D loss: 0.616899, acc.: 68.75%] [G loss: 0.965060]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3771 [D loss: 0.620784, acc.: 62.50%] [G loss: 0.888873]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3772 [D loss: 0.628864, acc.: 65.62%] [G loss: 1.034837]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3773 [D loss: 0.667089, acc.: 68.75%] [G loss: 0.885662]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3774 [D loss: 0.694439, acc.: 46.88%] [G loss: 0.922456]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3775 [D loss: 0.634580, acc.: 71.88%] [G loss: 0.858815]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "3776 [D loss: 0.585259, acc.: 65.62%] [G loss: 0.816671]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3777 [D loss: 0.707702, acc.: 53.12%] [G loss: 0.911696]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3778 [D loss: 0.628595, acc.: 59.38%] [G loss: 0.949868]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3779 [D loss: 0.520947, acc.: 81.25%] [G loss: 0.951409]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3780 [D loss: 0.632150, acc.: 56.25%] [G loss: 0.927852]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3781 [D loss: 0.712300, acc.: 65.62%] [G loss: 0.833163]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "3782 [D loss: 0.677426, acc.: 65.62%] [G loss: 0.851402]\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "3783 [D loss: 0.599386, acc.: 68.75%] [G loss: 0.819509]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "3784 [D loss: 0.624619, acc.: 71.88%] [G loss: 0.908387]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3785 [D loss: 0.575948, acc.: 75.00%] [G loss: 0.907471]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3786 [D loss: 0.713841, acc.: 56.25%] [G loss: 0.888593]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3787 [D loss: 0.691008, acc.: 56.25%] [G loss: 0.915950]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3788 [D loss: 0.748795, acc.: 43.75%] [G loss: 0.858626]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3789 [D loss: 0.527144, acc.: 84.38%] [G loss: 0.813373]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3790 [D loss: 0.627320, acc.: 75.00%] [G loss: 0.844558]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3791 [D loss: 0.713806, acc.: 56.25%] [G loss: 0.826209]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3792 [D loss: 0.680767, acc.: 62.50%] [G loss: 0.893778]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3793 [D loss: 0.671714, acc.: 46.88%] [G loss: 0.930790]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3794 [D loss: 0.587899, acc.: 71.88%] [G loss: 0.902578]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3795 [D loss: 0.576892, acc.: 71.88%] [G loss: 0.861110]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3796 [D loss: 0.689910, acc.: 65.62%] [G loss: 0.956628]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3797 [D loss: 0.620118, acc.: 65.62%] [G loss: 0.934018]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3798 [D loss: 0.667521, acc.: 56.25%] [G loss: 0.909093]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3799 [D loss: 0.565541, acc.: 68.75%] [G loss: 0.888718]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3800 [D loss: 0.628945, acc.: 68.75%] [G loss: 0.896689]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3801 [D loss: 0.695970, acc.: 65.62%] [G loss: 0.980054]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3802 [D loss: 0.685955, acc.: 50.00%] [G loss: 0.893871]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3803 [D loss: 0.630830, acc.: 59.38%] [G loss: 0.876963]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3804 [D loss: 0.689081, acc.: 56.25%] [G loss: 0.912293]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3805 [D loss: 0.659328, acc.: 59.38%] [G loss: 0.932009]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3806 [D loss: 0.680136, acc.: 59.38%] [G loss: 0.895300]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3807 [D loss: 0.639070, acc.: 62.50%] [G loss: 0.961892]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3808 [D loss: 0.677540, acc.: 53.12%] [G loss: 1.000303]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3809 [D loss: 0.642154, acc.: 65.62%] [G loss: 0.923560]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3810 [D loss: 0.561751, acc.: 71.88%] [G loss: 1.037015]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3811 [D loss: 0.662754, acc.: 59.38%] [G loss: 0.957605]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3812 [D loss: 0.648612, acc.: 65.62%] [G loss: 1.025821]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3813 [D loss: 0.561249, acc.: 75.00%] [G loss: 0.942214]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3814 [D loss: 0.674627, acc.: 59.38%] [G loss: 0.889609]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3815 [D loss: 0.713890, acc.: 53.12%] [G loss: 0.934699]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3816 [D loss: 0.586840, acc.: 68.75%] [G loss: 0.884473]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3817 [D loss: 0.604267, acc.: 62.50%] [G loss: 0.875705]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3818 [D loss: 0.710108, acc.: 56.25%] [G loss: 0.878023]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3819 [D loss: 0.613411, acc.: 75.00%] [G loss: 0.821067]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3820 [D loss: 0.566286, acc.: 65.62%] [G loss: 0.887771]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3821 [D loss: 0.615123, acc.: 68.75%] [G loss: 0.889086]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3822 [D loss: 0.619931, acc.: 62.50%] [G loss: 0.840087]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3823 [D loss: 0.646713, acc.: 59.38%] [G loss: 0.728073]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3824 [D loss: 0.601114, acc.: 75.00%] [G loss: 0.856551]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3825 [D loss: 0.669687, acc.: 59.38%] [G loss: 0.851253]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3826 [D loss: 0.634420, acc.: 56.25%] [G loss: 0.835222]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3827 [D loss: 0.602296, acc.: 75.00%] [G loss: 0.859026]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3828 [D loss: 0.686420, acc.: 50.00%] [G loss: 0.961110]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3829 [D loss: 0.542354, acc.: 84.38%] [G loss: 0.899898]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3830 [D loss: 0.699130, acc.: 53.12%] [G loss: 0.839315]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3831 [D loss: 0.613292, acc.: 71.88%] [G loss: 0.893667]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3832 [D loss: 0.623995, acc.: 62.50%] [G loss: 0.861918]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3833 [D loss: 0.577864, acc.: 78.12%] [G loss: 0.824552]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3834 [D loss: 0.654818, acc.: 62.50%] [G loss: 0.857533]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3835 [D loss: 0.700918, acc.: 62.50%] [G loss: 0.815793]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3836 [D loss: 0.564014, acc.: 71.88%] [G loss: 0.886985]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3837 [D loss: 0.697940, acc.: 56.25%] [G loss: 0.855585]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3838 [D loss: 0.633660, acc.: 59.38%] [G loss: 0.922836]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3839 [D loss: 0.634137, acc.: 71.88%] [G loss: 0.838436]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3840 [D loss: 0.576523, acc.: 75.00%] [G loss: 0.927359]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3841 [D loss: 0.652493, acc.: 56.25%] [G loss: 0.867374]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3842 [D loss: 0.762464, acc.: 46.88%] [G loss: 0.807418]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3843 [D loss: 0.555451, acc.: 71.88%] [G loss: 0.838055]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3844 [D loss: 0.647702, acc.: 53.12%] [G loss: 0.904858]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3845 [D loss: 0.605740, acc.: 68.75%] [G loss: 0.852674]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3846 [D loss: 0.676466, acc.: 50.00%] [G loss: 0.856538]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3847 [D loss: 0.638990, acc.: 65.62%] [G loss: 0.873455]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3848 [D loss: 0.745020, acc.: 59.38%] [G loss: 0.882551]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3849 [D loss: 0.636007, acc.: 65.62%] [G loss: 0.934975]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3850 [D loss: 0.620187, acc.: 62.50%] [G loss: 1.013563]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3851 [D loss: 0.549549, acc.: 78.12%] [G loss: 0.959573]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3852 [D loss: 0.688344, acc.: 59.38%] [G loss: 0.891823]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3853 [D loss: 0.589079, acc.: 68.75%] [G loss: 1.032696]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3854 [D loss: 0.600218, acc.: 75.00%] [G loss: 0.957786]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3855 [D loss: 0.607407, acc.: 78.12%] [G loss: 0.894021]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3856 [D loss: 0.645767, acc.: 59.38%] [G loss: 0.939524]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3857 [D loss: 0.743186, acc.: 53.12%] [G loss: 0.897636]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3858 [D loss: 0.638448, acc.: 68.75%] [G loss: 0.919549]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3859 [D loss: 0.702811, acc.: 53.12%] [G loss: 1.054047]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3860 [D loss: 0.708427, acc.: 53.12%] [G loss: 0.974930]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3861 [D loss: 0.644521, acc.: 68.75%] [G loss: 0.905202]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3862 [D loss: 0.615682, acc.: 68.75%] [G loss: 0.916297]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3863 [D loss: 0.648122, acc.: 68.75%] [G loss: 0.919606]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3864 [D loss: 0.601562, acc.: 78.12%] [G loss: 0.973202]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3865 [D loss: 0.649876, acc.: 59.38%] [G loss: 0.946324]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3866 [D loss: 0.633934, acc.: 53.12%] [G loss: 0.970899]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3867 [D loss: 0.642185, acc.: 53.12%] [G loss: 0.949684]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3868 [D loss: 0.713960, acc.: 56.25%] [G loss: 0.934615]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3869 [D loss: 0.585413, acc.: 68.75%] [G loss: 0.954344]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3870 [D loss: 0.682963, acc.: 65.62%] [G loss: 0.831064]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3871 [D loss: 0.719394, acc.: 53.12%] [G loss: 0.908138]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "3872 [D loss: 0.618679, acc.: 65.62%] [G loss: 0.848395]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3873 [D loss: 0.604503, acc.: 71.88%] [G loss: 0.884996]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3874 [D loss: 0.687323, acc.: 43.75%] [G loss: 0.864949]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3875 [D loss: 0.604599, acc.: 68.75%] [G loss: 0.863333]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3876 [D loss: 0.624536, acc.: 53.12%] [G loss: 0.762816]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3877 [D loss: 0.673605, acc.: 62.50%] [G loss: 0.854222]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3878 [D loss: 0.641177, acc.: 53.12%] [G loss: 0.906201]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3879 [D loss: 0.543005, acc.: 78.12%] [G loss: 0.980366]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "3880 [D loss: 0.699121, acc.: 62.50%] [G loss: 0.979663]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3881 [D loss: 0.601043, acc.: 68.75%] [G loss: 0.931004]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3882 [D loss: 0.643325, acc.: 62.50%] [G loss: 0.868933]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3883 [D loss: 0.676738, acc.: 53.12%] [G loss: 0.960201]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3884 [D loss: 0.670048, acc.: 62.50%] [G loss: 0.974251]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "3885 [D loss: 0.637623, acc.: 59.38%] [G loss: 0.969175]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "3886 [D loss: 0.615807, acc.: 68.75%] [G loss: 0.995064]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "3887 [D loss: 0.552724, acc.: 71.88%] [G loss: 0.999065]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3888 [D loss: 0.636191, acc.: 53.12%] [G loss: 0.996847]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3889 [D loss: 0.728082, acc.: 56.25%] [G loss: 0.870220]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3890 [D loss: 0.593443, acc.: 71.88%] [G loss: 0.910403]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "3891 [D loss: 0.643344, acc.: 71.88%] [G loss: 0.874561]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3892 [D loss: 0.678531, acc.: 62.50%] [G loss: 0.918087]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3893 [D loss: 0.603864, acc.: 68.75%] [G loss: 0.909482]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "3894 [D loss: 0.563801, acc.: 71.88%] [G loss: 0.918682]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3895 [D loss: 0.714481, acc.: 50.00%] [G loss: 1.071326]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3896 [D loss: 0.680801, acc.: 53.12%] [G loss: 0.910212]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3897 [D loss: 0.628889, acc.: 71.88%] [G loss: 0.931996]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3898 [D loss: 0.620240, acc.: 68.75%] [G loss: 0.912761]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3899 [D loss: 0.620331, acc.: 62.50%] [G loss: 0.885551]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3900 [D loss: 0.714540, acc.: 68.75%] [G loss: 0.869886]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3901 [D loss: 0.690948, acc.: 65.62%] [G loss: 0.913533]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3902 [D loss: 0.608772, acc.: 68.75%] [G loss: 0.955052]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3903 [D loss: 0.718067, acc.: 56.25%] [G loss: 0.942438]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3904 [D loss: 0.583593, acc.: 81.25%] [G loss: 0.881045]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3905 [D loss: 0.544432, acc.: 71.88%] [G loss: 0.869549]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3906 [D loss: 0.651243, acc.: 71.88%] [G loss: 0.945703]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3907 [D loss: 0.645213, acc.: 62.50%] [G loss: 0.909633]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3908 [D loss: 0.568097, acc.: 71.88%] [G loss: 0.856060]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3909 [D loss: 0.641544, acc.: 59.38%] [G loss: 0.890319]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3910 [D loss: 0.607311, acc.: 68.75%] [G loss: 0.834753]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3911 [D loss: 0.732524, acc.: 43.75%] [G loss: 0.926153]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3912 [D loss: 0.702612, acc.: 62.50%] [G loss: 0.909759]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3913 [D loss: 0.665605, acc.: 59.38%] [G loss: 0.843882]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3914 [D loss: 0.612285, acc.: 65.62%] [G loss: 0.856133]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3915 [D loss: 0.606713, acc.: 71.88%] [G loss: 0.882249]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3916 [D loss: 0.697222, acc.: 59.38%] [G loss: 0.921623]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3917 [D loss: 0.623428, acc.: 68.75%] [G loss: 0.990737]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3918 [D loss: 0.578596, acc.: 78.12%] [G loss: 0.903183]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3919 [D loss: 0.691392, acc.: 59.38%] [G loss: 1.024803]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3920 [D loss: 0.670471, acc.: 50.00%] [G loss: 0.862032]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3921 [D loss: 0.630449, acc.: 59.38%] [G loss: 0.959087]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3922 [D loss: 0.577504, acc.: 68.75%] [G loss: 0.939807]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3923 [D loss: 0.701681, acc.: 53.12%] [G loss: 0.897442]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3924 [D loss: 0.729324, acc.: 50.00%] [G loss: 0.874021]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3925 [D loss: 0.705678, acc.: 53.12%] [G loss: 0.839541]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3926 [D loss: 0.612045, acc.: 68.75%] [G loss: 0.954445]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3927 [D loss: 0.719890, acc.: 50.00%] [G loss: 1.006118]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3928 [D loss: 0.674279, acc.: 50.00%] [G loss: 1.042977]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3929 [D loss: 0.665222, acc.: 62.50%] [G loss: 0.882189]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3930 [D loss: 0.639530, acc.: 68.75%] [G loss: 0.907337]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3931 [D loss: 0.608824, acc.: 68.75%] [G loss: 0.900814]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3932 [D loss: 0.610011, acc.: 62.50%] [G loss: 0.938287]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3933 [D loss: 0.623714, acc.: 68.75%] [G loss: 0.954304]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3934 [D loss: 0.684043, acc.: 56.25%] [G loss: 0.881374]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3935 [D loss: 0.705945, acc.: 56.25%] [G loss: 0.845546]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3936 [D loss: 0.635561, acc.: 65.62%] [G loss: 0.922068]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3937 [D loss: 0.716099, acc.: 56.25%] [G loss: 0.917769]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3938 [D loss: 0.670134, acc.: 62.50%] [G loss: 0.809103]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3939 [D loss: 0.716102, acc.: 46.88%] [G loss: 0.842201]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3940 [D loss: 0.692749, acc.: 62.50%] [G loss: 0.850489]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3941 [D loss: 0.583375, acc.: 71.88%] [G loss: 0.881743]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3942 [D loss: 0.646512, acc.: 68.75%] [G loss: 0.960103]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3943 [D loss: 0.741916, acc.: 43.75%] [G loss: 0.927488]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3944 [D loss: 0.683865, acc.: 46.88%] [G loss: 0.853216]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3945 [D loss: 0.672948, acc.: 68.75%] [G loss: 0.861269]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3946 [D loss: 0.661707, acc.: 62.50%] [G loss: 0.872403]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3947 [D loss: 0.638574, acc.: 56.25%] [G loss: 0.895808]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3948 [D loss: 0.654318, acc.: 65.62%] [G loss: 0.957133]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3949 [D loss: 0.599815, acc.: 68.75%] [G loss: 1.029871]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3950 [D loss: 0.569313, acc.: 78.12%] [G loss: 1.026178]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3951 [D loss: 0.612251, acc.: 65.62%] [G loss: 0.976881]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3952 [D loss: 0.682401, acc.: 53.12%] [G loss: 0.905413]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3953 [D loss: 0.568356, acc.: 78.12%] [G loss: 0.883107]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3954 [D loss: 0.597004, acc.: 68.75%] [G loss: 0.933024]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3955 [D loss: 0.552883, acc.: 75.00%] [G loss: 0.888191]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3956 [D loss: 0.667811, acc.: 62.50%] [G loss: 0.914043]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3957 [D loss: 0.605156, acc.: 78.12%] [G loss: 0.835610]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3958 [D loss: 0.672397, acc.: 62.50%] [G loss: 0.939424]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3959 [D loss: 0.604605, acc.: 68.75%] [G loss: 0.979039]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3960 [D loss: 0.638977, acc.: 68.75%] [G loss: 0.926508]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3961 [D loss: 0.634920, acc.: 59.38%] [G loss: 0.898863]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3962 [D loss: 0.602634, acc.: 71.88%] [G loss: 0.902266]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3963 [D loss: 0.544568, acc.: 75.00%] [G loss: 0.946342]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3964 [D loss: 0.613082, acc.: 71.88%] [G loss: 0.942949]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3965 [D loss: 0.648617, acc.: 53.12%] [G loss: 0.933207]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3966 [D loss: 0.631708, acc.: 62.50%] [G loss: 0.965983]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3967 [D loss: 0.616714, acc.: 71.88%] [G loss: 1.052521]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3968 [D loss: 0.634144, acc.: 65.62%] [G loss: 0.935993]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3969 [D loss: 0.595587, acc.: 75.00%] [G loss: 0.826512]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3970 [D loss: 0.628090, acc.: 59.38%] [G loss: 0.951942]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3971 [D loss: 0.684279, acc.: 62.50%] [G loss: 1.029056]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3972 [D loss: 0.604604, acc.: 62.50%] [G loss: 0.931413]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3973 [D loss: 0.573427, acc.: 71.88%] [G loss: 0.946545]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3974 [D loss: 0.704657, acc.: 43.75%] [G loss: 0.978253]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3975 [D loss: 0.518646, acc.: 84.38%] [G loss: 0.938957]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3976 [D loss: 0.558546, acc.: 78.12%] [G loss: 0.948980]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3977 [D loss: 0.742262, acc.: 59.38%] [G loss: 0.970788]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3978 [D loss: 0.565615, acc.: 75.00%] [G loss: 0.976735]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3979 [D loss: 0.695716, acc.: 65.62%] [G loss: 0.951979]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3980 [D loss: 0.700157, acc.: 46.88%] [G loss: 1.047398]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3981 [D loss: 0.741216, acc.: 43.75%] [G loss: 0.931360]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3982 [D loss: 0.640593, acc.: 65.62%] [G loss: 0.919342]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3983 [D loss: 0.631499, acc.: 75.00%] [G loss: 0.975331]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3984 [D loss: 0.604645, acc.: 62.50%] [G loss: 1.017312]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3985 [D loss: 0.638151, acc.: 68.75%] [G loss: 0.952780]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3986 [D loss: 0.686535, acc.: 53.12%] [G loss: 0.987265]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3987 [D loss: 0.563771, acc.: 81.25%] [G loss: 1.012355]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3988 [D loss: 0.703742, acc.: 56.25%] [G loss: 0.972236]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3989 [D loss: 0.527526, acc.: 75.00%] [G loss: 1.006147]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3990 [D loss: 0.736540, acc.: 43.75%] [G loss: 0.871304]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3991 [D loss: 0.647875, acc.: 59.38%] [G loss: 0.833668]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3992 [D loss: 0.652571, acc.: 62.50%] [G loss: 0.784797]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3993 [D loss: 0.552372, acc.: 71.88%] [G loss: 0.896126]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3994 [D loss: 0.618024, acc.: 65.62%] [G loss: 0.939358]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3995 [D loss: 0.648755, acc.: 68.75%] [G loss: 0.921441]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3996 [D loss: 0.680734, acc.: 62.50%] [G loss: 0.871700]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3997 [D loss: 0.657884, acc.: 59.38%] [G loss: 0.971376]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3998 [D loss: 0.653749, acc.: 65.62%] [G loss: 1.049537]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3999 [D loss: 0.674949, acc.: 59.38%] [G loss: 0.971460]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4000 [D loss: 0.477311, acc.: 81.25%] [G loss: 0.992714]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4001 [D loss: 0.611932, acc.: 65.62%] [G loss: 0.929749]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4002 [D loss: 0.727267, acc.: 59.38%] [G loss: 0.892816]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4003 [D loss: 0.639067, acc.: 56.25%] [G loss: 0.871342]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4004 [D loss: 0.634819, acc.: 62.50%] [G loss: 0.965225]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4005 [D loss: 0.751843, acc.: 37.50%] [G loss: 0.919189]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4006 [D loss: 0.626880, acc.: 59.38%] [G loss: 0.856394]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4007 [D loss: 0.694941, acc.: 59.38%] [G loss: 0.927236]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4008 [D loss: 0.584456, acc.: 71.88%] [G loss: 0.966204]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4009 [D loss: 0.566691, acc.: 68.75%] [G loss: 0.951329]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4010 [D loss: 0.633121, acc.: 59.38%] [G loss: 0.990201]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4011 [D loss: 0.617039, acc.: 59.38%] [G loss: 0.943422]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4012 [D loss: 0.630826, acc.: 62.50%] [G loss: 1.019400]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4013 [D loss: 0.727965, acc.: 56.25%] [G loss: 0.962994]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4014 [D loss: 0.570426, acc.: 75.00%] [G loss: 0.880553]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4015 [D loss: 0.554653, acc.: 81.25%] [G loss: 0.928773]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4016 [D loss: 0.663944, acc.: 53.12%] [G loss: 0.995733]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4017 [D loss: 0.557844, acc.: 68.75%] [G loss: 0.974198]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4018 [D loss: 0.689138, acc.: 62.50%] [G loss: 1.000945]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4019 [D loss: 0.688017, acc.: 59.38%] [G loss: 0.971591]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4020 [D loss: 0.779490, acc.: 40.62%] [G loss: 0.839647]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4021 [D loss: 0.629249, acc.: 65.62%] [G loss: 0.953860]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4022 [D loss: 0.586417, acc.: 71.88%] [G loss: 1.000457]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4023 [D loss: 0.663405, acc.: 56.25%] [G loss: 0.979682]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4024 [D loss: 0.609953, acc.: 62.50%] [G loss: 0.992008]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4025 [D loss: 0.658864, acc.: 62.50%] [G loss: 0.927078]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4026 [D loss: 0.713520, acc.: 62.50%] [G loss: 0.994598]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4027 [D loss: 0.652185, acc.: 56.25%] [G loss: 0.994257]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4028 [D loss: 0.670360, acc.: 56.25%] [G loss: 0.905560]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4029 [D loss: 0.640244, acc.: 50.00%] [G loss: 1.055014]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4030 [D loss: 0.609638, acc.: 68.75%] [G loss: 0.920962]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4031 [D loss: 0.674756, acc.: 46.88%] [G loss: 0.858548]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4032 [D loss: 0.627848, acc.: 71.88%] [G loss: 0.890814]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4033 [D loss: 0.647265, acc.: 59.38%] [G loss: 0.887077]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4034 [D loss: 0.651964, acc.: 65.62%] [G loss: 0.855631]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4035 [D loss: 0.678253, acc.: 56.25%] [G loss: 0.946172]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4036 [D loss: 0.598837, acc.: 62.50%] [G loss: 0.992614]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4037 [D loss: 0.730345, acc.: 40.62%] [G loss: 0.884161]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4038 [D loss: 0.659906, acc.: 59.38%] [G loss: 0.919974]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4039 [D loss: 0.737591, acc.: 50.00%] [G loss: 0.848011]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4040 [D loss: 0.666016, acc.: 56.25%] [G loss: 0.885644]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4041 [D loss: 0.617754, acc.: 56.25%] [G loss: 0.921985]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4042 [D loss: 0.677464, acc.: 62.50%] [G loss: 0.842237]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4043 [D loss: 0.536323, acc.: 71.88%] [G loss: 0.813437]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4044 [D loss: 0.634223, acc.: 68.75%] [G loss: 0.929574]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4045 [D loss: 0.675844, acc.: 53.12%] [G loss: 0.931635]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4046 [D loss: 0.674996, acc.: 56.25%] [G loss: 0.940296]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4047 [D loss: 0.747822, acc.: 53.12%] [G loss: 0.904112]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4048 [D loss: 0.554098, acc.: 78.12%] [G loss: 0.949774]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4049 [D loss: 0.723709, acc.: 46.88%] [G loss: 0.919306]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4050 [D loss: 0.572665, acc.: 68.75%] [G loss: 0.934240]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4051 [D loss: 0.663583, acc.: 71.88%] [G loss: 0.903375]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4052 [D loss: 0.674901, acc.: 56.25%] [G loss: 0.910963]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4053 [D loss: 0.605092, acc.: 71.88%] [G loss: 0.926482]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4054 [D loss: 0.605810, acc.: 65.62%] [G loss: 0.935248]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4055 [D loss: 0.543148, acc.: 87.50%] [G loss: 0.927551]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4056 [D loss: 0.605894, acc.: 68.75%] [G loss: 0.923543]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4057 [D loss: 0.704628, acc.: 65.62%] [G loss: 0.883451]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4058 [D loss: 0.566841, acc.: 71.88%] [G loss: 0.905852]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4059 [D loss: 0.600385, acc.: 68.75%] [G loss: 0.878340]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4060 [D loss: 0.532235, acc.: 81.25%] [G loss: 0.924182]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4061 [D loss: 0.606002, acc.: 65.62%] [G loss: 0.887265]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4062 [D loss: 0.649490, acc.: 68.75%] [G loss: 0.921450]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4063 [D loss: 0.719582, acc.: 50.00%] [G loss: 0.883977]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4064 [D loss: 0.678501, acc.: 59.38%] [G loss: 0.916594]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4065 [D loss: 0.650206, acc.: 71.88%] [G loss: 0.898188]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4066 [D loss: 0.699575, acc.: 40.62%] [G loss: 1.000005]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4067 [D loss: 0.654678, acc.: 68.75%] [G loss: 0.905102]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4068 [D loss: 0.626565, acc.: 59.38%] [G loss: 0.850876]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4069 [D loss: 0.616541, acc.: 71.88%] [G loss: 0.828441]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4070 [D loss: 0.678843, acc.: 59.38%] [G loss: 0.892349]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4071 [D loss: 0.648518, acc.: 56.25%] [G loss: 0.933971]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4072 [D loss: 0.673365, acc.: 62.50%] [G loss: 0.965296]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4073 [D loss: 0.764986, acc.: 40.62%] [G loss: 0.958307]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4074 [D loss: 0.670325, acc.: 56.25%] [G loss: 0.847076]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4075 [D loss: 0.517133, acc.: 84.38%] [G loss: 0.932643]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4076 [D loss: 0.727057, acc.: 43.75%] [G loss: 0.861191]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4077 [D loss: 0.648991, acc.: 62.50%] [G loss: 0.879264]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4078 [D loss: 0.553648, acc.: 78.12%] [G loss: 0.827490]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4079 [D loss: 0.585632, acc.: 62.50%] [G loss: 0.836044]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4080 [D loss: 0.623029, acc.: 75.00%] [G loss: 0.828368]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4081 [D loss: 0.670337, acc.: 62.50%] [G loss: 0.843446]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4082 [D loss: 0.639076, acc.: 56.25%] [G loss: 0.851725]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4083 [D loss: 0.689379, acc.: 50.00%] [G loss: 0.895696]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4084 [D loss: 0.658811, acc.: 62.50%] [G loss: 0.765434]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4085 [D loss: 0.635441, acc.: 71.88%] [G loss: 0.844598]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4086 [D loss: 0.676831, acc.: 62.50%] [G loss: 0.905808]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4087 [D loss: 0.617858, acc.: 71.88%] [G loss: 0.907877]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4088 [D loss: 0.572380, acc.: 71.88%] [G loss: 0.940263]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4089 [D loss: 0.664335, acc.: 65.62%] [G loss: 0.837840]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4090 [D loss: 0.652751, acc.: 59.38%] [G loss: 0.896051]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4091 [D loss: 0.568811, acc.: 68.75%] [G loss: 0.839671]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4092 [D loss: 0.804792, acc.: 34.38%] [G loss: 0.828123]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4093 [D loss: 0.535615, acc.: 84.38%] [G loss: 0.920653]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4094 [D loss: 0.616858, acc.: 68.75%] [G loss: 0.939947]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4095 [D loss: 0.630155, acc.: 53.12%] [G loss: 0.916996]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4096 [D loss: 0.686409, acc.: 62.50%] [G loss: 0.917540]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4097 [D loss: 0.502376, acc.: 84.38%] [G loss: 0.978942]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4098 [D loss: 0.714233, acc.: 59.38%] [G loss: 0.895563]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4099 [D loss: 0.635024, acc.: 62.50%] [G loss: 0.905255]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4100 [D loss: 0.678868, acc.: 65.62%] [G loss: 0.813636]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4101 [D loss: 0.735125, acc.: 50.00%] [G loss: 0.891219]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "4102 [D loss: 0.587334, acc.: 71.88%] [G loss: 0.835410]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4103 [D loss: 0.557095, acc.: 75.00%] [G loss: 1.004961]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4104 [D loss: 0.609760, acc.: 59.38%] [G loss: 1.010566]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4105 [D loss: 0.726468, acc.: 43.75%] [G loss: 0.951423]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4106 [D loss: 0.574728, acc.: 75.00%] [G loss: 0.938937]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4107 [D loss: 0.661459, acc.: 68.75%] [G loss: 0.895628]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4108 [D loss: 0.678474, acc.: 65.62%] [G loss: 1.004156]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4109 [D loss: 0.710934, acc.: 56.25%] [G loss: 0.974237]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4110 [D loss: 0.682765, acc.: 56.25%] [G loss: 1.041434]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4111 [D loss: 0.601245, acc.: 65.62%] [G loss: 0.961348]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "4112 [D loss: 0.589878, acc.: 78.12%] [G loss: 0.901148]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "4113 [D loss: 0.633726, acc.: 56.25%] [G loss: 0.922729]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "4114 [D loss: 0.606470, acc.: 71.88%] [G loss: 1.074239]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4115 [D loss: 0.784405, acc.: 50.00%] [G loss: 0.921604]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4116 [D loss: 0.669823, acc.: 59.38%] [G loss: 0.967842]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4117 [D loss: 0.624296, acc.: 62.50%] [G loss: 0.900156]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4118 [D loss: 0.587674, acc.: 68.75%] [G loss: 0.862835]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4119 [D loss: 0.622291, acc.: 65.62%] [G loss: 0.873090]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4120 [D loss: 0.552026, acc.: 81.25%] [G loss: 0.840328]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4121 [D loss: 0.679550, acc.: 59.38%] [G loss: 0.884649]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4122 [D loss: 0.647175, acc.: 71.88%] [G loss: 0.870959]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4123 [D loss: 0.699448, acc.: 62.50%] [G loss: 0.909511]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4124 [D loss: 0.622913, acc.: 68.75%] [G loss: 0.961495]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4125 [D loss: 0.609507, acc.: 68.75%] [G loss: 0.916864]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4126 [D loss: 0.570224, acc.: 75.00%] [G loss: 0.989070]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4127 [D loss: 0.730653, acc.: 46.88%] [G loss: 0.901770]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4128 [D loss: 0.669479, acc.: 65.62%] [G loss: 0.977702]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4129 [D loss: 0.724363, acc.: 53.12%] [G loss: 0.830207]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4130 [D loss: 0.654622, acc.: 62.50%] [G loss: 0.884545]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4131 [D loss: 0.586488, acc.: 65.62%] [G loss: 0.849752]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4132 [D loss: 0.652704, acc.: 62.50%] [G loss: 0.875548]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4133 [D loss: 0.643548, acc.: 62.50%] [G loss: 1.030876]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4134 [D loss: 0.700758, acc.: 50.00%] [G loss: 0.984482]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4135 [D loss: 0.619484, acc.: 68.75%] [G loss: 0.968279]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4136 [D loss: 0.643962, acc.: 59.38%] [G loss: 0.899613]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4137 [D loss: 0.578803, acc.: 68.75%] [G loss: 0.963073]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4138 [D loss: 0.678999, acc.: 46.88%] [G loss: 0.863595]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4139 [D loss: 0.607597, acc.: 68.75%] [G loss: 0.876385]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4140 [D loss: 0.664741, acc.: 68.75%] [G loss: 0.887999]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4141 [D loss: 0.601467, acc.: 71.88%] [G loss: 0.902145]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4142 [D loss: 0.566328, acc.: 71.88%] [G loss: 0.939080]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4143 [D loss: 0.614498, acc.: 68.75%] [G loss: 0.850611]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4144 [D loss: 0.581384, acc.: 65.62%] [G loss: 0.866463]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4145 [D loss: 0.642714, acc.: 56.25%] [G loss: 0.827599]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4146 [D loss: 0.666460, acc.: 62.50%] [G loss: 0.918618]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4147 [D loss: 0.619242, acc.: 68.75%] [G loss: 0.981833]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4148 [D loss: 0.714313, acc.: 62.50%] [G loss: 1.052432]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4149 [D loss: 0.593819, acc.: 71.88%] [G loss: 0.965254]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4150 [D loss: 0.695125, acc.: 56.25%] [G loss: 0.859878]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4151 [D loss: 0.624624, acc.: 65.62%] [G loss: 0.907041]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4152 [D loss: 0.613794, acc.: 62.50%] [G loss: 0.818810]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4153 [D loss: 0.595338, acc.: 75.00%] [G loss: 0.892976]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4154 [D loss: 0.624497, acc.: 68.75%] [G loss: 0.965217]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4155 [D loss: 0.571032, acc.: 68.75%] [G loss: 0.965985]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4156 [D loss: 0.685278, acc.: 53.12%] [G loss: 0.977953]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4157 [D loss: 0.641394, acc.: 75.00%] [G loss: 1.054773]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4158 [D loss: 0.605330, acc.: 59.38%] [G loss: 0.939289]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4159 [D loss: 0.726599, acc.: 46.88%] [G loss: 0.868382]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4160 [D loss: 0.595911, acc.: 75.00%] [G loss: 0.861204]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4161 [D loss: 0.635906, acc.: 68.75%] [G loss: 0.822867]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4162 [D loss: 0.690357, acc.: 65.62%] [G loss: 0.874539]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4163 [D loss: 0.654018, acc.: 62.50%] [G loss: 0.875974]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4164 [D loss: 0.607492, acc.: 75.00%] [G loss: 0.918610]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4165 [D loss: 0.583522, acc.: 65.62%] [G loss: 0.958518]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4166 [D loss: 0.621998, acc.: 68.75%] [G loss: 0.921606]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4167 [D loss: 0.653134, acc.: 65.62%] [G loss: 0.964128]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4168 [D loss: 0.728019, acc.: 46.88%] [G loss: 0.915533]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4169 [D loss: 0.577283, acc.: 75.00%] [G loss: 0.886656]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4170 [D loss: 0.607116, acc.: 65.62%] [G loss: 0.981679]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4171 [D loss: 0.705393, acc.: 50.00%] [G loss: 0.913074]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4172 [D loss: 0.612908, acc.: 62.50%] [G loss: 0.883342]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4173 [D loss: 0.658917, acc.: 62.50%] [G loss: 0.868935]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4174 [D loss: 0.595572, acc.: 65.62%] [G loss: 0.917257]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4175 [D loss: 0.577642, acc.: 71.88%] [G loss: 0.865219]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4176 [D loss: 0.699790, acc.: 59.38%] [G loss: 0.972263]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4177 [D loss: 0.754716, acc.: 53.12%] [G loss: 0.914860]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4178 [D loss: 0.707574, acc.: 53.12%] [G loss: 0.930641]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4179 [D loss: 0.679604, acc.: 59.38%] [G loss: 1.054062]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4180 [D loss: 0.639460, acc.: 59.38%] [G loss: 0.905975]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4181 [D loss: 0.635311, acc.: 68.75%] [G loss: 0.950462]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4182 [D loss: 0.622602, acc.: 71.88%] [G loss: 0.934286]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4183 [D loss: 0.694544, acc.: 56.25%] [G loss: 0.931065]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4184 [D loss: 0.596716, acc.: 65.62%] [G loss: 0.966613]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4185 [D loss: 0.549229, acc.: 81.25%] [G loss: 0.852379]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4186 [D loss: 0.717093, acc.: 50.00%] [G loss: 0.766746]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4187 [D loss: 0.678554, acc.: 56.25%] [G loss: 0.750003]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4188 [D loss: 0.784226, acc.: 59.38%] [G loss: 0.847209]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4189 [D loss: 0.670857, acc.: 65.62%] [G loss: 0.912970]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4190 [D loss: 0.661028, acc.: 68.75%] [G loss: 0.920943]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4191 [D loss: 0.741010, acc.: 46.88%] [G loss: 0.941372]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4192 [D loss: 0.559609, acc.: 78.12%] [G loss: 0.889339]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4193 [D loss: 0.650688, acc.: 65.62%] [G loss: 0.901567]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4194 [D loss: 0.763155, acc.: 37.50%] [G loss: 0.842055]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4195 [D loss: 0.604321, acc.: 71.88%] [G loss: 0.931869]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4196 [D loss: 0.603608, acc.: 68.75%] [G loss: 0.918414]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4197 [D loss: 0.530526, acc.: 81.25%] [G loss: 0.860525]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4198 [D loss: 0.612324, acc.: 59.38%] [G loss: 0.814064]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4199 [D loss: 0.593133, acc.: 78.12%] [G loss: 0.866978]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4200 [D loss: 0.627660, acc.: 62.50%] [G loss: 0.898463]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4201 [D loss: 0.634925, acc.: 59.38%] [G loss: 0.926738]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4202 [D loss: 0.555361, acc.: 75.00%] [G loss: 0.939584]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4203 [D loss: 0.770022, acc.: 46.88%] [G loss: 0.968879]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4204 [D loss: 0.664511, acc.: 65.62%] [G loss: 0.912828]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "4205 [D loss: 0.620509, acc.: 65.62%] [G loss: 0.889306]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4206 [D loss: 0.626101, acc.: 62.50%] [G loss: 0.949507]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "4207 [D loss: 0.581063, acc.: 68.75%] [G loss: 0.889945]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4208 [D loss: 0.697717, acc.: 46.88%] [G loss: 0.847504]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4209 [D loss: 0.691673, acc.: 53.12%] [G loss: 0.937146]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4210 [D loss: 0.664530, acc.: 62.50%] [G loss: 0.905235]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4211 [D loss: 0.694078, acc.: 46.88%] [G loss: 0.868402]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4212 [D loss: 0.646346, acc.: 62.50%] [G loss: 0.924729]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "4213 [D loss: 0.652408, acc.: 62.50%] [G loss: 0.850488]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4214 [D loss: 0.599603, acc.: 68.75%] [G loss: 0.944690]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4215 [D loss: 0.589533, acc.: 62.50%] [G loss: 0.910864]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "4216 [D loss: 0.724525, acc.: 62.50%] [G loss: 0.921010]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4217 [D loss: 0.584516, acc.: 71.88%] [G loss: 1.014723]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4218 [D loss: 0.620025, acc.: 62.50%] [G loss: 0.845461]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4219 [D loss: 0.654554, acc.: 65.62%] [G loss: 0.872542]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "4220 [D loss: 0.639422, acc.: 71.88%] [G loss: 0.904792]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "4221 [D loss: 0.656948, acc.: 65.62%] [G loss: 0.869146]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "4222 [D loss: 0.668975, acc.: 68.75%] [G loss: 0.896802]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4223 [D loss: 0.626021, acc.: 65.62%] [G loss: 0.992185]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4224 [D loss: 0.617513, acc.: 59.38%] [G loss: 0.979204]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4225 [D loss: 0.620087, acc.: 65.62%] [G loss: 1.018039]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4226 [D loss: 0.712518, acc.: 59.38%] [G loss: 0.869859]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4227 [D loss: 0.685332, acc.: 46.88%] [G loss: 0.894188]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "4228 [D loss: 0.666851, acc.: 56.25%] [G loss: 0.825505]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4229 [D loss: 0.718801, acc.: 40.62%] [G loss: 0.928748]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4230 [D loss: 0.777987, acc.: 46.88%] [G loss: 0.901524]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4231 [D loss: 0.597308, acc.: 81.25%] [G loss: 0.819010]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4232 [D loss: 0.594401, acc.: 68.75%] [G loss: 0.906595]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4233 [D loss: 0.591559, acc.: 59.38%] [G loss: 0.942805]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4234 [D loss: 0.671103, acc.: 59.38%] [G loss: 0.894228]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4235 [D loss: 0.589442, acc.: 65.62%] [G loss: 0.923324]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4236 [D loss: 0.703765, acc.: 46.88%] [G loss: 0.876287]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4237 [D loss: 0.642848, acc.: 53.12%] [G loss: 0.868684]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4238 [D loss: 0.612289, acc.: 68.75%] [G loss: 1.093453]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4239 [D loss: 0.687145, acc.: 53.12%] [G loss: 0.967810]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4240 [D loss: 0.603125, acc.: 59.38%] [G loss: 1.055167]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4241 [D loss: 0.719191, acc.: 62.50%] [G loss: 0.911448]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4242 [D loss: 0.591438, acc.: 71.88%] [G loss: 0.872621]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4243 [D loss: 0.737101, acc.: 53.12%] [G loss: 0.937216]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4244 [D loss: 0.569078, acc.: 71.88%] [G loss: 1.018293]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4245 [D loss: 0.664516, acc.: 62.50%] [G loss: 0.957233]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4246 [D loss: 0.613291, acc.: 59.38%] [G loss: 1.008078]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4247 [D loss: 0.670750, acc.: 59.38%] [G loss: 1.023649]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4248 [D loss: 0.571249, acc.: 71.88%] [G loss: 0.918588]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4249 [D loss: 0.629673, acc.: 68.75%] [G loss: 0.900907]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4250 [D loss: 0.728755, acc.: 59.38%] [G loss: 0.883514]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4251 [D loss: 0.649588, acc.: 65.62%] [G loss: 0.878829]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4252 [D loss: 0.787723, acc.: 40.62%] [G loss: 0.886198]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4253 [D loss: 0.566573, acc.: 78.12%] [G loss: 0.925992]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4254 [D loss: 0.652448, acc.: 65.62%] [G loss: 0.854784]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4255 [D loss: 0.688384, acc.: 46.88%] [G loss: 0.923480]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4256 [D loss: 0.665353, acc.: 56.25%] [G loss: 0.960675]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4257 [D loss: 0.608040, acc.: 62.50%] [G loss: 0.993566]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4258 [D loss: 0.684280, acc.: 59.38%] [G loss: 0.963074]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4259 [D loss: 0.651121, acc.: 62.50%] [G loss: 0.942904]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4260 [D loss: 0.687692, acc.: 56.25%] [G loss: 0.956730]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4261 [D loss: 0.649392, acc.: 68.75%] [G loss: 1.020890]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4262 [D loss: 0.690055, acc.: 50.00%] [G loss: 1.001822]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4263 [D loss: 0.647903, acc.: 59.38%] [G loss: 0.987156]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4264 [D loss: 0.605972, acc.: 68.75%] [G loss: 0.930205]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4265 [D loss: 0.655814, acc.: 62.50%] [G loss: 0.989600]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4266 [D loss: 0.709205, acc.: 62.50%] [G loss: 0.902547]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4267 [D loss: 0.649184, acc.: 56.25%] [G loss: 0.907322]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4268 [D loss: 0.652156, acc.: 65.62%] [G loss: 0.922633]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4269 [D loss: 0.633227, acc.: 65.62%] [G loss: 0.867515]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4270 [D loss: 0.733530, acc.: 62.50%] [G loss: 0.838365]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4271 [D loss: 0.650016, acc.: 59.38%] [G loss: 0.982353]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4272 [D loss: 0.645441, acc.: 62.50%] [G loss: 0.950470]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4273 [D loss: 0.660893, acc.: 65.62%] [G loss: 0.852672]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4274 [D loss: 0.719910, acc.: 46.88%] [G loss: 0.917006]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4275 [D loss: 0.685263, acc.: 53.12%] [G loss: 0.918964]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4276 [D loss: 0.687696, acc.: 62.50%] [G loss: 0.838025]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4277 [D loss: 0.672799, acc.: 62.50%] [G loss: 0.894475]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4278 [D loss: 0.565435, acc.: 71.88%] [G loss: 0.882498]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4279 [D loss: 0.642515, acc.: 65.62%] [G loss: 0.904608]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4280 [D loss: 0.724131, acc.: 50.00%] [G loss: 0.980134]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4281 [D loss: 0.661983, acc.: 56.25%] [G loss: 0.918323]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4282 [D loss: 0.621723, acc.: 68.75%] [G loss: 0.928183]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4283 [D loss: 0.594689, acc.: 75.00%] [G loss: 0.954066]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4284 [D loss: 0.653461, acc.: 59.38%] [G loss: 0.955039]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4285 [D loss: 0.560530, acc.: 62.50%] [G loss: 0.845746]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4286 [D loss: 0.612740, acc.: 59.38%] [G loss: 0.889432]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4287 [D loss: 0.649722, acc.: 62.50%] [G loss: 0.772725]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4288 [D loss: 0.656263, acc.: 59.38%] [G loss: 0.815813]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4289 [D loss: 0.664406, acc.: 59.38%] [G loss: 0.856278]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4290 [D loss: 0.608823, acc.: 71.88%] [G loss: 0.861875]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4291 [D loss: 0.671594, acc.: 50.00%] [G loss: 0.932811]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4292 [D loss: 0.566774, acc.: 65.62%] [G loss: 0.965696]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4293 [D loss: 0.655997, acc.: 56.25%] [G loss: 0.910216]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4294 [D loss: 0.576188, acc.: 75.00%] [G loss: 0.992697]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4295 [D loss: 0.678334, acc.: 59.38%] [G loss: 0.934479]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4296 [D loss: 0.582562, acc.: 68.75%] [G loss: 0.878168]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4297 [D loss: 0.722261, acc.: 56.25%] [G loss: 0.971004]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4298 [D loss: 0.620827, acc.: 68.75%] [G loss: 1.015048]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4299 [D loss: 0.677589, acc.: 59.38%] [G loss: 0.913464]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4300 [D loss: 0.660245, acc.: 59.38%] [G loss: 0.938115]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4301 [D loss: 0.687034, acc.: 53.12%] [G loss: 0.920968]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4302 [D loss: 0.608780, acc.: 65.62%] [G loss: 0.930336]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4303 [D loss: 0.570465, acc.: 71.88%] [G loss: 0.968477]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4304 [D loss: 0.572556, acc.: 65.62%] [G loss: 0.983069]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4305 [D loss: 0.576749, acc.: 68.75%] [G loss: 0.995766]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4306 [D loss: 0.628661, acc.: 65.62%] [G loss: 1.010924]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4307 [D loss: 0.913746, acc.: 31.25%] [G loss: 0.984572]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4308 [D loss: 0.659441, acc.: 59.38%] [G loss: 0.934003]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4309 [D loss: 0.587436, acc.: 75.00%] [G loss: 0.871023]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4310 [D loss: 0.661968, acc.: 59.38%] [G loss: 0.823920]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4311 [D loss: 0.622103, acc.: 75.00%] [G loss: 0.902903]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4312 [D loss: 0.622977, acc.: 62.50%] [G loss: 0.857526]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4313 [D loss: 0.652257, acc.: 65.62%] [G loss: 0.870583]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4314 [D loss: 0.651150, acc.: 59.38%] [G loss: 0.819746]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4315 [D loss: 0.603548, acc.: 78.12%] [G loss: 0.913995]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4316 [D loss: 0.677587, acc.: 56.25%] [G loss: 0.878478]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4317 [D loss: 0.680091, acc.: 50.00%] [G loss: 0.936863]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4318 [D loss: 0.721394, acc.: 50.00%] [G loss: 0.837767]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4319 [D loss: 0.659962, acc.: 62.50%] [G loss: 0.902564]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4320 [D loss: 0.641805, acc.: 56.25%] [G loss: 0.940652]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4321 [D loss: 0.674361, acc.: 65.62%] [G loss: 0.979950]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4322 [D loss: 0.637206, acc.: 65.62%] [G loss: 0.882665]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4323 [D loss: 0.607280, acc.: 71.88%] [G loss: 0.895154]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4324 [D loss: 0.719624, acc.: 56.25%] [G loss: 0.861532]\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "4325 [D loss: 0.720630, acc.: 59.38%] [G loss: 0.915494]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4326 [D loss: 0.628421, acc.: 65.62%] [G loss: 1.000758]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4327 [D loss: 0.691676, acc.: 53.12%] [G loss: 0.945988]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "4328 [D loss: 0.626348, acc.: 71.88%] [G loss: 0.875119]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4329 [D loss: 0.689025, acc.: 50.00%] [G loss: 0.915584]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4330 [D loss: 0.643267, acc.: 65.62%] [G loss: 0.872086]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4331 [D loss: 0.663728, acc.: 59.38%] [G loss: 0.833226]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4332 [D loss: 0.648566, acc.: 68.75%] [G loss: 0.962767]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4333 [D loss: 0.617004, acc.: 68.75%] [G loss: 0.914316]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "4334 [D loss: 0.610003, acc.: 75.00%] [G loss: 0.912222]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4335 [D loss: 0.641048, acc.: 65.62%] [G loss: 0.940656]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4336 [D loss: 0.601905, acc.: 62.50%] [G loss: 1.013165]\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "4337 [D loss: 0.681753, acc.: 62.50%] [G loss: 0.937425]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4338 [D loss: 0.660082, acc.: 59.38%] [G loss: 1.001376]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4339 [D loss: 0.623143, acc.: 71.88%] [G loss: 0.991374]\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "4340 [D loss: 0.594406, acc.: 65.62%] [G loss: 0.942429]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4341 [D loss: 0.588468, acc.: 65.62%] [G loss: 0.954419]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4342 [D loss: 0.645382, acc.: 62.50%] [G loss: 0.965679]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4343 [D loss: 0.601995, acc.: 68.75%] [G loss: 0.876352]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4344 [D loss: 0.598613, acc.: 62.50%] [G loss: 0.900583]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4345 [D loss: 0.647162, acc.: 68.75%] [G loss: 0.947601]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4346 [D loss: 0.577889, acc.: 75.00%] [G loss: 0.935332]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4347 [D loss: 0.676483, acc.: 53.12%] [G loss: 0.955925]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4348 [D loss: 0.710053, acc.: 46.88%] [G loss: 0.840752]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4349 [D loss: 0.607473, acc.: 68.75%] [G loss: 0.862462]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4350 [D loss: 0.589419, acc.: 75.00%] [G loss: 0.872040]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4351 [D loss: 0.707805, acc.: 50.00%] [G loss: 0.823011]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4352 [D loss: 0.687337, acc.: 50.00%] [G loss: 0.885856]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4353 [D loss: 0.670176, acc.: 62.50%] [G loss: 0.867724]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4354 [D loss: 0.594500, acc.: 65.62%] [G loss: 0.957004]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4355 [D loss: 0.642036, acc.: 65.62%] [G loss: 0.912963]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4356 [D loss: 0.732038, acc.: 53.12%] [G loss: 0.894650]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4357 [D loss: 0.681332, acc.: 56.25%] [G loss: 0.888978]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4358 [D loss: 0.755551, acc.: 59.38%] [G loss: 0.844380]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4359 [D loss: 0.672494, acc.: 53.12%] [G loss: 0.885840]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4360 [D loss: 0.657884, acc.: 65.62%] [G loss: 0.838296]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4361 [D loss: 0.602198, acc.: 75.00%] [G loss: 0.868671]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4362 [D loss: 0.703992, acc.: 53.12%] [G loss: 0.874030]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4363 [D loss: 0.628273, acc.: 68.75%] [G loss: 0.891165]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4364 [D loss: 0.726856, acc.: 53.12%] [G loss: 0.923762]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4365 [D loss: 0.659449, acc.: 71.88%] [G loss: 0.893394]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4366 [D loss: 0.606921, acc.: 65.62%] [G loss: 0.849096]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4367 [D loss: 0.642645, acc.: 59.38%] [G loss: 0.862763]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4368 [D loss: 0.612348, acc.: 62.50%] [G loss: 0.905090]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4369 [D loss: 0.616688, acc.: 75.00%] [G loss: 0.895445]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4370 [D loss: 0.686308, acc.: 53.12%] [G loss: 0.884539]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4371 [D loss: 0.706794, acc.: 43.75%] [G loss: 0.919457]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4372 [D loss: 0.772250, acc.: 37.50%] [G loss: 0.853794]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4373 [D loss: 0.633182, acc.: 56.25%] [G loss: 0.878443]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4374 [D loss: 0.591085, acc.: 75.00%] [G loss: 0.910429]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4375 [D loss: 0.662500, acc.: 62.50%] [G loss: 0.903412]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4376 [D loss: 0.627809, acc.: 59.38%] [G loss: 0.889615]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4377 [D loss: 0.606612, acc.: 68.75%] [G loss: 0.918836]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4378 [D loss: 0.654230, acc.: 62.50%] [G loss: 0.860365]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4379 [D loss: 0.550184, acc.: 75.00%] [G loss: 0.867996]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4380 [D loss: 0.684424, acc.: 68.75%] [G loss: 0.890286]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4381 [D loss: 0.555702, acc.: 71.88%] [G loss: 0.907809]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4382 [D loss: 0.594082, acc.: 75.00%] [G loss: 0.928329]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4383 [D loss: 0.665087, acc.: 62.50%] [G loss: 0.909148]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4384 [D loss: 0.649072, acc.: 68.75%] [G loss: 0.943995]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4385 [D loss: 0.680732, acc.: 50.00%] [G loss: 1.009895]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4386 [D loss: 0.674939, acc.: 62.50%] [G loss: 0.925998]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4387 [D loss: 0.630242, acc.: 71.88%] [G loss: 0.896579]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4388 [D loss: 0.578155, acc.: 68.75%] [G loss: 0.894534]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4389 [D loss: 0.612289, acc.: 65.62%] [G loss: 0.914843]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4390 [D loss: 0.628546, acc.: 68.75%] [G loss: 0.974274]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4391 [D loss: 0.555369, acc.: 75.00%] [G loss: 0.970224]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4392 [D loss: 0.586278, acc.: 68.75%] [G loss: 0.997095]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4393 [D loss: 0.630978, acc.: 68.75%] [G loss: 0.770497]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4394 [D loss: 0.773954, acc.: 46.88%] [G loss: 0.848732]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4395 [D loss: 0.699884, acc.: 50.00%] [G loss: 0.833616]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4396 [D loss: 0.656789, acc.: 59.38%] [G loss: 0.891335]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4397 [D loss: 0.650297, acc.: 53.12%] [G loss: 0.940444]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4398 [D loss: 0.670595, acc.: 59.38%] [G loss: 0.892427]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4399 [D loss: 0.726882, acc.: 50.00%] [G loss: 1.025849]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4400 [D loss: 0.567209, acc.: 71.88%] [G loss: 0.877737]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4401 [D loss: 0.728372, acc.: 56.25%] [G loss: 0.867829]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4402 [D loss: 0.658250, acc.: 59.38%] [G loss: 0.855580]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4403 [D loss: 0.597389, acc.: 68.75%] [G loss: 0.883527]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4404 [D loss: 0.605721, acc.: 59.38%] [G loss: 0.912533]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4405 [D loss: 0.531546, acc.: 87.50%] [G loss: 0.907280]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4406 [D loss: 0.645126, acc.: 59.38%] [G loss: 0.812156]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4407 [D loss: 0.768277, acc.: 40.62%] [G loss: 0.792198]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4408 [D loss: 0.631263, acc.: 71.88%] [G loss: 0.910711]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4409 [D loss: 0.739037, acc.: 50.00%] [G loss: 0.865602]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4410 [D loss: 0.652852, acc.: 46.88%] [G loss: 0.909071]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4411 [D loss: 0.571520, acc.: 75.00%] [G loss: 1.007882]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4412 [D loss: 0.616138, acc.: 68.75%] [G loss: 0.955941]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4413 [D loss: 0.697905, acc.: 65.62%] [G loss: 0.877690]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4414 [D loss: 0.655392, acc.: 62.50%] [G loss: 0.971796]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4415 [D loss: 0.581515, acc.: 71.88%] [G loss: 0.928257]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4416 [D loss: 0.649654, acc.: 56.25%] [G loss: 0.934749]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4417 [D loss: 0.639672, acc.: 68.75%] [G loss: 0.858881]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4418 [D loss: 0.710776, acc.: 62.50%] [G loss: 0.923245]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4419 [D loss: 0.721382, acc.: 46.88%] [G loss: 0.932953]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4420 [D loss: 0.696854, acc.: 59.38%] [G loss: 0.917325]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4421 [D loss: 0.673173, acc.: 56.25%] [G loss: 0.900333]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4422 [D loss: 0.627247, acc.: 56.25%] [G loss: 0.886581]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4423 [D loss: 0.646025, acc.: 62.50%] [G loss: 0.921303]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4424 [D loss: 0.632941, acc.: 59.38%] [G loss: 0.908245]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4425 [D loss: 0.719514, acc.: 46.88%] [G loss: 0.907798]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4426 [D loss: 0.679562, acc.: 56.25%] [G loss: 0.863666]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4427 [D loss: 0.707756, acc.: 46.88%] [G loss: 0.884805]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4428 [D loss: 0.723638, acc.: 59.38%] [G loss: 0.838734]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4429 [D loss: 0.646821, acc.: 62.50%] [G loss: 0.887176]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4430 [D loss: 0.619037, acc.: 68.75%] [G loss: 0.884551]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4431 [D loss: 0.788731, acc.: 43.75%] [G loss: 0.898398]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "4432 [D loss: 0.680117, acc.: 65.62%] [G loss: 0.978632]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4433 [D loss: 0.603088, acc.: 68.75%] [G loss: 0.968083]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "4434 [D loss: 0.556808, acc.: 78.12%] [G loss: 0.972472]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4435 [D loss: 0.673213, acc.: 59.38%] [G loss: 0.870193]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4436 [D loss: 0.665574, acc.: 62.50%] [G loss: 0.901689]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4437 [D loss: 0.704303, acc.: 56.25%] [G loss: 0.860081]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4438 [D loss: 0.716926, acc.: 50.00%] [G loss: 0.924688]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4439 [D loss: 0.704076, acc.: 46.88%] [G loss: 0.842274]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4440 [D loss: 0.583208, acc.: 65.62%] [G loss: 0.974145]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4441 [D loss: 0.590239, acc.: 71.88%] [G loss: 0.916308]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4442 [D loss: 0.611548, acc.: 59.38%] [G loss: 0.853036]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "4443 [D loss: 0.601966, acc.: 56.25%] [G loss: 0.927013]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4444 [D loss: 0.654420, acc.: 56.25%] [G loss: 0.911077]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4445 [D loss: 0.570764, acc.: 71.88%] [G loss: 0.872208]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4446 [D loss: 0.568111, acc.: 71.88%] [G loss: 0.947358]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4447 [D loss: 0.763773, acc.: 56.25%] [G loss: 1.017703]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4448 [D loss: 0.572501, acc.: 68.75%] [G loss: 0.941855]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4449 [D loss: 0.609020, acc.: 65.62%] [G loss: 0.991014]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4450 [D loss: 0.769694, acc.: 43.75%] [G loss: 0.871192]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4451 [D loss: 0.666691, acc.: 50.00%] [G loss: 0.814598]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4452 [D loss: 0.664373, acc.: 56.25%] [G loss: 0.831984]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4453 [D loss: 0.738370, acc.: 53.12%] [G loss: 0.914849]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4454 [D loss: 0.598658, acc.: 71.88%] [G loss: 0.964673]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4455 [D loss: 0.620048, acc.: 62.50%] [G loss: 0.804075]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4456 [D loss: 0.608855, acc.: 62.50%] [G loss: 0.896400]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4457 [D loss: 0.603188, acc.: 62.50%] [G loss: 0.920589]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4458 [D loss: 0.666845, acc.: 62.50%] [G loss: 0.953773]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4459 [D loss: 0.632660, acc.: 59.38%] [G loss: 0.860143]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4460 [D loss: 0.640531, acc.: 62.50%] [G loss: 0.927944]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4461 [D loss: 0.720349, acc.: 43.75%] [G loss: 0.943324]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4462 [D loss: 0.561655, acc.: 71.88%] [G loss: 0.936643]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4463 [D loss: 0.729108, acc.: 53.12%] [G loss: 0.873868]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4464 [D loss: 0.592185, acc.: 71.88%] [G loss: 0.858090]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4465 [D loss: 0.774034, acc.: 46.88%] [G loss: 0.918092]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4466 [D loss: 0.580028, acc.: 75.00%] [G loss: 0.952745]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4467 [D loss: 0.744644, acc.: 46.88%] [G loss: 0.932816]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4468 [D loss: 0.682730, acc.: 62.50%] [G loss: 1.013686]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4469 [D loss: 0.595136, acc.: 71.88%] [G loss: 0.938356]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4470 [D loss: 0.614930, acc.: 65.62%] [G loss: 0.918004]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4471 [D loss: 0.572767, acc.: 75.00%] [G loss: 0.939474]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4472 [D loss: 0.710788, acc.: 46.88%] [G loss: 0.877274]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4473 [D loss: 0.546773, acc.: 75.00%] [G loss: 0.876587]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4474 [D loss: 0.640643, acc.: 59.38%] [G loss: 0.956230]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4475 [D loss: 0.637364, acc.: 56.25%] [G loss: 0.870341]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4476 [D loss: 0.626078, acc.: 68.75%] [G loss: 0.989349]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4477 [D loss: 0.601765, acc.: 68.75%] [G loss: 0.921366]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4478 [D loss: 0.651163, acc.: 65.62%] [G loss: 0.903093]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4479 [D loss: 0.798077, acc.: 40.62%] [G loss: 0.878106]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4480 [D loss: 0.626922, acc.: 71.88%] [G loss: 0.841889]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4481 [D loss: 0.573081, acc.: 81.25%] [G loss: 0.930920]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4482 [D loss: 0.594521, acc.: 75.00%] [G loss: 0.980865]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4483 [D loss: 0.659396, acc.: 62.50%] [G loss: 1.058455]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4484 [D loss: 0.591688, acc.: 68.75%] [G loss: 0.913095]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4485 [D loss: 0.761860, acc.: 46.88%] [G loss: 0.842913]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4486 [D loss: 0.571714, acc.: 71.88%] [G loss: 0.886884]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4487 [D loss: 0.654948, acc.: 62.50%] [G loss: 0.902562]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4488 [D loss: 0.702804, acc.: 53.12%] [G loss: 0.955711]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4489 [D loss: 0.576679, acc.: 78.12%] [G loss: 0.889370]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4490 [D loss: 0.548410, acc.: 75.00%] [G loss: 0.982755]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4491 [D loss: 0.685810, acc.: 59.38%] [G loss: 1.013464]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4492 [D loss: 0.650641, acc.: 62.50%] [G loss: 1.010599]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4493 [D loss: 0.652924, acc.: 56.25%] [G loss: 1.021639]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4494 [D loss: 0.523295, acc.: 81.25%] [G loss: 0.976014]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4495 [D loss: 0.627769, acc.: 68.75%] [G loss: 1.026967]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4496 [D loss: 0.646175, acc.: 59.38%] [G loss: 1.058256]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4497 [D loss: 0.717961, acc.: 50.00%] [G loss: 0.975276]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4498 [D loss: 0.677615, acc.: 53.12%] [G loss: 0.968968]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4499 [D loss: 0.653054, acc.: 56.25%] [G loss: 0.863471]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4500 [D loss: 0.675607, acc.: 56.25%] [G loss: 0.903799]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4501 [D loss: 0.603134, acc.: 65.62%] [G loss: 0.925128]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4502 [D loss: 0.601715, acc.: 68.75%] [G loss: 0.888690]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4503 [D loss: 0.660743, acc.: 62.50%] [G loss: 0.892062]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4504 [D loss: 0.667535, acc.: 56.25%] [G loss: 0.903461]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4505 [D loss: 0.616115, acc.: 71.88%] [G loss: 0.868850]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4506 [D loss: 0.674743, acc.: 56.25%] [G loss: 0.898577]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4507 [D loss: 0.642422, acc.: 68.75%] [G loss: 0.862404]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4508 [D loss: 0.779431, acc.: 43.75%] [G loss: 0.916420]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4509 [D loss: 0.655680, acc.: 56.25%] [G loss: 0.870969]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4510 [D loss: 0.650745, acc.: 56.25%] [G loss: 0.852497]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4511 [D loss: 0.608536, acc.: 59.38%] [G loss: 0.898747]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4512 [D loss: 0.645066, acc.: 62.50%] [G loss: 0.849664]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4513 [D loss: 0.599129, acc.: 71.88%] [G loss: 0.911327]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4514 [D loss: 0.577128, acc.: 68.75%] [G loss: 0.832674]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4515 [D loss: 0.604067, acc.: 62.50%] [G loss: 0.957535]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4516 [D loss: 0.570397, acc.: 68.75%] [G loss: 0.920080]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4517 [D loss: 0.581234, acc.: 65.62%] [G loss: 0.916272]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4518 [D loss: 0.641955, acc.: 65.62%] [G loss: 0.949332]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4519 [D loss: 0.608919, acc.: 56.25%] [G loss: 0.931655]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4520 [D loss: 0.548442, acc.: 81.25%] [G loss: 0.988360]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4521 [D loss: 0.689828, acc.: 46.88%] [G loss: 0.954829]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4522 [D loss: 0.648381, acc.: 62.50%] [G loss: 0.791977]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4523 [D loss: 0.676531, acc.: 59.38%] [G loss: 0.877282]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4524 [D loss: 0.613088, acc.: 68.75%] [G loss: 0.899818]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4525 [D loss: 0.563907, acc.: 84.38%] [G loss: 0.946288]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4526 [D loss: 0.637607, acc.: 68.75%] [G loss: 0.829303]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4527 [D loss: 0.753134, acc.: 56.25%] [G loss: 0.833069]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4528 [D loss: 0.643930, acc.: 68.75%] [G loss: 0.973483]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4529 [D loss: 0.623328, acc.: 62.50%] [G loss: 1.031721]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4530 [D loss: 0.633515, acc.: 65.62%] [G loss: 1.031199]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4531 [D loss: 0.663582, acc.: 59.38%] [G loss: 0.897778]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4532 [D loss: 0.711324, acc.: 50.00%] [G loss: 0.892647]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4533 [D loss: 0.694503, acc.: 50.00%] [G loss: 0.877695]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4534 [D loss: 0.628252, acc.: 62.50%] [G loss: 0.881744]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4535 [D loss: 0.702860, acc.: 53.12%] [G loss: 0.853033]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4536 [D loss: 0.608566, acc.: 75.00%] [G loss: 0.848229]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4537 [D loss: 0.591010, acc.: 62.50%] [G loss: 0.953771]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4538 [D loss: 0.615883, acc.: 65.62%] [G loss: 0.994443]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4539 [D loss: 0.670617, acc.: 62.50%] [G loss: 0.950007]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4540 [D loss: 0.608242, acc.: 59.38%] [G loss: 0.985963]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4541 [D loss: 0.625324, acc.: 59.38%] [G loss: 0.950966]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4542 [D loss: 0.558873, acc.: 71.88%] [G loss: 0.970392]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4543 [D loss: 0.598929, acc.: 75.00%] [G loss: 0.926481]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4544 [D loss: 0.664520, acc.: 59.38%] [G loss: 0.918740]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "4545 [D loss: 0.721054, acc.: 56.25%] [G loss: 0.846780]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4546 [D loss: 0.680355, acc.: 59.38%] [G loss: 0.896761]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4547 [D loss: 0.596213, acc.: 71.88%] [G loss: 0.852773]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4548 [D loss: 0.645886, acc.: 65.62%] [G loss: 0.903509]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4549 [D loss: 0.630114, acc.: 68.75%] [G loss: 0.918248]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4550 [D loss: 0.683669, acc.: 59.38%] [G loss: 0.924326]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4551 [D loss: 0.649536, acc.: 62.50%] [G loss: 0.935635]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4552 [D loss: 0.609736, acc.: 71.88%] [G loss: 0.849108]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4553 [D loss: 0.641260, acc.: 68.75%] [G loss: 0.840933]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "4554 [D loss: 0.682676, acc.: 50.00%] [G loss: 0.895803]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4555 [D loss: 0.660999, acc.: 50.00%] [G loss: 0.925531]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4556 [D loss: 0.686846, acc.: 53.12%] [G loss: 0.879267]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4557 [D loss: 0.543694, acc.: 75.00%] [G loss: 0.964429]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "4558 [D loss: 0.716801, acc.: 59.38%] [G loss: 0.842644]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4559 [D loss: 0.589483, acc.: 81.25%] [G loss: 0.913122]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4560 [D loss: 0.650060, acc.: 53.12%] [G loss: 1.011783]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4561 [D loss: 0.579577, acc.: 71.88%] [G loss: 1.035881]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4562 [D loss: 0.735587, acc.: 50.00%] [G loss: 0.905446]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4563 [D loss: 0.531917, acc.: 84.38%] [G loss: 0.953971]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4564 [D loss: 0.658594, acc.: 59.38%] [G loss: 0.922372]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4565 [D loss: 0.601093, acc.: 65.62%] [G loss: 0.849729]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4566 [D loss: 0.665450, acc.: 56.25%] [G loss: 0.853153]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4567 [D loss: 0.640612, acc.: 75.00%] [G loss: 0.930664]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4568 [D loss: 0.693700, acc.: 62.50%] [G loss: 0.817303]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4569 [D loss: 0.669160, acc.: 59.38%] [G loss: 0.850374]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4570 [D loss: 0.638171, acc.: 65.62%] [G loss: 0.908405]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4571 [D loss: 0.613487, acc.: 65.62%] [G loss: 0.905563]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4572 [D loss: 0.592414, acc.: 62.50%] [G loss: 0.925190]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4573 [D loss: 0.759994, acc.: 37.50%] [G loss: 0.855769]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4574 [D loss: 0.619631, acc.: 68.75%] [G loss: 0.912850]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4575 [D loss: 0.636333, acc.: 59.38%] [G loss: 1.069190]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4576 [D loss: 0.682050, acc.: 62.50%] [G loss: 0.923710]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4577 [D loss: 0.807741, acc.: 53.12%] [G loss: 0.977500]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4578 [D loss: 0.697178, acc.: 53.12%] [G loss: 0.976412]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4579 [D loss: 0.704266, acc.: 59.38%] [G loss: 0.887282]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4580 [D loss: 0.721460, acc.: 53.12%] [G loss: 0.910362]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4581 [D loss: 0.606420, acc.: 62.50%] [G loss: 0.847544]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4582 [D loss: 0.648920, acc.: 53.12%] [G loss: 0.840444]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4583 [D loss: 0.693514, acc.: 53.12%] [G loss: 0.890513]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4584 [D loss: 0.659562, acc.: 62.50%] [G loss: 0.850295]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4585 [D loss: 0.577038, acc.: 81.25%] [G loss: 0.850768]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4586 [D loss: 0.686870, acc.: 53.12%] [G loss: 0.878897]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4587 [D loss: 0.616955, acc.: 68.75%] [G loss: 0.971789]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4588 [D loss: 0.730328, acc.: 53.12%] [G loss: 0.937860]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4589 [D loss: 0.718800, acc.: 50.00%] [G loss: 0.926509]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4590 [D loss: 0.727051, acc.: 46.88%] [G loss: 0.996707]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4591 [D loss: 0.696060, acc.: 59.38%] [G loss: 0.938315]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4592 [D loss: 0.633561, acc.: 62.50%] [G loss: 0.964864]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4593 [D loss: 0.655708, acc.: 68.75%] [G loss: 0.816149]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4594 [D loss: 0.676389, acc.: 59.38%] [G loss: 0.867750]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4595 [D loss: 0.684669, acc.: 62.50%] [G loss: 0.902389]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4596 [D loss: 0.624623, acc.: 68.75%] [G loss: 0.893233]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4597 [D loss: 0.580615, acc.: 68.75%] [G loss: 0.924218]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4598 [D loss: 0.708201, acc.: 50.00%] [G loss: 1.004767]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4599 [D loss: 0.624248, acc.: 59.38%] [G loss: 1.014174]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4600 [D loss: 0.628643, acc.: 65.62%] [G loss: 0.994437]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4601 [D loss: 0.742753, acc.: 53.12%] [G loss: 0.937561]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4602 [D loss: 0.726361, acc.: 37.50%] [G loss: 0.922858]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4603 [D loss: 0.600528, acc.: 68.75%] [G loss: 0.913007]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4604 [D loss: 0.615601, acc.: 65.62%] [G loss: 0.933484]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4605 [D loss: 0.661659, acc.: 59.38%] [G loss: 0.929617]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4606 [D loss: 0.656050, acc.: 53.12%] [G loss: 0.907378]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4607 [D loss: 0.601379, acc.: 71.88%] [G loss: 0.835693]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4608 [D loss: 0.672452, acc.: 59.38%] [G loss: 0.869961]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4609 [D loss: 0.534863, acc.: 81.25%] [G loss: 0.857901]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4610 [D loss: 0.613948, acc.: 62.50%] [G loss: 0.903853]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4611 [D loss: 0.657461, acc.: 56.25%] [G loss: 0.937471]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4612 [D loss: 0.705404, acc.: 59.38%] [G loss: 0.987869]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4613 [D loss: 0.604672, acc.: 62.50%] [G loss: 0.954619]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4614 [D loss: 0.672547, acc.: 68.75%] [G loss: 0.903209]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4615 [D loss: 0.601394, acc.: 71.88%] [G loss: 0.871998]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4616 [D loss: 0.603456, acc.: 65.62%] [G loss: 0.914151]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4617 [D loss: 0.673554, acc.: 75.00%] [G loss: 0.891619]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4618 [D loss: 0.671455, acc.: 59.38%] [G loss: 0.889159]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4619 [D loss: 0.723023, acc.: 56.25%] [G loss: 0.930233]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4620 [D loss: 0.612565, acc.: 71.88%] [G loss: 1.003712]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4621 [D loss: 0.619408, acc.: 68.75%] [G loss: 0.875094]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4622 [D loss: 0.588080, acc.: 68.75%] [G loss: 0.899172]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4623 [D loss: 0.560429, acc.: 75.00%] [G loss: 1.044276]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4624 [D loss: 0.635514, acc.: 68.75%] [G loss: 0.927454]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4625 [D loss: 0.688378, acc.: 50.00%] [G loss: 0.877325]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4626 [D loss: 0.630892, acc.: 59.38%] [G loss: 0.853168]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4627 [D loss: 0.608533, acc.: 75.00%] [G loss: 0.855437]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4628 [D loss: 0.667875, acc.: 68.75%] [G loss: 0.852619]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4629 [D loss: 0.658697, acc.: 62.50%] [G loss: 0.875203]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4630 [D loss: 0.609060, acc.: 62.50%] [G loss: 0.847185]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4631 [D loss: 0.603075, acc.: 65.62%] [G loss: 0.955875]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4632 [D loss: 0.829241, acc.: 43.75%] [G loss: 0.917681]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4633 [D loss: 0.663146, acc.: 62.50%] [G loss: 0.943039]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4634 [D loss: 0.635171, acc.: 62.50%] [G loss: 0.995372]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4635 [D loss: 0.640298, acc.: 68.75%] [G loss: 0.949125]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4636 [D loss: 0.628007, acc.: 56.25%] [G loss: 0.879987]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4637 [D loss: 0.673699, acc.: 56.25%] [G loss: 1.007936]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4638 [D loss: 0.539671, acc.: 68.75%] [G loss: 0.994213]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4639 [D loss: 0.791918, acc.: 43.75%] [G loss: 0.998940]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4640 [D loss: 0.630234, acc.: 65.62%] [G loss: 0.916610]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4641 [D loss: 0.765516, acc.: 50.00%] [G loss: 0.819167]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4642 [D loss: 0.596242, acc.: 71.88%] [G loss: 0.886172]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4643 [D loss: 0.709852, acc.: 53.12%] [G loss: 0.921401]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4644 [D loss: 0.635715, acc.: 62.50%] [G loss: 0.821939]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4645 [D loss: 0.626429, acc.: 62.50%] [G loss: 0.850320]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4646 [D loss: 0.681297, acc.: 59.38%] [G loss: 0.839521]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4647 [D loss: 0.624567, acc.: 68.75%] [G loss: 0.885263]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4648 [D loss: 0.691683, acc.: 53.12%] [G loss: 0.896711]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4649 [D loss: 0.642086, acc.: 71.88%] [G loss: 0.869630]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4650 [D loss: 0.633457, acc.: 59.38%] [G loss: 0.853598]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4651 [D loss: 0.662972, acc.: 53.12%] [G loss: 0.909762]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4652 [D loss: 0.688087, acc.: 50.00%] [G loss: 1.015266]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4653 [D loss: 0.633077, acc.: 59.38%] [G loss: 0.945569]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4654 [D loss: 0.728774, acc.: 46.88%] [G loss: 0.874423]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4655 [D loss: 0.573615, acc.: 71.88%] [G loss: 0.924262]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4656 [D loss: 0.575743, acc.: 78.12%] [G loss: 1.034250]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "4657 [D loss: 0.691426, acc.: 56.25%] [G loss: 0.853029]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4658 [D loss: 0.683002, acc.: 50.00%] [G loss: 0.850873]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4659 [D loss: 0.690315, acc.: 62.50%] [G loss: 0.843972]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4660 [D loss: 0.632871, acc.: 56.25%] [G loss: 0.940181]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4661 [D loss: 0.634362, acc.: 71.88%] [G loss: 0.864423]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4662 [D loss: 0.660140, acc.: 65.62%] [G loss: 0.912358]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "4663 [D loss: 0.680484, acc.: 68.75%] [G loss: 0.858600]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4664 [D loss: 0.607628, acc.: 65.62%] [G loss: 0.861947]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4665 [D loss: 0.711578, acc.: 53.12%] [G loss: 0.907876]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4666 [D loss: 0.586345, acc.: 75.00%] [G loss: 0.833349]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4667 [D loss: 0.651960, acc.: 62.50%] [G loss: 0.870404]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4668 [D loss: 0.684711, acc.: 46.88%] [G loss: 0.941509]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4669 [D loss: 0.652947, acc.: 56.25%] [G loss: 0.925529]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4670 [D loss: 0.665391, acc.: 56.25%] [G loss: 0.980663]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4671 [D loss: 0.682656, acc.: 56.25%] [G loss: 0.929877]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "4672 [D loss: 0.743790, acc.: 53.12%] [G loss: 0.978195]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4673 [D loss: 0.656204, acc.: 62.50%] [G loss: 0.929353]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4674 [D loss: 0.694757, acc.: 59.38%] [G loss: 0.858914]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "4675 [D loss: 0.593578, acc.: 68.75%] [G loss: 0.912609]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4676 [D loss: 0.735609, acc.: 46.88%] [G loss: 0.952134]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4677 [D loss: 0.637828, acc.: 68.75%] [G loss: 0.824517]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4678 [D loss: 0.631805, acc.: 68.75%] [G loss: 0.874423]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4679 [D loss: 0.691058, acc.: 56.25%] [G loss: 0.892470]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4680 [D loss: 0.591158, acc.: 71.88%] [G loss: 0.894782]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4681 [D loss: 0.703457, acc.: 53.12%] [G loss: 0.857221]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4682 [D loss: 0.690400, acc.: 50.00%] [G loss: 0.874161]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4683 [D loss: 0.620358, acc.: 62.50%] [G loss: 0.872410]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4684 [D loss: 0.635103, acc.: 50.00%] [G loss: 0.863489]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4685 [D loss: 0.635412, acc.: 59.38%] [G loss: 0.868736]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4686 [D loss: 0.742569, acc.: 40.62%] [G loss: 0.838164]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4687 [D loss: 0.662461, acc.: 65.62%] [G loss: 0.772060]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4688 [D loss: 0.618653, acc.: 65.62%] [G loss: 0.743958]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4689 [D loss: 0.605708, acc.: 62.50%] [G loss: 0.767676]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4690 [D loss: 0.574574, acc.: 71.88%] [G loss: 0.921107]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4691 [D loss: 0.641571, acc.: 56.25%] [G loss: 0.952178]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4692 [D loss: 0.647112, acc.: 56.25%] [G loss: 0.983424]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4693 [D loss: 0.653277, acc.: 59.38%] [G loss: 0.857553]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4694 [D loss: 0.639535, acc.: 59.38%] [G loss: 0.861586]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4695 [D loss: 0.730403, acc.: 56.25%] [G loss: 0.905595]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4696 [D loss: 0.614008, acc.: 62.50%] [G loss: 0.901445]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4697 [D loss: 0.773462, acc.: 53.12%] [G loss: 0.866886]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4698 [D loss: 0.794287, acc.: 40.62%] [G loss: 0.929076]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4699 [D loss: 0.643296, acc.: 75.00%] [G loss: 0.928764]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4700 [D loss: 0.639885, acc.: 71.88%] [G loss: 0.848835]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4701 [D loss: 0.670314, acc.: 62.50%] [G loss: 0.898573]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4702 [D loss: 0.655078, acc.: 59.38%] [G loss: 0.924438]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4703 [D loss: 0.599606, acc.: 65.62%] [G loss: 0.837797]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4704 [D loss: 0.738404, acc.: 46.88%] [G loss: 0.909809]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4705 [D loss: 0.613885, acc.: 68.75%] [G loss: 0.924525]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4706 [D loss: 0.703681, acc.: 56.25%] [G loss: 0.912958]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4707 [D loss: 0.663573, acc.: 71.88%] [G loss: 0.968767]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4708 [D loss: 0.709595, acc.: 50.00%] [G loss: 0.956591]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4709 [D loss: 0.594414, acc.: 62.50%] [G loss: 0.950588]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4710 [D loss: 0.613716, acc.: 71.88%] [G loss: 0.869292]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4711 [D loss: 0.624843, acc.: 65.62%] [G loss: 0.875972]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4712 [D loss: 0.625057, acc.: 56.25%] [G loss: 0.937100]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4713 [D loss: 0.624544, acc.: 65.62%] [G loss: 0.889416]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4714 [D loss: 0.617353, acc.: 65.62%] [G loss: 0.821603]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4715 [D loss: 0.708881, acc.: 59.38%] [G loss: 0.853262]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4716 [D loss: 0.581409, acc.: 81.25%] [G loss: 0.889960]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4717 [D loss: 0.666379, acc.: 59.38%] [G loss: 0.896639]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4718 [D loss: 0.714997, acc.: 56.25%] [G loss: 0.893211]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4719 [D loss: 0.614666, acc.: 62.50%] [G loss: 0.828782]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4720 [D loss: 0.579773, acc.: 71.88%] [G loss: 0.814735]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4721 [D loss: 0.749834, acc.: 40.62%] [G loss: 0.915829]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4722 [D loss: 0.689354, acc.: 53.12%] [G loss: 0.854005]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4723 [D loss: 0.643011, acc.: 56.25%] [G loss: 0.901222]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4724 [D loss: 0.651518, acc.: 59.38%] [G loss: 0.942261]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4725 [D loss: 0.675340, acc.: 50.00%] [G loss: 0.861662]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4726 [D loss: 0.548205, acc.: 81.25%] [G loss: 0.921971]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4727 [D loss: 0.646407, acc.: 59.38%] [G loss: 0.887019]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4728 [D loss: 0.654207, acc.: 59.38%] [G loss: 0.902292]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4729 [D loss: 0.604223, acc.: 59.38%] [G loss: 0.959080]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4730 [D loss: 0.690777, acc.: 56.25%] [G loss: 0.872761]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4731 [D loss: 0.665763, acc.: 59.38%] [G loss: 0.922939]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4732 [D loss: 0.647703, acc.: 59.38%] [G loss: 0.967529]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4733 [D loss: 0.668707, acc.: 62.50%] [G loss: 0.939599]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4734 [D loss: 0.635219, acc.: 68.75%] [G loss: 0.896273]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4735 [D loss: 0.720858, acc.: 53.12%] [G loss: 0.869745]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4736 [D loss: 0.615853, acc.: 62.50%] [G loss: 0.932675]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4737 [D loss: 0.649851, acc.: 62.50%] [G loss: 0.940350]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4738 [D loss: 0.671940, acc.: 59.38%] [G loss: 0.870109]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4739 [D loss: 0.696833, acc.: 53.12%] [G loss: 0.826808]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4740 [D loss: 0.687372, acc.: 43.75%] [G loss: 0.831230]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4741 [D loss: 0.562371, acc.: 68.75%] [G loss: 0.931276]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4742 [D loss: 0.640112, acc.: 71.88%] [G loss: 0.964852]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4743 [D loss: 0.609819, acc.: 68.75%] [G loss: 0.784205]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4744 [D loss: 0.661715, acc.: 56.25%] [G loss: 0.850904]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4745 [D loss: 0.659996, acc.: 62.50%] [G loss: 0.818408]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4746 [D loss: 0.678253, acc.: 46.88%] [G loss: 0.835004]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4747 [D loss: 0.745501, acc.: 53.12%] [G loss: 0.911859]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4748 [D loss: 0.659410, acc.: 59.38%] [G loss: 0.933165]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4749 [D loss: 0.684236, acc.: 53.12%] [G loss: 0.974786]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4750 [D loss: 0.682728, acc.: 62.50%] [G loss: 0.870064]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4751 [D loss: 0.676439, acc.: 65.62%] [G loss: 0.948087]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4752 [D loss: 0.627271, acc.: 71.88%] [G loss: 0.915784]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4753 [D loss: 0.699971, acc.: 59.38%] [G loss: 0.886579]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4754 [D loss: 0.793057, acc.: 40.62%] [G loss: 0.830290]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4755 [D loss: 0.616024, acc.: 56.25%] [G loss: 0.857408]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4756 [D loss: 0.733647, acc.: 56.25%] [G loss: 0.955605]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4757 [D loss: 0.616463, acc.: 62.50%] [G loss: 0.925105]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4758 [D loss: 0.704492, acc.: 59.38%] [G loss: 0.891597]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4759 [D loss: 0.582522, acc.: 75.00%] [G loss: 0.943093]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4760 [D loss: 0.662395, acc.: 56.25%] [G loss: 0.893181]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4761 [D loss: 0.598037, acc.: 68.75%] [G loss: 0.901123]\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "4762 [D loss: 0.577062, acc.: 71.88%] [G loss: 0.916195]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4763 [D loss: 0.638013, acc.: 78.12%] [G loss: 0.810140]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4764 [D loss: 0.648236, acc.: 62.50%] [G loss: 0.854074]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "4765 [D loss: 0.749307, acc.: 59.38%] [G loss: 0.846553]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4766 [D loss: 0.654349, acc.: 62.50%] [G loss: 0.862119]\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "4767 [D loss: 0.666413, acc.: 56.25%] [G loss: 0.817603]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4768 [D loss: 0.609327, acc.: 75.00%] [G loss: 0.870957]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "4769 [D loss: 0.658169, acc.: 71.88%] [G loss: 0.920330]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4770 [D loss: 0.557954, acc.: 78.12%] [G loss: 1.031501]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4771 [D loss: 0.612404, acc.: 65.62%] [G loss: 0.978064]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4772 [D loss: 0.699187, acc.: 59.38%] [G loss: 0.959233]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "4773 [D loss: 0.764394, acc.: 31.25%] [G loss: 0.894479]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4774 [D loss: 0.614709, acc.: 68.75%] [G loss: 1.012847]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4775 [D loss: 0.703250, acc.: 59.38%] [G loss: 0.997881]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "4776 [D loss: 0.622019, acc.: 68.75%] [G loss: 0.947650]\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "4777 [D loss: 0.772048, acc.: 28.12%] [G loss: 0.880147]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4778 [D loss: 0.600441, acc.: 65.62%] [G loss: 0.868288]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4779 [D loss: 0.582545, acc.: 71.88%] [G loss: 0.781989]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4780 [D loss: 0.572383, acc.: 68.75%] [G loss: 0.887959]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4781 [D loss: 0.744929, acc.: 56.25%] [G loss: 0.817444]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4782 [D loss: 0.632815, acc.: 59.38%] [G loss: 0.837372]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4783 [D loss: 0.661508, acc.: 65.62%] [G loss: 0.901340]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4784 [D loss: 0.565769, acc.: 75.00%] [G loss: 0.895741]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4785 [D loss: 0.690679, acc.: 56.25%] [G loss: 0.873749]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4786 [D loss: 0.727874, acc.: 53.12%] [G loss: 0.879416]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4787 [D loss: 0.586073, acc.: 65.62%] [G loss: 0.960785]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4788 [D loss: 0.610656, acc.: 75.00%] [G loss: 1.048755]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4789 [D loss: 0.568820, acc.: 71.88%] [G loss: 1.028619]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4790 [D loss: 0.597367, acc.: 65.62%] [G loss: 0.918996]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4791 [D loss: 0.706348, acc.: 46.88%] [G loss: 0.963102]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4792 [D loss: 0.612811, acc.: 65.62%] [G loss: 0.892519]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4793 [D loss: 0.556646, acc.: 75.00%] [G loss: 0.938275]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4794 [D loss: 0.607688, acc.: 65.62%] [G loss: 0.848976]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4795 [D loss: 0.717585, acc.: 50.00%] [G loss: 0.866993]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4796 [D loss: 0.590234, acc.: 62.50%] [G loss: 0.952746]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4797 [D loss: 0.777648, acc.: 40.62%] [G loss: 0.862139]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4798 [D loss: 0.674886, acc.: 65.62%] [G loss: 0.945824]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4799 [D loss: 0.575185, acc.: 75.00%] [G loss: 0.962180]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4800 [D loss: 0.678750, acc.: 62.50%] [G loss: 0.934137]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4801 [D loss: 0.617121, acc.: 68.75%] [G loss: 0.837159]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4802 [D loss: 0.646365, acc.: 59.38%] [G loss: 0.848757]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4803 [D loss: 0.665834, acc.: 53.12%] [G loss: 0.837770]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4804 [D loss: 0.639013, acc.: 50.00%] [G loss: 0.893074]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4805 [D loss: 0.618452, acc.: 68.75%] [G loss: 0.951245]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4806 [D loss: 0.680320, acc.: 56.25%] [G loss: 0.876633]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4807 [D loss: 0.649704, acc.: 65.62%] [G loss: 0.876068]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4808 [D loss: 0.612468, acc.: 65.62%] [G loss: 0.949519]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4809 [D loss: 0.586259, acc.: 65.62%] [G loss: 1.034655]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4810 [D loss: 0.686012, acc.: 56.25%] [G loss: 0.986712]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4811 [D loss: 0.627421, acc.: 59.38%] [G loss: 0.966384]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4812 [D loss: 0.529932, acc.: 84.38%] [G loss: 0.983912]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4813 [D loss: 0.626664, acc.: 68.75%] [G loss: 1.021348]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4814 [D loss: 0.587327, acc.: 68.75%] [G loss: 0.964889]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4815 [D loss: 0.570995, acc.: 68.75%] [G loss: 1.007559]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4816 [D loss: 0.642765, acc.: 71.88%] [G loss: 0.919317]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4817 [D loss: 0.787419, acc.: 53.12%] [G loss: 0.746787]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4818 [D loss: 0.751263, acc.: 46.88%] [G loss: 0.856439]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4819 [D loss: 0.557338, acc.: 75.00%] [G loss: 0.928922]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4820 [D loss: 0.613010, acc.: 68.75%] [G loss: 0.895466]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4821 [D loss: 0.621135, acc.: 71.88%] [G loss: 0.944095]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4822 [D loss: 0.567574, acc.: 68.75%] [G loss: 0.930221]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4823 [D loss: 0.614861, acc.: 65.62%] [G loss: 0.975461]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4824 [D loss: 0.837435, acc.: 37.50%] [G loss: 1.005011]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4825 [D loss: 0.617088, acc.: 65.62%] [G loss: 1.107621]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4826 [D loss: 0.742849, acc.: 46.88%] [G loss: 0.963984]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4827 [D loss: 0.797837, acc.: 37.50%] [G loss: 0.907929]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4828 [D loss: 0.623590, acc.: 68.75%] [G loss: 0.997715]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4829 [D loss: 0.556192, acc.: 78.12%] [G loss: 0.948495]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4830 [D loss: 0.666485, acc.: 59.38%] [G loss: 0.943914]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4831 [D loss: 0.576265, acc.: 68.75%] [G loss: 0.948627]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4832 [D loss: 0.707678, acc.: 53.12%] [G loss: 0.950796]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4833 [D loss: 0.602888, acc.: 68.75%] [G loss: 0.935792]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4834 [D loss: 0.726065, acc.: 50.00%] [G loss: 0.849897]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4835 [D loss: 0.688677, acc.: 46.88%] [G loss: 0.876958]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4836 [D loss: 0.676142, acc.: 50.00%] [G loss: 0.857924]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4837 [D loss: 0.666149, acc.: 65.62%] [G loss: 0.863319]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4838 [D loss: 0.622637, acc.: 65.62%] [G loss: 0.792940]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4839 [D loss: 0.708202, acc.: 62.50%] [G loss: 0.878462]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4840 [D loss: 0.679684, acc.: 56.25%] [G loss: 0.913378]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4841 [D loss: 0.654265, acc.: 59.38%] [G loss: 0.980605]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4842 [D loss: 0.736653, acc.: 65.62%] [G loss: 0.932981]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4843 [D loss: 0.661633, acc.: 59.38%] [G loss: 0.877397]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4844 [D loss: 0.676857, acc.: 62.50%] [G loss: 0.922732]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4845 [D loss: 0.583187, acc.: 78.12%] [G loss: 0.910217]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4846 [D loss: 0.651002, acc.: 53.12%] [G loss: 0.860103]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4847 [D loss: 0.616021, acc.: 68.75%] [G loss: 0.891151]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4848 [D loss: 0.679996, acc.: 65.62%] [G loss: 0.942027]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4849 [D loss: 0.665898, acc.: 50.00%] [G loss: 0.959882]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4850 [D loss: 0.578005, acc.: 65.62%] [G loss: 0.920683]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4851 [D loss: 0.633231, acc.: 62.50%] [G loss: 0.898658]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4852 [D loss: 0.710596, acc.: 50.00%] [G loss: 0.760991]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4853 [D loss: 0.635477, acc.: 59.38%] [G loss: 0.823341]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4854 [D loss: 0.623673, acc.: 68.75%] [G loss: 0.935592]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4855 [D loss: 0.659677, acc.: 62.50%] [G loss: 0.884505]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4856 [D loss: 0.605390, acc.: 65.62%] [G loss: 0.898309]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "4857 [D loss: 0.652994, acc.: 56.25%] [G loss: 0.868640]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4858 [D loss: 0.629345, acc.: 62.50%] [G loss: 0.837961]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4859 [D loss: 0.636508, acc.: 71.88%] [G loss: 0.811324]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4860 [D loss: 0.634565, acc.: 59.38%] [G loss: 0.806623]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4861 [D loss: 0.694150, acc.: 53.12%] [G loss: 0.898385]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4862 [D loss: 0.821625, acc.: 40.62%] [G loss: 0.873917]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4863 [D loss: 0.657702, acc.: 59.38%] [G loss: 0.941309]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4864 [D loss: 0.616837, acc.: 71.88%] [G loss: 0.888799]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4865 [D loss: 0.533722, acc.: 78.12%] [G loss: 0.914112]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4866 [D loss: 0.717542, acc.: 50.00%] [G loss: 0.941326]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4867 [D loss: 0.581839, acc.: 68.75%] [G loss: 0.910328]\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "4868 [D loss: 0.692495, acc.: 40.62%] [G loss: 0.914294]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4869 [D loss: 0.610023, acc.: 65.62%] [G loss: 0.987878]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4870 [D loss: 0.760019, acc.: 53.12%] [G loss: 0.975409]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4871 [D loss: 0.635973, acc.: 68.75%] [G loss: 0.936141]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4872 [D loss: 0.656469, acc.: 56.25%] [G loss: 0.877569]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4873 [D loss: 0.689058, acc.: 50.00%] [G loss: 0.711991]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4874 [D loss: 0.607068, acc.: 59.38%] [G loss: 0.803894]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4875 [D loss: 0.629275, acc.: 62.50%] [G loss: 0.854655]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4876 [D loss: 0.641977, acc.: 65.62%] [G loss: 0.873818]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4877 [D loss: 0.602734, acc.: 62.50%] [G loss: 0.948822]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4878 [D loss: 0.666341, acc.: 56.25%] [G loss: 0.885314]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4879 [D loss: 0.633294, acc.: 65.62%] [G loss: 0.931975]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4880 [D loss: 0.580864, acc.: 81.25%] [G loss: 0.845198]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4881 [D loss: 0.638749, acc.: 68.75%] [G loss: 0.912639]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4882 [D loss: 0.610001, acc.: 75.00%] [G loss: 0.937036]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4883 [D loss: 0.675315, acc.: 68.75%] [G loss: 0.862865]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4884 [D loss: 0.626578, acc.: 65.62%] [G loss: 0.924688]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4885 [D loss: 0.665429, acc.: 53.12%] [G loss: 0.865447]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4886 [D loss: 0.636267, acc.: 50.00%] [G loss: 0.825128]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4887 [D loss: 0.601788, acc.: 78.12%] [G loss: 0.891390]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4888 [D loss: 0.645298, acc.: 46.88%] [G loss: 0.801882]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4889 [D loss: 0.600895, acc.: 68.75%] [G loss: 0.799369]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4890 [D loss: 0.716188, acc.: 56.25%] [G loss: 0.891839]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4891 [D loss: 0.635722, acc.: 62.50%] [G loss: 0.871583]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4892 [D loss: 0.710478, acc.: 53.12%] [G loss: 0.968347]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4893 [D loss: 0.603550, acc.: 65.62%] [G loss: 0.884235]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4894 [D loss: 0.690221, acc.: 53.12%] [G loss: 0.927902]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4895 [D loss: 0.583378, acc.: 78.12%] [G loss: 0.998372]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4896 [D loss: 0.603656, acc.: 68.75%] [G loss: 0.931259]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4897 [D loss: 0.616616, acc.: 65.62%] [G loss: 0.975594]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4898 [D loss: 0.586747, acc.: 65.62%] [G loss: 0.942433]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4899 [D loss: 0.788320, acc.: 46.88%] [G loss: 0.873869]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4900 [D loss: 0.653742, acc.: 65.62%] [G loss: 0.834384]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4901 [D loss: 0.638053, acc.: 65.62%] [G loss: 0.787466]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4902 [D loss: 0.633673, acc.: 59.38%] [G loss: 0.905935]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4903 [D loss: 0.702239, acc.: 56.25%] [G loss: 0.923181]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4904 [D loss: 0.664383, acc.: 62.50%] [G loss: 0.909154]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4905 [D loss: 0.660792, acc.: 53.12%] [G loss: 1.009111]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4906 [D loss: 0.653717, acc.: 56.25%] [G loss: 0.941854]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4907 [D loss: 0.608472, acc.: 68.75%] [G loss: 0.966811]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4908 [D loss: 0.590923, acc.: 62.50%] [G loss: 0.888465]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4909 [D loss: 0.590185, acc.: 68.75%] [G loss: 0.967051]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4910 [D loss: 0.615735, acc.: 59.38%] [G loss: 0.903400]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4911 [D loss: 0.770172, acc.: 50.00%] [G loss: 0.912772]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4912 [D loss: 0.663945, acc.: 65.62%] [G loss: 0.945662]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4913 [D loss: 0.726627, acc.: 56.25%] [G loss: 0.879837]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4914 [D loss: 0.657132, acc.: 59.38%] [G loss: 0.999262]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4915 [D loss: 0.677775, acc.: 53.12%] [G loss: 0.891844]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4916 [D loss: 0.618596, acc.: 71.88%] [G loss: 0.957549]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4917 [D loss: 0.639998, acc.: 71.88%] [G loss: 1.027233]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4918 [D loss: 0.749418, acc.: 50.00%] [G loss: 0.880406]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4919 [D loss: 0.655071, acc.: 71.88%] [G loss: 0.909640]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4920 [D loss: 0.620835, acc.: 78.12%] [G loss: 0.810783]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4921 [D loss: 0.686265, acc.: 56.25%] [G loss: 0.901809]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4922 [D loss: 0.658194, acc.: 65.62%] [G loss: 0.878672]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4923 [D loss: 0.674815, acc.: 62.50%] [G loss: 0.869403]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4924 [D loss: 0.577207, acc.: 81.25%] [G loss: 0.918536]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4925 [D loss: 0.597820, acc.: 71.88%] [G loss: 0.920910]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4926 [D loss: 0.690171, acc.: 53.12%] [G loss: 0.909593]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4927 [D loss: 0.644791, acc.: 71.88%] [G loss: 0.899766]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4928 [D loss: 0.634014, acc.: 65.62%] [G loss: 0.940352]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4929 [D loss: 0.599805, acc.: 68.75%] [G loss: 0.969909]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4930 [D loss: 0.627888, acc.: 65.62%] [G loss: 0.881173]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4931 [D loss: 0.616956, acc.: 68.75%] [G loss: 0.939533]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4932 [D loss: 0.663726, acc.: 56.25%] [G loss: 0.890252]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4933 [D loss: 0.690562, acc.: 65.62%] [G loss: 0.924607]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4934 [D loss: 0.604729, acc.: 56.25%] [G loss: 0.870551]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4935 [D loss: 0.586154, acc.: 71.88%] [G loss: 0.900883]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4936 [D loss: 0.545963, acc.: 81.25%] [G loss: 0.891955]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4937 [D loss: 0.681444, acc.: 53.12%] [G loss: 0.906676]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4938 [D loss: 0.693913, acc.: 59.38%] [G loss: 0.911871]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4939 [D loss: 0.676434, acc.: 56.25%] [G loss: 0.902619]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4940 [D loss: 0.658887, acc.: 62.50%] [G loss: 0.899850]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4941 [D loss: 0.753766, acc.: 59.38%] [G loss: 0.925362]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4942 [D loss: 0.618550, acc.: 71.88%] [G loss: 0.900820]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4943 [D loss: 0.672695, acc.: 68.75%] [G loss: 0.886041]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4944 [D loss: 0.615179, acc.: 65.62%] [G loss: 0.906215]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4945 [D loss: 0.583710, acc.: 65.62%] [G loss: 0.891669]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4946 [D loss: 0.653313, acc.: 59.38%] [G loss: 0.887741]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4947 [D loss: 0.666223, acc.: 40.62%] [G loss: 1.006715]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4948 [D loss: 0.689975, acc.: 56.25%] [G loss: 0.944337]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4949 [D loss: 0.550676, acc.: 78.12%] [G loss: 0.899475]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4950 [D loss: 0.704966, acc.: 53.12%] [G loss: 0.996384]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4951 [D loss: 0.704946, acc.: 65.62%] [G loss: 0.983921]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4952 [D loss: 0.681594, acc.: 59.38%] [G loss: 0.866514]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4953 [D loss: 0.640187, acc.: 65.62%] [G loss: 0.938594]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4954 [D loss: 0.669237, acc.: 56.25%] [G loss: 0.948264]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4955 [D loss: 0.636894, acc.: 62.50%] [G loss: 0.999228]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4956 [D loss: 0.591192, acc.: 65.62%] [G loss: 0.956264]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4957 [D loss: 0.664164, acc.: 68.75%] [G loss: 1.014863]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4958 [D loss: 0.694843, acc.: 59.38%] [G loss: 0.998652]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4959 [D loss: 0.527035, acc.: 81.25%] [G loss: 1.026210]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4960 [D loss: 0.689803, acc.: 62.50%] [G loss: 0.999425]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4961 [D loss: 0.593695, acc.: 75.00%] [G loss: 0.991360]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4962 [D loss: 0.692394, acc.: 53.12%] [G loss: 0.889374]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4963 [D loss: 0.654103, acc.: 53.12%] [G loss: 0.853819]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4964 [D loss: 0.671800, acc.: 65.62%] [G loss: 0.890162]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4965 [D loss: 0.629659, acc.: 62.50%] [G loss: 0.858737]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4966 [D loss: 0.673334, acc.: 71.88%] [G loss: 0.808446]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "4967 [D loss: 0.603152, acc.: 71.88%] [G loss: 0.913882]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4968 [D loss: 0.655979, acc.: 62.50%] [G loss: 0.964477]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4969 [D loss: 0.535019, acc.: 81.25%] [G loss: 0.921387]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4970 [D loss: 0.619789, acc.: 71.88%] [G loss: 0.897776]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4971 [D loss: 0.693163, acc.: 56.25%] [G loss: 0.864157]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4972 [D loss: 0.606706, acc.: 62.50%] [G loss: 0.905884]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "4973 [D loss: 0.704854, acc.: 53.12%] [G loss: 0.899740]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "4974 [D loss: 0.669315, acc.: 59.38%] [G loss: 0.896676]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4975 [D loss: 0.642394, acc.: 59.38%] [G loss: 0.969177]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4976 [D loss: 0.640319, acc.: 68.75%] [G loss: 0.905917]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4977 [D loss: 0.628825, acc.: 65.62%] [G loss: 0.885358]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4978 [D loss: 0.662328, acc.: 53.12%] [G loss: 0.850350]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4979 [D loss: 0.654799, acc.: 59.38%] [G loss: 0.823492]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4980 [D loss: 0.630408, acc.: 62.50%] [G loss: 0.930980]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4981 [D loss: 0.623399, acc.: 75.00%] [G loss: 0.945908]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "4982 [D loss: 0.616379, acc.: 62.50%] [G loss: 0.874013]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4983 [D loss: 0.623154, acc.: 68.75%] [G loss: 0.912397]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4984 [D loss: 0.579963, acc.: 71.88%] [G loss: 0.873097]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4985 [D loss: 0.705826, acc.: 68.75%] [G loss: 0.860106]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4986 [D loss: 0.607942, acc.: 65.62%] [G loss: 0.917211]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4987 [D loss: 0.627055, acc.: 65.62%] [G loss: 0.889253]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4988 [D loss: 0.554951, acc.: 68.75%] [G loss: 1.004665]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "4989 [D loss: 0.720626, acc.: 56.25%] [G loss: 0.983427]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4990 [D loss: 0.576503, acc.: 68.75%] [G loss: 0.920817]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4991 [D loss: 0.639220, acc.: 62.50%] [G loss: 0.836416]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4992 [D loss: 0.670595, acc.: 56.25%] [G loss: 0.915601]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4993 [D loss: 0.620295, acc.: 68.75%] [G loss: 0.965168]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4994 [D loss: 0.773601, acc.: 50.00%] [G loss: 0.913904]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4995 [D loss: 0.644095, acc.: 78.12%] [G loss: 0.955418]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4996 [D loss: 0.741998, acc.: 50.00%] [G loss: 0.871430]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4997 [D loss: 0.715035, acc.: 59.38%] [G loss: 0.878622]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4998 [D loss: 0.601253, acc.: 75.00%] [G loss: 0.892457]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4999 [D loss: 0.699506, acc.: 56.25%] [G loss: 0.892464]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> the images/ folder shows the images generated by GANs after every 500 epochs"
      ],
      "metadata": {
        "id": "sDZHMwDPswlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### generate images now!"
      ],
      "metadata": {
        "id": "LytmdR_lvcgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from numpy import asarray\n",
        "from matplotlib import pyplot\n",
        "from numpy.random import randn\n",
        "\n",
        "# load model\n",
        "model = load_model('generator_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5OWkIgZkjQf",
        "outputId": "4a7b4262-0d35-4eb8-e13a-5076011b943a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To create random images each time...\n",
        "vector = randn(100) #Vector of random numbers (creates a column, need to reshape)\n",
        "vector = vector.reshape(1, 100)\n",
        "\n",
        "# generate image\n",
        "X = model.predict(vector)\n",
        "\n",
        "# plot the result\n",
        "pyplot.imshow(X[0, :, :, 0], cmap='gray_r')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "E7uOkLqOkjNk",
        "outputId": "6b1f6ac7-d1df-4320-e336-3ea443974ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/imagesGAN.zip /content/images"
      ],
      "metadata": {
        "id": "9urG9rndkjKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrthS-TvkjIE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}